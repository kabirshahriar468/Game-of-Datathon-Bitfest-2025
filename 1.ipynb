{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT ke dilam kore dilo. XGboost use kore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Load the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders']\n",
    "\n",
    "# Fill NaN values with 'Unknown' in categorical columns (specifically for 'Drug')\n",
    "for col in categorical_columns:\n",
    "    train_df[col] = train_df[col].fillna('Unknown')\n",
    "    test_df[col] = test_df[col].fillna('Unknown')\n",
    "\n",
    "# Make sure to preserve the 'Status' column\n",
    "status_train = train_df['Status']\n",
    "\n",
    "# Drop 'Status' from the dataframes before combining\n",
    "train_df = train_df.drop(columns=['Status'])\n",
    "\n",
    "# Combine the datasets (concatenate the dataframes)\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# One-hot encode all categorical columns\n",
    "combined_df = pd.get_dummies(combined_df, columns=categorical_columns)\n",
    "\n",
    "# Now, split the combined dataset back into train and test dataframes\n",
    "train_df = combined_df.iloc[:len(train_df), :]\n",
    "test_df = combined_df.iloc[len(train_df):, :]\n",
    "\n",
    "# Add the 'Status' column back to the dataframes\n",
    "train_df['Status'] = status_train\n",
    "\n",
    "# Check the result (first 10 rows of the train dataframe)\n",
    "train_df = pd.get_dummies(train_df, columns=['Status'])\n",
    "train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fix data types\n",
    "# Convert Edema to numeric\n",
    "train_df['Edema'] = train_df['Edema'].map({'N': 0, 'S': 1, 'Y': 2}).astype('int8')\n",
    "test_df['Edema'] = test_df['Edema'].map({'N': 0, 'S': 1, 'Y': 2}).astype('int8')\n",
    "\n",
    "# Fill numeric missing values with median\n",
    "numeric_cols = ['N_Days', 'Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', \n",
    "                'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n",
    "for col in numeric_cols:\n",
    "    train_df[col] = train_df[col].fillna(train_df[col].median())\n",
    "    test_df[col] = test_df[col].fillna(train_df[col].median())\n",
    "\n",
    "# 2. Prepare features and target\n",
    "feature_cols = [col for col in train_df.columns if col not in ['id', 'Status_C', 'Status_CL', 'Status_D']]\n",
    "X = train_df[feature_cols]\n",
    "\n",
    "# Convert target to numeric labels\n",
    "y = pd.Series(np.where(train_df['Status_C']==1, 0, \n",
    "                       np.where(train_df['Status_CL']==1, 1, 2)))\n",
    "\n",
    "# 3. Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Train XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train with validation monitoring\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 5. Evaluate model\n",
    "val_pred = model.predict_proba(X_val)\n",
    "val_loss = log_loss(y_val, val_pred)\n",
    "print(f\"\\nValidation Log Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Print feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(importance.sort_values('importance', ascending=False).head(10))\n",
    "\n",
    "# 6. Generate predictions\n",
    "X_test = test_df[feature_cols]\n",
    "test_pred = model.predict_proba(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Status_C': test_pred[:, 0],\n",
    "    'Status_CL': test_pred[:, 1],\n",
    "    'Status_D': test_pred[:, 2]\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission created!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
