{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90798,"databundleVersionId":10606811,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('./'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\nimport pandas as pd\nimport numpy as np\nimport ast\nimport re\nfrom datetime import datetime\nfrom dateutil import parser\nfrom collections import Counter\n\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\n\nfrom textblob import TextBlob\nfrom fuzzywuzzy import fuzz\nfrom sklearn.preprocessing import RobustScaler\n\n\nimport gc\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = '/kaggle/input/bitfest-datathon-2025/train.csv'\ntest_path  = '/kaggle/input/bitfest-datathon-2025/test.csv'\nsample_sub_path = '/kaggle/input/bitfest-datathon-2025/sample_submission.csv'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed=42\ndef parse_list( x):\n    \"\"\"Parse string representation of lists\"\"\"\n    if pd.isnull(x):\n        return []\n    try:\n        return ast.literal_eval(x)\n    except:\n        return []\n\ndef extract_skill_overlap( row):\n    \"\"\"Calculate skill overlap ratio\"\"\"\n    candidate = set(row['skills']) if 'skills' in row else set()\n    required  = set(row['skills_required']) if 'skills_required' in row else set()\n    if not candidate or not required:\n        return 0.0\n    inter = candidate.intersection(required)\n    union = candidate.union(required)\n    return len(inter) / len(union) if union else 0.0\n\ndef extract_total_experience_months( row):\n    \"\"\"Calculate total months of experience\"\"\"\n    start_str = row['start_dates']\n    end_str = row['end_dates']\n    start = parse_date(start_str)\n    end = parse_date(end_str)\n    if start is None or end is None:\n        return 0\n    diff = (end.year - start.year)*12 + (end.month - start.month)\n    return max(diff, 0)\n\ndef parse_date( date_str):\n    \"\"\"Parse date string\"\"\"\n    if pd.isnull(date_str):\n        return None\n    if any(word.lower() in str(date_str).lower() for word in ['till','present']):\n        return datetime.now()\n    try:\n        return parser.parse(str(date_str))\n    except:\n        return None\n\ndef extract_passing_year( val):\n    \"\"\"Extract passing year as integer\"\"\"\n    if pd.isnull(val):\n        return 0\n    try:\n        yrs = ast.literal_eval(val)\n        if isinstance(yrs, list) and len(yrs) > 0:\n            yrs_numeric = [int(x) for x in yrs if str(x).isdigit()]\n            if len(yrs_numeric) == 0:\n                return 0\n            return max(yrs_numeric)\n    except:\n        pass\n    return 0\n\n\ndef extract_education_features( df):\n    \"\"\"Enhanced education feature extraction\"\"\"\n    def get_education_level(degree):\n        if pd.isna(degree):\n            return 0\n        degree = degree.lower()\n        if 'phd' in degree or 'doctorate' in degree:\n            return 4\n        elif 'master' in degree or 'mba' in degree:\n            return 3\n        elif 'bachelor' in degree or 'bsc' in degree:\n            return 2\n        elif 'diploma' in degree or 'certificate' in degree:\n            return 1\n        return 0\n\n    df['education_level'] = df['degree_names'].apply(get_education_level)\n\n    def extract_numeric_result(x):\n        if pd.isna(x):\n            return 0.0\n        try:\n            matches = re.findall(r'\\d+\\.?\\d*', str(x))\n            if matches:\n                return float(matches[0])\n            return 0.0\n        except:\n            return 0.0\n\n    df['numeric_result'] = df['educational_results'].apply(extract_numeric_result)\n\n    # Education-job requirement match score using fuzzy matching\n    df['education_match'] = df.apply(\n        lambda x: fuzz.ratio(\n            str(x['degree_names']).lower(), \n            str(x['educationaL_requirements']).lower()\n        ) / 100.0, \n        axis=1\n    )\n\n    return df\n\ndef extract_experience_features( df):\n    \"\"\"Enhanced experience feature extraction\"\"\"\n    df['required_years'] = df['experiencere_requirement'].apply(extract_years)\n\n    # Calculate total experience in months\n    df['total_experience_months'] = df.apply(\n        extract_total_experience_months, axis=1\n    )\n\n    # Experience match score\n    df['experience_match'] = (\n        df['total_experience_months'] / df['required_years'].replace(0, 1)\n    ).clip(0, 2)\n\n    return df\n\ndef extract_years( text):\n    \"\"\"Extract years from text\"\"\"\n    if pd.isna(text):\n        return 0\n    years = re.findall(r'(\\d+)[\\s-]*year', text.lower())\n    return int(years[0]) if years else 0\n\ndef extract_skill_features( df):\n    \"\"\"Enhanced skill feature extraction\"\"\"\n    df['skills'] = df['skills'].apply(parse_list)\n    df['skills_required'] = df['skills_required'].apply(parse_list)\n\n    df['skill_overlap'] = df.apply(extract_skill_overlap, axis=1)\n\n    # Skill coverage\n    df['skill_coverage'] = df.apply(\n        lambda x: len(x['skills']) / max(len(x['skills_required']), 1) \n        if len(x['skills_required']) > 0 else 0, axis=1\n    )\n\n    # Skill importance score\n    skill_freq = Counter()\n    for skills in df['skills']:\n        skill_freq.update(skills)\n    \n    df['skill_importance_score'] = df.apply(\n        lambda x: sum(1/np.log2(skill_freq[skill] + 1) \n                        for skill in set(x['skills']).intersection(set(x['skills_required'])))\n        if len(x['skills_required']) > 0 else 0,\n        axis=1\n    )\n\n    df.drop(['skills', 'skills_required'], axis=1, inplace=True)\n\n    return df\n\ndef extract_text_features( df):\n    \"\"\"Enhanced text feature extraction\"\"\"\n    # Sentiment analysis\n    df['objective_sentiment'] = df['career_objective'].apply(\n        lambda x: TextBlob(str(x)).sentiment.polarity\n    )\n\n    # Text length features\n    df['objective_length'] = df['career_objective'].str.len()\n    df['resp_length'] = df['responsibilities'].str.len()\n\n    # Keyword matching between responsibilities\n    df['resp_match'] = df.apply(\n        lambda x: fuzz.ratio(\n            str(x['responsibilities']), \n            str(x['responsibilities.1'])\n        ) / 100.0,\n        axis=1\n    )\n\n    return df\n\n\ndef create_interaction_features( df):\n    \"\"\"Create interaction features\"\"\"\n    df['skill_edu_interaction'] = df['skill_overlap'] * df['education_match']\n    df['skill_exp_interaction'] = df['skill_overlap'] * df['experience_match']\n    df['edu_exp_interaction'] = df['education_match'] * df['experience_match']\n\n    return df\n\n# def encode_categorical_features( train_df, test_df, categorical_cols):\n#     \"\"\"Encode categorical features using Label Encoding\"\"\"\n#     for col in categorical_cols:\n#         if col in train_df.columns:\n#             le = LabelEncoder()\n#             train_df[f'{col}_encoded'] = le.fit_transform(train_df[col].fillna('unknown'))\n#             test_df[f'{col}_encoded'] = le.transform(test_df[col].fillna('unknown'))\n#     return train_df, test_df\n\n# from sklearn.preprocessing import LabelEncoder\n\n# def encode_categorical_features(train_df, test_df, categorical_cols):\n#     \"\"\"\n#     Encode categorical features using Label Encoding.\n#     If a category is present in the test set but not in the train set, it will be labeled as -1.\n#     \"\"\"\n#     for col in categorical_cols:\n#         if col in train_df.columns:\n#             le = LabelEncoder()\n\n#             # Combine unique categories from train and test to avoid unseen errors\n#             all_categories = pd.concat([train_df[col], test_df[col]], axis=0).fillna('unknown').unique()\n#             le.fit(all_categories)\n\n#             # Transform train and test datasets\n#             train_df[f'{col}_encoded'] = le.transform(train_df[col].fillna('unknown'))\n#             test_df[f'{col}_encoded'] = le.transform(test_df[col].fillna('unknown'))\n\n#     return train_df, test_df\n\ndef encode_categorical_features(train_df, test_df, categorical_cols):\n    \"\"\"\n    Encode categorical features where each cell can have multiple categories (e.g., lists) using One-Hot Encoding.\n    \"\"\"\n    for col in categorical_cols:\n        print(f\"Raw data sample for column {col} in train_df:\")\n        print(train_df[col].head(10))\n        print(f\"Raw data sample for column {col} in test_df:\")\n        print(test_df[col].head(10))\n        # print(f\"Data type of column {col} in train_df: {train_df[col].dtype}\")\n        # print(f\"Data type of column {col} in test_df: {test_df[col].dtype}\")\n        if col in train_df.columns:\n            # Ensure cells are parsed correctly as lists and handle empty/null values\n            train_df[col] = train_df[col].apply(lambda x: eval(x) if isinstance(x, str) and x.startswith('[') else x)\n            test_df[col] = test_df[col].apply(lambda x: eval(x) if isinstance(x, str) and x.startswith('[') else x)\n\n            train_df[col] = train_df[col].apply(lambda x: x if isinstance(x, list) and len(x) > 0 else ['unknown'])\n            test_df[col] = test_df[col].apply(lambda x: x if isinstance(x, list) and len(x) > 0 else ['unknown'])\n            \n            # Combine unique categories from both train and test\n            all_categories = pd.concat(\n                [train_df[col].explode(), test_df[col].explode()], axis=0\n            ).fillna('unknown').unique()\n\n            #print(f\"All categories for column {col}: {all_categories}\")  # Debugging\n            \n            # Create binary columns for each category\n            for category in all_categories:\n                train_df[f'{col}_{category}'] = train_df[col].apply(lambda x: 1 if category in x else 0)\n                test_df[f'{col}_{category}'] = test_df[col].apply(lambda x: 1 if category in x else 0)\n                \n    return train_df, test_df\n\n\n\n\n\ndef extract_text_features_tf_idf_svd_scaled(train_df, test_df, text_cols, max_features=500, n_components=50):\n    \"\"\"Encode text features using TF-IDF Vectorization, SVD, and scale the SVD features.\"\"\"\n    scaler = StandardScaler()  # Initialize the scaler\n    svd_cols = []  # List to store names of SVD columns created\n\n    for col in text_cols:\n        print(f\"Processing TF-IDF for column: {col}\")\n        tfidf = TfidfVectorizer(\n            stop_words='english',\n            max_features=max_features,\n            ngram_range=(1, 2)\n        )\n\n        # Fit TF-IDF on train and transform train/test\n        tfidf.fit(train_df[col].fillna('').astype(str))\n        train_tfidf = tfidf.transform(train_df[col].fillna('').astype(str))\n        test_tfidf = tfidf.transform(test_df[col].fillna('').astype(str))\n\n        # Truncated SVD\n        svd = TruncatedSVD(n_components=n_components, random_state=42)\n        svd.fit(train_tfidf)\n        train_svd = svd.transform(train_tfidf)\n        test_svd = svd.transform(test_tfidf)\n\n        # Scale the SVD components\n        train_svd_scaled = scaler.fit_transform(train_svd)  # Fit and transform on training data\n        test_svd_scaled = scaler.transform(test_svd)        # Transform on test data\n\n        # Add scaled SVD components as new features\n        for i in range(n_components):\n            svd_col_name = f'{col}_svd_scaled_{i}'\n            train_df[svd_col_name] = train_svd_scaled[:, i]\n            test_df[svd_col_name] = test_svd_scaled[:, i]\n            svd_cols.append(svd_col_name)  # Append to the list of SVD columns\n\n    # Drop original text columns\n    train_df.drop(text_cols, axis=1, inplace=True)\n    test_df.drop(text_cols, axis=1, inplace=True)\n    gc.collect()\n\n    return train_df, test_df, svd_cols\n\n\n\n\n\n\ndef prepare_features( train_df, test_df,numeric_cols):\n    \"\"\"Prepare features for modeling\"\"\"\n    # Fill missing numeric values with 0\n    # numeric_cols = ['skill_overlap', 'skill_coverage', 'skill_importance_score',\n    #                 'objective_sentiment', 'objective_length', 'resp_length',\n    #                 'resp_match', 'skill_edu_interaction', 'skill_exp_interaction',\n    #                 'edu_exp_interaction', 'total_experience_months', 'passing_year']\n    for col in numeric_cols:\n        if col in train_df.columns:\n            train_df[col] = train_df[col].fillna(0)\n        if col in test_df.columns:\n            test_df[col] = test_df[col].fillna(0)\n\n    return train_df, test_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# def emphasize_numerical_features(train_df, test_df, numerical_cols, svd_cols, weight_factor=2.0):\n#     \"\"\"\n#     Emphasize numerical features by scaling them and optionally weighting them more heavily than SVD features.\n#     \"\"\"\n#     # Initialize scalers\n#     numerical_cols = [col for col in numerical_cols if col in train_df.columns and col in test_df.columns]\n#     numerical_scaler = StandardScaler()\n#     svd_scaler = StandardScaler()\n\n#     # Scale and emphasize numerical features\n#     train_df[numerical_cols] = numerical_scaler.fit_transform(train_df[numerical_cols])\n#     test_df[numerical_cols] = numerical_scaler.transform(test_df[numerical_cols])\n    \n#     train_df[numerical_cols] *= weight_factor\n#     test_df[numerical_cols] *= weight_factor\n\n#     # Scale SVD features\n#     train_df[svd_cols] = svd_scaler.fit_transform(train_df[svd_cols])\n#     test_df[svd_cols] = svd_scaler.transform(test_df[svd_cols])\n\n#     # Combine emphasized numerical and scaled SVD features into separate DataFrames for clarity\n#     train_combined = train_df[numerical_cols + svd_cols + ['matched_score']].copy()\n#     test_combined = test_df[numerical_cols + svd_cols].copy()\n\n#     return train_combined, test_combined\n\n\ndef emphasize_numerical_features(train_df, test_df, numerical_cols, svd_cols, weight_factor=2.0):\n    \"\"\"\n    Emphasize numerical features by scaling them and optionally weighting them more heavily than SVD features.\n    Includes one-hot encoded columns dynamically.\n    \"\"\"\n\n    numerical_cols = [col for col in numerical_cols if col in train_df.columns and col in test_df.columns]\n    # Identify all numerical columns (explicit + dynamically generated one-hot encoded columns)\n    one_hot_encoded_cols = [col for col in train_df.columns if col not in numerical_cols + svd_cols + ['matched_score'] and train_df[col].dtype in [np.int64, np.float64]]\n    all_numerical_cols = numerical_cols + one_hot_encoded_cols\n    \n    print(\"Final numerical columns (including one-hot encoded):\", all_numerical_cols)\n    \n    # Initialize scalers\n    numerical_scaler = StandardScaler()\n    svd_scaler = StandardScaler()\n    \n    # Scale and emphasize numerical features\n    train_df[all_numerical_cols] = numerical_scaler.fit_transform(train_df[all_numerical_cols])\n    test_df[all_numerical_cols] = numerical_scaler.transform(test_df[all_numerical_cols])\n    \n    train_df[all_numerical_cols] *= weight_factor\n    test_df[all_numerical_cols] *= weight_factor\n    \n    # Scale SVD features\n    train_df[svd_cols] = svd_scaler.fit_transform(train_df[svd_cols])\n    test_df[svd_cols] = svd_scaler.transform(test_df[svd_cols])\n    \n    # Combine emphasized numerical and scaled SVD features into separate DataFrames for clarity\n    train_combined = train_df[all_numerical_cols + svd_cols + ['matched_score']].copy()\n    test_combined = test_df[all_numerical_cols + svd_cols].copy()\n    \n    return train_combined, test_combined\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\ndef cross_validate_model(train_df, features, target, params_hgb, params_gb, test_df, n_folds=5, random_state=42):\n    \"\"\"\n    Perform K-Fold Cross-Validation with HistGradientBoostingRegressor and GradientBoostingRegressor.\n    \n    Args:\n    - train_df (pd.DataFrame): Training data.\n    - features (list): List of feature column names.\n    - target (str): Target column name.\n    - params_hgb (dict): Parameters for HistGradientBoostingRegressor.\n    - params_gb (dict): Parameters for GradientBoostingRegressor.\n    - test_df (pd.DataFrame): Testing data (features only).\n    - n_folds (int): Number of folds for cross-validation.\n    - random_state (int): Random state for reproducibility.\n\n    Returns:\n    - final_test_preds (np.array): Averaged predictions for the test set.\n    - avg_mse (float): Average MSE across folds for both models.\n    \"\"\"\n    # Initialize KFold\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\n    # Initialize variables for predictions and metrics\n    oof_preds_hgb = np.zeros(len(train_df))\n    oof_preds_gb = np.zeros(len(train_df))\n    test_preds_hgb = np.zeros(len(test_df))\n    test_preds_gb = np.zeros(len(test_df))\n    fold_mses_hgb = []\n    fold_mses_gb = []\n\n    # Perform K-Fold Cross-Validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n        print(f'\\nTraining fold {fold + 1} / {n_folds}')\n        \n        # Split data into training and validation folds\n        X_train_fold = train_df.iloc[train_idx][features]\n        y_train_fold = train_df.iloc[train_idx][target]\n        X_val_fold = train_df.iloc[val_idx][features]\n        y_val_fold = train_df.iloc[val_idx][target]\n        \n        # Train HistGradientBoostingRegressor\n        hgb = HistGradientBoostingRegressor(**params_hgb)\n        hgb.fit(X_train_fold, y_train_fold)\n        y_pred_hgb = hgb.predict(X_val_fold)\n        mse_hgb = mean_squared_error(y_val_fold, y_pred_hgb)\n        fold_mses_hgb.append(mse_hgb)\n        print(f\"Fold {fold + 1} HistGradientBoostingRegressor MSE: {mse_hgb:.6f}\")\n        oof_preds_hgb[val_idx] = y_pred_hgb\n        \n        # Predict on test set\n        y_test_pred_hgb = hgb.predict(test_df[features])\n        test_preds_hgb += y_test_pred_hgb / n_folds\n        \n        # Train GradientBoostingRegressor\n        gb = GradientBoostingRegressor(**params_gb)\n        gb.fit(X_train_fold, y_train_fold)\n        y_pred_gb = gb.predict(X_val_fold)\n        mse_gb = mean_squared_error(y_val_fold, y_pred_gb)\n        fold_mses_gb.append(mse_gb)\n        print(f\"Fold {fold + 1} GradientBoostingRegressor MSE: {mse_gb:.6f}\")\n        oof_preds_gb[val_idx] = y_pred_gb\n        \n        # Predict on test set\n        y_test_pred_gb = gb.predict(test_df[features])\n        test_preds_gb += y_test_pred_gb / n_folds\n    \n    # Calculate average MSE\n    avg_mse_hgb = np.mean(fold_mses_hgb)\n    avg_mse_gb = np.mean(fold_mses_gb)\n    print(f\"\\nAverage HistGradientBoostingRegressor MSE: {avg_mse_hgb:.6f}\")\n    print(f\"Average GradientBoostingRegressor MSE: {avg_mse_gb:.6f}\")\n    \n    # Average predictions from both models\n    final_test_preds = (test_preds_hgb + test_preds_gb) / 2\n    \n    return final_test_preds, (avg_mse_hgb + avg_mse_gb) / 2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\nsample_submission = pd.read_csv(sample_sub_path)\n\nprint(\"Initial train shape:\", train_df.shape)\nprint(\"Initial test shape:\", test_df.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop columns >80% missing\ncol_threshold = 0.8\ncols_to_drop = [col for col in train_df.columns if train_df[col].isnull().mean() > col_threshold]\ntrain_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\ntest_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\nprint(\"Dropped columns:\", cols_to_drop)\n\n# Drop rows with <5 non-null in train\nrow_threshold = 5\nbefore_rows = len(train_df)\ntrain_df.dropna(thresh=row_threshold, axis=0, inplace=True)\nafter_rows = len(train_df)\nprint(f\"Dropped {before_rows - after_rows} rows with < {row_threshold} non-null columns.\")\n\nprint(\"Train shape after drops:\", train_df.shape)\nprint(\"Test shape after drops:\", test_df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nExtracting features...\")\nfor df in [train_df, test_df]:\n    df = extract_education_features(df)\n    df = extract_experience_features(df)\n    df = extract_skill_features(df)\n    df = extract_text_features(df)\n    df = create_interaction_features(df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train_df.head()\ntrain_df.info()\n#train_df['educational_institution_name']\nnumerical = train_df.select_dtypes(include=['int64', 'float64','int32', 'float32'])\nnumerical_cols = numerical.columns.tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['result_types'].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define categorical columns\ncategorical_cols = [\n    'educational_institution_name',\n    'major_field_of_studies',\n    'degree_names',\n    'result_types',\n    'professional_company_names',\n    'role_positions',\n    'certification_providers',\n    'extra_curricular_organization_names'\n]\n\n# Encode categorical features\ntrain_df, test_df = encode_categorical_features(train_df, test_df, categorical_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define text columns\ntext_cols = [\n    'career_objective',\n    'responsibilities',\n    'educationaL_requirements',\n    'related_skils_in_job',\n    'certification_skills',\n    'extra_curricular_activity_types',\n    'ï»¿job_position_name'\n]\n\n# Encode text features using TF-IDF and SVD\ntrain_df, test_df, svd_cols = extract_text_features_tf_idf_svd_scaled(\n    train_df, test_df, text_cols, max_features=500, n_components=70\n)\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_st,test_st=train_df,test_df\ntrain_st.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_st,test_st=train_df,test_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df,test_df=train_st,test_st\ntrain_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, test_df = emphasize_numerical_features(train_df, test_df, numerical_cols, svd_cols, weight_factor=20.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_cols = [col for col in numerical_cols if col != target_col]\noutlier_cols=numerical_cols+svd_cols\n#outlier_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndrop_cols = ['matched_score', 'ID']\ntarget_col='matched_score'\nfeature_cols = [\n    c for c in train_df.columns\n    if c not in drop_cols\n        and (train_df[c].dtype in [np.float64, np.int64, np.float32, np.int32])\n]\n\n\n\n# Fill missing numeric values\ntrain_df, test_df = prepare_features(train_df, test_df,numerical_cols)\noutlier_threshold = 3.0  # Define threshold for identifying outliers (z-score method)\n        \ndef handle_outliers(df, columns):\n    for col in columns:\n        if df[col].dtype in [np.float64, np.int64, np.float32, np.int32]:\n            # Calculate z-scores\n            z_scores = (df[col] - df[col].mean()) / df[col].std()\n            \n            # Winsorize extreme values (cap outliers)\n            upper_limit = df[col].mean() + outlier_threshold * df[col].std()\n            lower_limit = df[col].mean() - outlier_threshold * df[col].std()\n            \n            df[col] = np.clip(df[col], lower_limit, upper_limit)\n    return df\n\n\n# Apply outlier handling on both train and test sets\ntrain_df = handle_outliers(train_df, outlier_cols)\ntest_df = handle_outliers(test_df, outlier_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_st,test_st=train_df,test_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df,test_df=train_st,test_st\ntrain_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# def select_important_features(train_df, test_df, target, top_k=20):\n#     \"\"\"\n#     Select top `k` features based on importance using a random forest.\n#     \"\"\"\n#     # Split into features and target\n#     X_train = train_df.drop(columns=[target])\n#     y_train = train_df[target]\n    \n#     # Train a random forest to get feature importance\n#     model = RandomForestClassifier(random_state=42)\n#     model.fit(X_train, y_train)\n    \n#     # Get feature importance\n#     feature_importance = pd.Series(model.feature_importances_, index=X_train.columns)\n#     important_features = feature_importance.nlargest(top_k).index\n    \n#     # Filter top features\n#     train_df = train_df[important_features]\n#     test_df = test_df[important_features]\n    \n#     return train_df, test_df\n\n\n# Use Random Forest to estimate feature importance\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(train_df[feature_cols], train_df[target_col])\n\n# Feature importance\nfeature_importances = pd.Series(model.feature_importances_, index=feature_cols)\nprint(\"Feature Importances:\")\nprint(feature_importances)\n\n# Select features based on importance threshold\nimportant_features = feature_importances[feature_importances > 0.0002].index.tolist()\nprint(f\"Selected features: {len(important_features)} out of {len(feature_cols)}\")\n\n# Drop less important features\ntrain_df = train_df[important_features + [target_col]]\ntest_df = test_df[important_features]\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"md\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_st_imp,test_st_imp=train_df,test_df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_st_imp.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df,test_df=train_st_imp,test_st_imp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Define target and features\ntarget_col = 'matched_score'\nif target_col not in train_df.columns:\n    raise ValueError(f\"{target_col} not found in train_df columns!\")\n\n# Drop rows with missing target\ntrain_df = train_df.dropna(subset=[target_col])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train_df.copy()\ny = train_df[target_col].values\nX_test = test_df.copy()\n\n# Define feature columns\ndrop_cols = ['matched_score', 'ID']\nfeature_cols = [\n    c for c in train_df.columns\n    if c not in drop_cols\n        and (train_df[c].dtype in [np.float64, np.int64, np.float32, np.int32])\n]\nprint(f\"Total features: {len(feature_cols)}\")\n\n# Scale features\n\n# Scale features\nscaler = RobustScaler()\nX[feature_cols] = scaler.fit_transform(X[feature_cols])\nX_test[feature_cols] = scaler.transform(X_test[feature_cols])\n\n# scaler = StandardScaler()\n# X[feature_cols] = scaler.fit_transform(X[feature_cols])\n# X_test[feature_cols] = scaler.transform(X_test[feature_cols])\n\n# Re-assign after scaling\ntrain_df = X\ntest_df = X_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical = train_df.select_dtypes(include=['int64', 'float64'])\nnumerical_cols = numerical.columns\nCorrelation = numerical.corr()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_neural_network(input_dim):\n    \"\"\"\n    Create a denser Neural Network model for datasets with sufficient samples.\n    Args:\n    - input_dim (int): Number of input features.\n\n    Returns:\n    - model: Compiled Keras model.\n    \"\"\"\n    model = Sequential()\n\n    # First hidden layer\n    model.add(Dense(256, input_dim=input_dim))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.3))  # Higher dropout for denser layers\n\n    # Second hidden layer\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Third hidden layer\n    model.add(Dense(64))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Output layer\n    model.add(Dense(1, activation='linear'))  # Linear activation for regression\n\n    # Compile the model\n    model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='mse',\n        metrics=['mse']\n    )\n    \n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cross_validate_neural_network(train_df, features, target, test_df, n_folds=5, random_state=42):\n    \"\"\"\n    Perform K-Fold Cross-Validation with a Neural Network.\n    \n    Args:\n    - train_df (pd.DataFrame): Training data.\n    - features (list): List of feature column names.\n    - target (str): Target column name.\n    - test_df (pd.DataFrame): Testing data (features only).\n    - n_folds (int): Number of folds for cross-validation.\n    - random_state (int): Random state for reproducibility.\n\n    Returns:\n    - final_test_preds (np.array): Averaged predictions for the test set.\n    - avg_mse (float): Average MSE across folds.\n    \"\"\"\n    # Initialize KFold\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\n    # Initialize variables for predictions and metrics\n    oof_preds_nn = np.zeros(len(train_df))\n    test_preds_nn = np.zeros(len(test_df))\n    fold_mses_nn = []\n\n    # Perform K-Fold Cross-Validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n        print(f'\\nTraining fold {fold + 1} / {n_folds}')\n        \n        # Split data into training and validation folds\n        X_train_fold = train_df.iloc[train_idx][features].values\n        y_train_fold = train_df.iloc[train_idx][target].values\n        X_val_fold = train_df.iloc[val_idx][features].values\n        y_val_fold = train_df.iloc[val_idx][target].values\n\n        # Create Neural Network model\n        model = create_neural_network(input_dim=len(features))\n\n        # Early stopping\n        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n        # Train the model\n        model.fit(\n            X_train_fold, y_train_fold,\n            validation_data=(X_val_fold, y_val_fold),\n            epochs=200,\n            batch_size=32,\n            callbacks=[early_stopping],\n            verbose=1\n        )\n\n        # Predict on validation set\n        y_pred_nn = model.predict(X_val_fold).flatten()\n        mse_nn = mean_squared_error(y_val_fold, y_pred_nn)\n        fold_mses_nn.append(mse_nn)\n        print(f\"Fold {fold + 1} Neural Network MSE: {mse_nn:.6f}\")\n        oof_preds_nn[val_idx] = y_pred_nn\n\n        # Predict on test set\n        test_preds_nn += model.predict(test_df[features].values).flatten() / n_folds\n\n    # Calculate average MSE\n    avg_mse_nn = np.mean(fold_mses_nn)\n    print(f\"\\nAverage Neural Network MSE: {avg_mse_nn:.6f}\")\n    \n    return test_preds_nn, avg_mse_nn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n\n# Perform Cross-Validation\nprint(\"\\n========== Starting Cross-Validation with Neural Network ==========\")\ntest_preds_nn, mean_mse_nn = cross_validate_neural_network(\n    train_df, \n    feature_cols, \n    target_col, \n    test_df\n)\n\n# Clip predictions to valid range\ntest_preds_nn = np.clip(test_preds_nn, 0, 1)\n# Prepare submission\nprint(\"\\nPreparing Submission...\")\n\n# Check if 'ID' column exists, rename or create if necessary\nif 'ID' not in test_df.columns:\n    if 'id' in test_df.columns:\n        test_df.rename(columns={'id': 'ID'}, inplace=True)\n    elif 'identifier' in test_df.columns:\n        test_df.rename(columns={'identifier': 'ID'}, inplace=True)\n    else:\n        print(\"No 'ID' column found in test_df. Generating a sequential ID column...\")\n        test_df['ID'] = range(1, len(test_df) + 1)\n\n# Ensure sample_submission has matching 'ID' structure\nif 'ID' not in sample_submission.columns:\n    raise ValueError(\"Sample submission file does not contain 'ID' column. Please check the file structure.\")\n\noutput_path='/kaggle/working/submission_final_nn.csv'\nsubmission = sample_submission.copy()\nsubmission['matched_score'] = test_preds_nn\nsubmission.to_csv(output_path, index=False)\nprint(f\"Submission saved: {output_path}\")\nprint(f\"Final Average MSE: {mean_mse_nn:.6f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Correlation.iloc[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nparams_hgb = {\n    'loss': 'squared_error',\n    'max_iter': 300,\n    'learning_rate': 0.05,\n    'max_depth': 6,\n    'random_state': seed,\n    'n_iter_no_change': 50,       # Early stopping\n    'tol': 1e-4,                   # Tolerance for early stopping\n    'validation_fraction': 0.1,    # Fraction of data to use for early stopping\n    'verbose': 0                   # Silent\n}\nparams_gb = {\n    'n_estimators': 300,\n    'learning_rate': 0.05,\n    'max_depth': 6,\n    'random_state': seed,\n    'n_iter_no_change': 50,      # Early stopping\n    'tol': 1e-4,                 # Tolerance for early stopping\n    'validation_fraction': 0.1,  # Fraction of data to use for early stopping\n    'verbose': 0                 # Silent\n}\n\n# Perform Cross-Validation\nprint(\"\\n========== Starting Cross-Validation ==========\")\ntest_preds, mean_mse = cross_validate_model(\n    train_df, \n    feature_cols, \n    target_col, \n    params_hgb, \n    params_gb,\n    test_df\n)\n\n# Clip predictions to valid range\ntest_preds = np.clip(test_preds, 0, 1)\n# Prepare submission\nprint(\"\\nPreparing Submission...\")\n\n# Check if 'ID' column exists, rename or create if necessary\nif 'ID' not in test_df.columns:\n    if 'id' in test_df.columns:\n        test_df.rename(columns={'id': 'ID'}, inplace=True)\n    elif 'identifier' in test_df.columns:\n        test_df.rename(columns={'identifier': 'ID'}, inplace=True)\n    else:\n        print(\"No 'ID' column found in test_df. Generating a sequential ID column...\")\n        test_df['ID'] = range(1, len(test_df) + 1)\n\n# Ensure sample_submission has matching 'ID' structure\nif 'ID' not in sample_submission.columns:\n    raise ValueError(\"Sample submission file does not contain 'ID' column. Please check the file structure.\")\n\noutput_path='/kaggle/working/submission_final.csv'\nsubmission = sample_submission.copy()\nsubmission['matched_score'] = test_preds\nsubmission.to_csv(output_path, index=False)\nprint(f\"Submission saved: {output_path}\")\nprint(f\"Final Average MSE: {mean_mse:.6f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_path='/kaggle/working/submission_final.csv'\nsubmission.to_csv(output_path, index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\n\n# Open file for writing\nfile = open('submission.csv', 'w', encoding='utf-8')\nlog_file = open('log.csv', 'w', encoding='utf-8')\n\n# Create CSV writers\nsubmission_writer = csv.writer(file)\nlog_writer = csv.writer(log_file)\n\n# Write headers\nsubmission_writer.writerow(['ID', 'matched_score'])  # Assuming your DataFrame has these columns\nlog_writer.writerow(['ID', 'Agent ID', 'matched_score'])  # Example log file headers\n\n# Write submission content\nfor index, row in submission.iterrows():\n    submission_writer.writerow([row['ID'], row['matched_score']])  # Adjust columns as per your DataFrame\n    log_writer.writerow([row['ID'], 'Agent_X', row['matched_score']])  # Example log content\n\n# Close files\nfile.close()\nlog_file.close()\n\nprint(\"Submission and log files written successfully.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20,7))\n\nsns.heatmap(Correlation,\n            annot=True,\n            cmap='coolwarm',\n            fmt='.2f',\n            linewidths=0.5)\n\nplt.title('Correlation Matrix')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\n\ndef create_denser_neural_network(input_dim):\n    \"\"\"\n    Create a denser Neural Network model for datasets with sufficient samples.\n    Args:\n    - input_dim (int): Number of input features.\n\n    Returns:\n    - model: Compiled Keras model.\n    \"\"\"\n    model = Sequential()\n\n    # First hidden layer\n    model.add(Dense(256, input_dim=input_dim))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.3))  # Higher dropout for denser layers\n\n    # Second hidden layer\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Third hidden layer\n    model.add(Dense(64))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Output layer\n    model.add(Dense(1, activation='linear'))  # Linear activation for regression\n\n    # Compile the model\n    model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='mse',\n        metrics=['mse']\n    )\n    \n    return model\n\n\n\ndef cross_validate_neural_network(train_df, features, target, test_df, n_folds=5, random_state=42):\n    \"\"\"\n    Perform K-Fold Cross-Validation with a Neural Network.\n    \n    Args:\n    - train_df (pd.DataFrame): Training data.\n    - features (list): List of feature column names.\n    - target (str): Target column name.\n    - test_df (pd.DataFrame): Testing data (features only).\n    - n_folds (int): Number of folds for cross-validation.\n    - random_state (int): Random state for reproducibility.\n\n    Returns:\n    - final_test_preds (np.array): Averaged predictions for the test set.\n    - avg_mse (float): Average MSE across folds.\n    \"\"\"\n    # Initialize KFold\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\n    # Initialize variables for predictions and metrics\n    oof_preds_nn = np.zeros(len(train_df))\n    test_preds_nn = np.zeros(len(test_df))\n    fold_mses_nn = []\n\n    # Perform K-Fold Cross-Validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n        print(f'\\nTraining fold {fold + 1} / {n_folds}')\n        \n        # Split data into training and validation folds\n        X_train_fold = train_df.iloc[train_idx][features].values\n        y_train_fold = train_df.iloc[train_idx][target].values\n        X_val_fold = train_df.iloc[val_idx][features].values\n        y_val_fold = train_df.iloc[val_idx][target].values\n\n        # Create Neural Network model\n        model = create_neural_network(input_dim=len(features))\n\n        # Early stopping\n        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n        # Train the model\n        model.fit(\n            X_train_fold, y_train_fold,\n            validation_data=(X_val_fold, y_val_fold),\n            epochs=100,\n            batch_size=32,\n            callbacks=[early_stopping],\n            verbose=1\n        )\n\n        # Predict on validation set\n        y_pred_nn = model.predict(X_val_fold).flatten()\n        mse_nn = mean_squared_error(y_val_fold, y_pred_nn)\n        fold_mses_nn.append(mse_nn)\n        print(f\"Fold {fold + 1} Neural Network MSE: {mse_nn:.6f}\")\n        oof_preds_nn[val_idx] = y_pred_nn\n\n        # Predict on test set\n        test_preds_nn += model.predict(test_df[features].values).flatten() / n_folds\n\n    # Calculate average MSE\n    avg_mse_nn = np.mean(fold_mses_nn)\n    print(f\"\\nAverage Neural Network MSE: {avg_mse_nn:.6f}\")\n    \n    return test_preds_nn, avg_mse_nn\n\n\n# Perform Cross-Validation\nprint(\"\\n========== Starting Cross-Validation with Neural Network ==========\")\ntest_preds_nn, mean_mse_nn = cross_validate_neural_network(\n    train_df, \n    feature_cols, \n    target_col, \n    test_df\n)\n\n# Clip predictions to valid range\ntest_preds_nn = np.clip(test_preds_nn, 0, 1)\n\n# Prepare submission\nprint(\"\\nPreparing Submission...\")\nif 'ID' not in test_df.columns:\n    raise ValueError(\"Test dataset does not contain 'ID' column. Please adjust the identifier column name.\")\n\nsubmission = sample_submission.copy()\nsubmission['matched_score'] = test_preds_nn\nsubmission.to_csv(output_path, index=False)\nprint(f\"Submission saved: {output_path}\")\nprint(f\"Final Average MSE: {mean_mse_nn:.6f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}