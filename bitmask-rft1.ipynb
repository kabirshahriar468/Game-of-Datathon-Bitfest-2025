{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90798,"databundleVersionId":10606811,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:49:58.733121Z","iopub.execute_input":"2024-12-26T15:49:58.733453Z","iopub.status.idle":"2024-12-26T15:49:59.017074Z","shell.execute_reply.started":"2024-12-26T15:49:58.733421Z","shell.execute_reply":"2024-12-26T15:49:59.016409Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/bitfest-datathon-2025/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T12:12:45.634556Z","iopub.execute_input":"2024-12-26T12:12:45.634982Z","iopub.status.idle":"2024-12-26T12:12:45.802360Z","shell.execute_reply.started":"2024-12-26T12:12:45.634953Z","shell.execute_reply":"2024-12-26T12:12:45.801481Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T12:13:36.017862Z","iopub.execute_input":"2024-12-26T12:13:36.018207Z","iopub.status.idle":"2024-12-26T12:13:36.039254Z","shell.execute_reply.started":"2024-12-26T12:13:36.018181Z","shell.execute_reply":"2024-12-26T12:13:36.038216Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  address                                   career_objective  \\\n0     NaN  Big data analytics working and database wareho...   \n1     NaN  Fresher looking to join as a data analyst and ...   \n2     NaN                                                NaN   \n3     NaN  To obtain a position in a fast-paced business ...   \n4     NaN  Professional accountant with an outstanding wo...   \n\n                                              skills  \\\n0  ['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...   \n1  ['Data Analysis', 'Data Analytics', 'Business ...   \n2  ['Software Development', 'Machine Learning', '...   \n3  ['accounts payables', 'accounts receivables', ...   \n4  ['Analytical reasoning', 'Compliance testing k...   \n\n                        educational_institution_name  \\\n0  ['The Amity School of Engineering & Technology...   \n1  ['Delhi University - Hansraj College', 'Delhi ...   \n2    ['Birla Institute of Technology (BIT), Ranchi']   \n3  ['Martinez Adult Education, Business Training ...   \n4                          ['Kent State University']   \n\n                                        degree_names     passing_years  \\\n0                                         ['B.Tech']          ['2019']   \n1    ['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']  ['2015', '2018']   \n2                                         ['B.Tech']          ['2018']   \n3  ['Computer Applications Specialist Certificate...          ['2008']   \n4            ['Bachelor of Business Administration']            [None]   \n\n  educational_results    result_types             major_field_of_studies  \\\n0             ['N/A']          [None]                    ['Electronics']   \n1      ['N/A', 'N/A']  ['N/A', 'N/A']      ['Mathematics', 'Statistics']   \n2             ['N/A']         ['N/A']  ['Electronics/Telecommunication']   \n3              [None]          [None]          ['Computer Applications']   \n4            ['3.84']          [None]                     ['Accounting']   \n\n                          professional_company_names  ... online_links  \\\n0                                      ['Coca-COla']  ...          NaN   \n1                                ['BIB Consultancy']  ...          NaN   \n2                              ['Axis Bank Limited']  ...          NaN   \n3  ['Company Name ï¼ City , State', 'Company Name...  ...          NaN   \n4  ['Company Name', 'Company Name', 'Company Name...  ...       [None]   \n\n  issue_dates           expiry_dates  \\\n0         NaN                    NaN   \n1         NaN                    NaN   \n2         NaN                    NaN   \n3         NaN                    NaN   \n4      [None]  ['February 15, 2021']   \n\n                                  ﻿job_position_name  \\\n0                           Senior Software Engineer   \n1                     Machine Learning (ML) Engineer   \n2  Executive/ Senior Executive- Trade Marketing, ...   \n3                     Business Development Executive   \n4                                Senior iOS Engineer   \n\n                            educationaL_requirements experiencere_requirement  \\\n0  B.Sc in Computer Science & Engineering from a ...          At least 1 year   \n1  M.Sc in Computer Science & Engineering or in a...       At least 5 year(s)   \n2            Master of Business Administration (MBA)         At least 3 years   \n3                                    Bachelor/Honors             1 to 3 years   \n4      Bachelor of Science (BSc) in Computer Science         At least 4 years   \n\n      age_requirement                                 responsibilities.1  \\\n0                 NaN  Technical Support\\nTroubleshooting\\nCollaborat...   \n1                 NaN  Machine Learning Leadership\\nCross-Functional ...   \n2                 NaN  Trade Marketing Executive\\nBrand Visibility, S...   \n3  Age 22 to 30 years  Apparel Sourcing\\nQuality Garment Sourcing\\nRe...   \n4                 NaN  iOS Lifecycle\\nRequirement Analysis\\nNative Fr...   \n\n                                     skills_required matched_score  \n0                                                NaN      0.850000  \n1                                                NaN      0.750000  \n2  Brand Promotion\\nCampaign Management\\nField Su...      0.416667  \n3  Fast typing skill\\nIELTSInternet browsing & on...      0.760000  \n4  iOS\\niOS App Developer\\niOS Application Develo...      0.650000  \n\n[5 rows x 35 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>address</th>\n      <th>career_objective</th>\n      <th>skills</th>\n      <th>educational_institution_name</th>\n      <th>degree_names</th>\n      <th>passing_years</th>\n      <th>educational_results</th>\n      <th>result_types</th>\n      <th>major_field_of_studies</th>\n      <th>professional_company_names</th>\n      <th>...</th>\n      <th>online_links</th>\n      <th>issue_dates</th>\n      <th>expiry_dates</th>\n      <th>﻿job_position_name</th>\n      <th>educationaL_requirements</th>\n      <th>experiencere_requirement</th>\n      <th>age_requirement</th>\n      <th>responsibilities.1</th>\n      <th>skills_required</th>\n      <th>matched_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Big data analytics working and database wareho...</td>\n      <td>['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...</td>\n      <td>['The Amity School of Engineering &amp; Technology...</td>\n      <td>['B.Tech']</td>\n      <td>['2019']</td>\n      <td>['N/A']</td>\n      <td>[None]</td>\n      <td>['Electronics']</td>\n      <td>['Coca-COla']</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Senior Software Engineer</td>\n      <td>B.Sc in Computer Science &amp; Engineering from a ...</td>\n      <td>At least 1 year</td>\n      <td>NaN</td>\n      <td>Technical Support\\nTroubleshooting\\nCollaborat...</td>\n      <td>NaN</td>\n      <td>0.850000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>Fresher looking to join as a data analyst and ...</td>\n      <td>['Data Analysis', 'Data Analytics', 'Business ...</td>\n      <td>['Delhi University - Hansraj College', 'Delhi ...</td>\n      <td>['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']</td>\n      <td>['2015', '2018']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['Mathematics', 'Statistics']</td>\n      <td>['BIB Consultancy']</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Machine Learning (ML) Engineer</td>\n      <td>M.Sc in Computer Science &amp; Engineering or in a...</td>\n      <td>At least 5 year(s)</td>\n      <td>NaN</td>\n      <td>Machine Learning Leadership\\nCross-Functional ...</td>\n      <td>NaN</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['Software Development', 'Machine Learning', '...</td>\n      <td>['Birla Institute of Technology (BIT), Ranchi']</td>\n      <td>['B.Tech']</td>\n      <td>['2018']</td>\n      <td>['N/A']</td>\n      <td>['N/A']</td>\n      <td>['Electronics/Telecommunication']</td>\n      <td>['Axis Bank Limited']</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Executive/ Senior Executive- Trade Marketing, ...</td>\n      <td>Master of Business Administration (MBA)</td>\n      <td>At least 3 years</td>\n      <td>NaN</td>\n      <td>Trade Marketing Executive\\nBrand Visibility, S...</td>\n      <td>Brand Promotion\\nCampaign Management\\nField Su...</td>\n      <td>0.416667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>To obtain a position in a fast-paced business ...</td>\n      <td>['accounts payables', 'accounts receivables', ...</td>\n      <td>['Martinez Adult Education, Business Training ...</td>\n      <td>['Computer Applications Specialist Certificate...</td>\n      <td>['2008']</td>\n      <td>[None]</td>\n      <td>[None]</td>\n      <td>['Computer Applications']</td>\n      <td>['Company Name ï¼ City , State', 'Company Name...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Business Development Executive</td>\n      <td>Bachelor/Honors</td>\n      <td>1 to 3 years</td>\n      <td>Age 22 to 30 years</td>\n      <td>Apparel Sourcing\\nQuality Garment Sourcing\\nRe...</td>\n      <td>Fast typing skill\\nIELTSInternet browsing &amp; on...</td>\n      <td>0.760000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Professional accountant with an outstanding wo...</td>\n      <td>['Analytical reasoning', 'Compliance testing k...</td>\n      <td>['Kent State University']</td>\n      <td>['Bachelor of Business Administration']</td>\n      <td>[None]</td>\n      <td>['3.84']</td>\n      <td>[None]</td>\n      <td>['Accounting']</td>\n      <td>['Company Name', 'Company Name', 'Company Name...</td>\n      <td>...</td>\n      <td>[None]</td>\n      <td>[None]</td>\n      <td>['February 15, 2021']</td>\n      <td>Senior iOS Engineer</td>\n      <td>Bachelor of Science (BSc) in Computer Science</td>\n      <td>At least 4 years</td>\n      <td>NaN</td>\n      <td>iOS Lifecycle\\nRequirement Analysis\\nNative Fr...</td>\n      <td>iOS\\niOS App Developer\\niOS Application Develo...</td>\n      <td>0.650000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T12:15:07.979338Z","iopub.execute_input":"2024-12-26T12:15:07.979840Z","iopub.status.idle":"2024-12-26T12:15:08.015842Z","shell.execute_reply.started":"2024-12-26T12:15:07.979802Z","shell.execute_reply":"2024-12-26T12:15:08.014678Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7635 entries, 0 to 7634\nData columns (total 35 columns):\n #   Column                               Non-Null Count  Dtype  \n---  ------                               --------------  -----  \n 0   address                              633 non-null    object \n 1   career_objective                     3794 non-null   object \n 2   skills                               7592 non-null   object \n 3   educational_institution_name         7574 non-null   object \n 4   degree_names                         7574 non-null   object \n 5   passing_years                        7574 non-null   object \n 6   educational_results                  7574 non-null   object \n 7   result_types                         7574 non-null   object \n 8   major_field_of_studies               7574 non-null   object \n 9   professional_company_names           7568 non-null   object \n 10  company_urls                         7568 non-null   object \n 11  start_dates                          7568 non-null   object \n 12  end_dates                            7568 non-null   object \n 13  related_skils_in_job                 7568 non-null   object \n 14  positions                            7568 non-null   object \n 15  locations                            7568 non-null   object \n 16  responsibilities                     7635 non-null   object \n 17  extra_curricular_activity_types      2732 non-null   object \n 18  extra_curricular_organization_names  2732 non-null   object \n 19  extra_curricular_organization_links  2732 non-null   object \n 20  role_positions                       2732 non-null   object \n 21  languages                            569 non-null    object \n 22  proficiency_levels                   569 non-null    object \n 23  certification_providers              1587 non-null   object \n 24  certification_skills                 1587 non-null   object \n 25  online_links                         1587 non-null   object \n 26  issue_dates                          1587 non-null   object \n 27  expiry_dates                         1587 non-null   object \n 28  ﻿job_position_name                   7635 non-null   object \n 29  educationaL_requirements             7635 non-null   object \n 30  experiencere_requirement             6549 non-null   object \n 31  age_requirement                      4371 non-null   object \n 32  responsibilities.1                   7635 non-null   object \n 33  skills_required                      6264 non-null   object \n 34  matched_score                        7635 non-null   float64\ndtypes: float64(1), object(34)\nmemory usage: 2.0+ MB\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"np.array(train_df[:1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T12:17:27.712108Z","iopub.execute_input":"2024-12-26T12:17:27.712446Z","iopub.status.idle":"2024-12-26T12:17:27.719324Z","shell.execute_reply.started":"2024-12-26T12:17:27.712422Z","shell.execute_reply":"2024-12-26T12:17:27.718229Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([[nan,\n        'Big data analytics working and database warehouse manager with robust experience in handling all kinds of data. I have also used multiple cloud infrastructure services and am well acquainted with them. Currently in search of role that offers more of development.',\n        \"['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapreduce', 'Spark', 'Java', 'Machine Learning', 'Cloud', 'Hdfs', 'YARN', 'Core Java', 'Data Science', 'C++', 'Data Structures', 'DBMS', 'RDBMS', 'Informatica', 'Talend', 'Amazon Redshift', 'Microsoft Azure']\",\n        \"['The Amity School of Engineering & Technology (ASET), Noida']\",\n        \"['B.Tech']\", \"['2019']\", \"['N/A']\", '[None]', \"['Electronics']\",\n        \"['Coca-COla']\", '[None]', \"['Nov 2019']\", \"['Till Date']\",\n        \"[['Big Data']]\", \"['Big Data Analyst']\", \"['N/A']\",\n        'Technical Support\\nTroubleshooting\\nCollaboration\\nDocumentation\\nSystem Monitoring\\nSoftware Deployment\\nTraining & Mentorship\\nIndustry Trends\\nField Visits\\n\\n\\n\\n\\n',\n        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n        'Senior Software Engineer',\n        'B.Sc in Computer Science & Engineering from a reputed university.',\n        'At least 1 year', nan,\n        'Technical Support\\nTroubleshooting\\nCollaboration\\nDocumentation\\nSystem Monitoring\\nSoftware Deployment\\nTraining & Mentorship\\nIndustry Trends\\nField Visits\\n\\n\\n\\n\\n',\n        nan, 0.85]], dtype=object)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport ast\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:12.463778Z","iopub.execute_input":"2024-12-26T15:50:12.464067Z","iopub.status.idle":"2024-12-26T15:50:12.468195Z","shell.execute_reply.started":"2024-12-26T15:50:12.464045Z","shell.execute_reply":"2024-12-26T15:50:12.467121Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom xgboost import XGBRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:13.772661Z","iopub.execute_input":"2024-12-26T15:50:13.772940Z","iopub.status.idle":"2024-12-26T15:50:14.754085Z","shell.execute_reply.started":"2024-12-26T15:50:13.772921Z","shell.execute_reply":"2024-12-26T15:50:14.753468Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_path = \"/kaggle/input/bitfest-datathon-2025/train.csv\"\ntest_path = \"/kaggle/input/bitfest-datathon-2025/test.csv\"\nsample_sub_path = \"/kaggle/input/bitfest-datathon-2025/sample_submission.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\nsample_submission = pd.read_csv(sample_sub_path)\n\nprint(\"Initial train shape:\", train_df.shape)\nprint(\"Initial test shape:\", test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:16.807893Z","iopub.execute_input":"2024-12-26T15:50:16.808363Z","iopub.status.idle":"2024-12-26T15:50:17.179515Z","shell.execute_reply.started":"2024-12-26T15:50:16.808332Z","shell.execute_reply":"2024-12-26T15:50:17.178773Z"}},"outputs":[{"name":"stdout","text":"Initial train shape: (7635, 35)\nInitial test shape: (1909, 35)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"col_threshold = 0.8\ncols_to_drop = []\nfor col in train_df.columns:\n    missing_ratio = train_df[col].isnull().mean()\n    if missing_ratio > col_threshold:\n        cols_to_drop.append(col)\n\ntrain_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\ntest_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\nprint(\"Dropped columns:\", cols_to_drop)\n\n# B. Drop rows that have fewer than 5 non-null columns in train\nrow_threshold = 5\nbefore_rows = train_df.shape[0]\ntrain_df.dropna(thresh=row_threshold, axis=0, inplace=True)\nafter_rows = train_df.shape[0]\nprint(f\"Dropped {before_rows - after_rows} rows with < {row_threshold} non-null columns.\")\n\nprint(\"Train shape after drops:\", train_df.shape)\nprint(\"Test shape after drops (same columns):\", test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:24.358495Z","iopub.execute_input":"2024-12-26T15:50:24.358816Z","iopub.status.idle":"2024-12-26T15:50:24.419464Z","shell.execute_reply.started":"2024-12-26T15:50:24.358793Z","shell.execute_reply":"2024-12-26T15:50:24.418709Z"}},"outputs":[{"name":"stdout","text":"Dropped columns: ['address', 'languages', 'proficiency_levels']\nDropped 0 rows with < 5 non-null columns.\nTrain shape after drops: (7635, 32)\nTest shape after drops (same columns): (1909, 32)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def parse_list(list_str):\n    \"\"\"\n    Convert a string like \"['Hadoop', 'Python']\" to a Python list.\n    Return an empty list if invalid or NaN.\n    \"\"\"\n    if pd.isnull(list_str):\n        return []\n    try:\n        return ast.literal_eval(list_str)\n    except:\n        return []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:26.643800Z","iopub.execute_input":"2024-12-26T15:50:26.644133Z","iopub.status.idle":"2024-12-26T15:50:26.648479Z","shell.execute_reply.started":"2024-12-26T15:50:26.644093Z","shell.execute_reply":"2024-12-26T15:50:26.647614Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_df['skills'] = train_df['skills'].apply(parse_list)\ntest_df['skills'] = test_df['skills'].apply(parse_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:30.044063Z","iopub.execute_input":"2024-12-26T15:50:30.044467Z","iopub.status.idle":"2024-12-26T15:50:30.473788Z","shell.execute_reply.started":"2024-12-26T15:50:30.044437Z","shell.execute_reply":"2024-12-26T15:50:30.473078Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def extract_numeric_years(text):\n    \"\"\"\n    Extract the first integer found in a string, e.g. \"At least 3 years\" -> 3.\n    Returns None if no integer is found or text is NaN.\n    \"\"\"\n    if pd.isnull(text):\n        return None\n    match = re.search(r'(\\d+)', str(text))\n    if match:\n        return float(match.group(1))\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:32.512716Z","iopub.execute_input":"2024-12-26T15:50:32.513013Z","iopub.status.idle":"2024-12-26T15:50:32.517443Z","shell.execute_reply.started":"2024-12-26T15:50:32.512990Z","shell.execute_reply":"2024-12-26T15:50:32.516707Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_df['experience_required'] = train_df['experiencere_requirement'].apply(extract_numeric_years)\ntest_df['experience_required'] = test_df['experiencere_requirement'].apply(extract_numeric_years)\ntrain_df['age_required'] = train_df['age_requirement'].apply(extract_numeric_years)\ntest_df['age_required'] = test_df['age_requirement'].apply(extract_numeric_years)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:34.015603Z","iopub.execute_input":"2024-12-26T15:50:34.015893Z","iopub.status.idle":"2024-12-26T15:50:34.049639Z","shell.execute_reply.started":"2024-12-26T15:50:34.015871Z","shell.execute_reply":"2024-12-26T15:50:34.048954Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"text_cols = []\nfor col in [\n    'career_objective', \n    'responsibilities', \n    'responsibilities.1', \n    'skills_required'\n]:\n    if col in train_df.columns:\n        text_cols.append(col)\n\n# Fill missing text with empty string\nfor col in text_cols:\n    train_df[col] = train_df[col].fillna(\"\")\n    test_df[col] = test_df[col].fillna(\"\")\n\n# Create a combined text column\nif text_cols:\n    train_df['combined_text'] = train_df[text_cols].agg(' '.join, axis=1)\n    test_df['combined_text'] = test_df[text_cols].agg(' '.join, axis=1)\nelse:\n    train_df['combined_text'] = \"\"\n    test_df['combined_text'] = \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:36.617599Z","iopub.execute_input":"2024-12-26T15:50:36.617890Z","iopub.status.idle":"2024-12-26T15:50:36.678958Z","shell.execute_reply.started":"2024-12-26T15:50:36.617868Z","shell.execute_reply":"2024-12-26T15:50:36.678342Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"target_col = 'matched_score'\nif target_col not in train_df.columns:\n    raise ValueError(\"The target column 'matched_score' is missing in train_df!\")\n\n# We only keep rows in train_df that have a valid matched_score\ntrain_df = train_df.dropna(subset=[target_col])\n\n# Example feature set:\nfeature_cols = []\n# Add combined text if it exists\nif 'combined_text' in train_df.columns:\n    feature_cols.append('combined_text')\n\n# Add numeric features if they exist\nfor possible_num_col in ['experience_required', 'age_required']:\n    if possible_num_col in train_df.columns:\n        feature_cols.append(possible_num_col)\n\nprint(\"Feature columns to be used:\", feature_cols)\n\nX = train_df[feature_cols].copy()\ny = train_df[target_col].values\n\nX_test = test_df[feature_cols].copy()  # For final prediction\n\nprint(\"Final Train shape:\", X.shape, \"| Target shape:\", y.shape)\nprint(\"Final Test shape:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:40.363576Z","iopub.execute_input":"2024-12-26T15:50:40.363857Z","iopub.status.idle":"2024-12-26T15:50:40.394228Z","shell.execute_reply.started":"2024-12-26T15:50:40.363836Z","shell.execute_reply":"2024-12-26T15:50:40.393519Z"}},"outputs":[{"name":"stdout","text":"Feature columns to be used: ['combined_text', 'experience_required', 'age_required']\nFinal Train shape: (7635, 3) | Target shape: (7635,)\nFinal Test shape: (1909, 3)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\nprint(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:44.495909Z","iopub.execute_input":"2024-12-26T15:50:44.496191Z","iopub.status.idle":"2024-12-26T15:50:44.507438Z","shell.execute_reply.started":"2024-12-26T15:50:44.496169Z","shell.execute_reply":"2024-12-26T15:50:44.506550Z"}},"outputs":[{"name":"stdout","text":"X_train: (6108, 3) y_train: (6108,)\nX_val: (1527, 3) y_val: (1527,)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"text_feature = 'combined_text' if 'combined_text' in feature_cols else None\nnumeric_features = [col for col in ['experience_required', 'age_required'] if col in feature_cols]\n\nfrom sklearn.pipeline import FeatureUnion\n\n# TF-IDF sub-pipeline\ntext_transformer = TfidfVectorizer(\n    stop_words='english',\n    max_features=1000  # tune as needed\n)\n\n# Numeric sub-pipeline\nnumeric_transformer = Pipeline([\n    ('scaler', MinMaxScaler())\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:50:47.225446Z","iopub.execute_input":"2024-12-26T15:50:47.225758Z","iopub.status.idle":"2024-12-26T15:50:47.229969Z","shell.execute_reply.started":"2024-12-26T15:50:47.225736Z","shell.execute_reply":"2024-12-26T15:50:47.229259Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"transformers = []\nif text_feature:\n    transformers.append(\n        ('text', text_transformer, text_feature)\n    )\nif numeric_features:\n    transformers.append(\n        ('num', numeric_transformer, numeric_features)\n    )\n\npreprocessor = ColumnTransformer(\n    transformers=transformers,\n    remainder='drop'\n)\n\nbase_xgb = XGBRegressor(\n    objective='reg:squarederror',\n    random_state=42,\n    n_jobs=-1\n)\n\n# Build the full pipeline\nmodel_pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('regressor', base_xgb)\n])\n\nparam_grid = {\n    'regressor__n_estimators': [100, 300],\n    'regressor__learning_rate': [0.01, 0.05, 0.1],\n    'regressor__max_depth': [4, 5 ,6 ,7],\n    'regressor__subsample': [0.7, 0.8],\n    'regressor__colsample_bytree': [0.6, 0.8],\n    'regressor__gamma': [0.1, 0.3]\n}\n\ngrid_search = GridSearchCV(\n    estimator=model_pipeline,\n    param_grid=param_grid,\n    scoring='neg_mean_squared_error',  # or use another regression metric\n    cv=3,                              # 3-fold cross-validation\n    verbose=1,                         # show progress\n    n_jobs=-1                          # parallel\n)\n\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best Params from GridSearchCV:\", grid_search.best_params_)\nprint(\"Best Score (neg MSE) from GridSearchCV:\", grid_search.best_score_)\n\n# Retrieve the best estimator (pipeline)\nbest_model_pipeline = grid_search.best_estimator_\n\nmodel_pipeline.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T15:51:15.486555Z","iopub.execute_input":"2024-12-26T15:51:15.486864Z","iopub.status.idle":"2024-12-26T16:08:25.877474Z","shell.execute_reply.started":"2024-12-26T15:51:15.486840Z","shell.execute_reply":"2024-12-26T16:08:25.876523Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 192 candidates, totalling 576 fits\nBest Params from GridSearchCV: {'regressor__colsample_bytree': 0.6, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 7, 'regressor__n_estimators': 300, 'regressor__subsample': 0.7}\nBest Score (neg MSE) from GridSearchCV: -0.01529776913218755\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('text',\n                                                  TfidfVectorizer(max_features=1000,\n                                                                  stop_words='english'),\n                                                  'combined_text'),\n                                                 ('num',\n                                                  Pipeline(steps=[('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['experience_required',\n                                                   'age_required'])])),\n                ('regressor',\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=N...\n                              feature_types=None, gamma=None, grow_policy=None,\n                              importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_threshold=None,\n                              max_cat_to_onehot=None, max_delta_step=None,\n                              max_depth=None, max_leaves=None,\n                              min_child_weight=None, missing=nan,\n                              monotone_constraints=None, multi_strategy=None,\n                              n_estimators=None, n_jobs=-1,\n                              num_parallel_tree=None, random_state=42, ...))])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                  TfidfVectorizer(max_features=1000,\n                                                                  stop_words=&#x27;english&#x27;),\n                                                  &#x27;combined_text&#x27;),\n                                                 (&#x27;num&#x27;,\n                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n                                                                   MinMaxScaler())]),\n                                                  [&#x27;experience_required&#x27;,\n                                                   &#x27;age_required&#x27;])])),\n                (&#x27;regressor&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=N...\n                              feature_types=None, gamma=None, grow_policy=None,\n                              importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_threshold=None,\n                              max_cat_to_onehot=None, max_delta_step=None,\n                              max_depth=None, max_leaves=None,\n                              min_child_weight=None, missing=nan,\n                              monotone_constraints=None, multi_strategy=None,\n                              n_estimators=None, n_jobs=-1,\n                              num_parallel_tree=None, random_state=42, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                  TfidfVectorizer(max_features=1000,\n                                                                  stop_words=&#x27;english&#x27;),\n                                                  &#x27;combined_text&#x27;),\n                                                 (&#x27;num&#x27;,\n                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n                                                                   MinMaxScaler())]),\n                                                  [&#x27;experience_required&#x27;,\n                                                   &#x27;age_required&#x27;])])),\n                (&#x27;regressor&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=N...\n                              feature_types=None, gamma=None, grow_policy=None,\n                              importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_threshold=None,\n                              max_cat_to_onehot=None, max_delta_step=None,\n                              max_depth=None, max_leaves=None,\n                              min_child_weight=None, missing=nan,\n                              monotone_constraints=None, multi_strategy=None,\n                              n_estimators=None, n_jobs=-1,\n                              num_parallel_tree=None, random_state=42, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                 TfidfVectorizer(max_features=1000,\n                                                 stop_words=&#x27;english&#x27;),\n                                 &#x27;combined_text&#x27;),\n                                (&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler())]),\n                                 [&#x27;experience_required&#x27;, &#x27;age_required&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>combined_text</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;experience_required&#x27;, &#x27;age_required&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=-1,\n             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"y_val_pred = best_model_pipeline.predict(X_val)\nmse = mean_squared_error(y_val, y_val_pred)\n\nprint(\"Validation MSE:\", mse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T16:15:24.602897Z","iopub.execute_input":"2024-12-26T16:15:24.603308Z","iopub.status.idle":"2024-12-26T16:15:24.703743Z","shell.execute_reply.started":"2024-12-26T16:15:24.603259Z","shell.execute_reply":"2024-12-26T16:15:24.702572Z"}},"outputs":[{"name":"stdout","text":"Validation MSE: 0.015543610125751516\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"test_predictions = best_model_pipeline.predict(X_test)\ntest_predictions = np.clip(test_predictions, 0.0, 1.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = sample_submission.copy()\nsubmission['matched_score'] = test_predictions\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission saved: submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T13:12:41.131180Z","iopub.execute_input":"2024-12-26T13:12:41.131558Z","iopub.status.idle":"2024-12-26T13:12:48.626563Z","shell.execute_reply.started":"2024-12-26T13:12:41.131528Z","shell.execute_reply":"2024-12-26T13:12:48.624871Z"}},"outputs":[{"name":"stdout","text":"Feature columns to be used: ['combined_text', 'experience_required', 'age_required']\nFinal Train shape: (7635, 3) | Target shape: (7635,)\nFinal Test shape: (1909, 3)\nX_train: (6108, 3) y_train: (6108,)\nX_val: (1527, 3) y_val: (1527,)\nValidation MSE: 0.01524988920784002\nValidation RMSE: 0.12349044176712634\nValidation R2: 0.41917438083744785\nSubmission saved: submission.csv\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T13:15:46.647750Z","iopub.execute_input":"2024-12-26T13:15:46.648145Z","iopub.status.idle":"2024-12-26T13:15:46.697780Z","shell.execute_reply.started":"2024-12-26T13:15:46.648119Z","shell.execute_reply":"2024-12-26T13:15:46.696421Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"                                       career_objective  \\\n0     Big data analytics working and database wareho...   \n1     Fresher looking to join as a data analyst and ...   \n2                                                         \n3     To obtain a position in a fast-paced business ...   \n4     Professional accountant with an outstanding wo...   \n...                                                 ...   \n7630  Dedicated and well-rounded software engineer w...   \n7631  Want to work as a Machine Learning Production ...   \n7632  Software developer focused in the areas of Mac...   \n7633                                                      \n7634                                                      \n\n                                                 skills  \\\n0     [Big Data, Hadoop, Hive, Python, Mapreduce, Sp...   \n1     [Data Analysis, Data Analytics, Business Analy...   \n2     [Software Development, Machine Learning, Deep ...   \n3     [accounts payables, accounts receivables, Acco...   \n4     [Analytical reasoning, Compliance testing know...   \n...                                                 ...   \n7630  [HTML, CSS, JavaScript (Angular), Python, Git,...   \n7631  [Machine Learning Engineer, Data Analyst, Natu...   \n7632  [Software Engineer, Data Analyst, Machine Lear...   \n7633  [Accounting, Accounting Software, Accounts Pay...   \n7634  [Electronic & Mechanical Technology, Maintenan...   \n\n                           educational_institution_name  \\\n0     ['The Amity School of Engineering & Technology...   \n1     ['Delhi University - Hansraj College', 'Delhi ...   \n2       ['Birla Institute of Technology (BIT), Ranchi']   \n3     ['Martinez Adult Education, Business Training ...   \n4                             ['Kent State University']   \n...                                                 ...   \n7630  ['Princeton International School of Mathematic...   \n7631                   ['AMIT, Bijnor', 'KVIT, Pilani']   \n7632           ['Dr. Jagjiban Rao Engineering College']   \n7633  ['University of Kerala', 'Mahatma Gandhi Unive...   \n7634  ['Eastern New Mexico University', 'Embry-Riddl...   \n\n                                           degree_names  \\\n0                                            ['B.Tech']   \n1       ['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']   \n2                                            ['B.Tech']   \n3     ['Computer Applications Specialist Certificate...   \n4               ['Bachelor of Business Administration']   \n...                                                 ...   \n7630       ['Master of Science', 'Bachelor of Science']   \n7631                               ['B.Tech', 'M.Tech']   \n7632                                         ['B.Tech']   \n7633  ['M.Com (Master of Commerce)', 'B.Com (Bachelo...   \n7634  ['MBA', 'Bachelor of Science', 'Associate of S...   \n\n                 passing_years       educational_results  \\\n0                     ['2019']                   ['N/A']   \n1             ['2015', '2018']            ['N/A', 'N/A']   \n2                     ['2018']                   ['N/A']   \n3                     ['2008']                    [None]   \n4                       [None]                  ['3.84']   \n...                        ...                       ...   \n7630          ['2015', '2012']            ['N/A', 'N/A']   \n7631           ['2017', 'N/A']  ['N/A', 'Gold Medalist']   \n7632                  ['2019']                    [None]   \n7633            ['N/A', 'N/A']            ['N/A', 'N/A']   \n7634  ['2015', '2008', '2004']     ['N/A', 'N/A', 'N/A']   \n\n               result_types  \\\n0                    [None]   \n1            ['N/A', 'N/A']   \n2                   ['N/A']   \n3                    [None]   \n4                    [None]   \n...                     ...   \n7630           [None, None]   \n7631         ['N/A', 'N/A']   \n7632                 [None]   \n7633         ['N/A', 'N/A']   \n7634  ['N/A', 'N/A', 'N/A']   \n\n                                 major_field_of_studies  \\\n0                                       ['Electronics']   \n1                         ['Mathematics', 'Statistics']   \n2                     ['Electronics/Telecommunication']   \n3                             ['Computer Applications']   \n4                                        ['Accounting']   \n...                                                 ...   \n7630           ['Computer Science', 'Computer Science']   \n7631  ['Electronics/Telecommunication', 'Advanced An...   \n7632                                            ['ECE']   \n7633                                     ['N/A', 'N/A']   \n7634  ['N/A', 'Professional Aeronautics', 'Airframe ...   \n\n                             professional_company_names  \\\n0                                         ['Coca-COla']   \n1                                   ['BIB Consultancy']   \n2                                 ['Axis Bank Limited']   \n3     ['Company Name ï¼ City , State', 'Company Name...   \n4     ['Company Name', 'Company Name', 'Company Name...   \n...                                                 ...   \n7630  ['Princeton International School of Mathematic...   \n7631                                ['Larsen & Toubro']   \n7632                       ['KLP Technology Solutions']   \n7633  ['Company Name', 'Company Name', 'Company Name...   \n7634   ['Company Name', 'Company Name', 'Company Name']   \n\n                              company_urls  ...  \\\n0                                   [None]  ...   \n1                                  ['N/A']  ...   \n2                                  ['N/A']  ...   \n3     [None, None, None, None, None, None]  ...   \n4           [None, None, None, None, None]  ...   \n...                                    ...  ...   \n7630                 ['N/A', 'N/A', 'N/A']  ...   \n7631                                [None]  ...   \n7632                                [None]  ...   \n7633              [None, None, None, None]  ...   \n7634                    [None, None, None]  ...   \n\n                                     ﻿job_position_name  \\\n0                              Senior Software Engineer   \n1                        Machine Learning (ML) Engineer   \n2     Executive/ Senior Executive- Trade Marketing, ...   \n3                        Business Development Executive   \n4                                   Senior iOS Engineer   \n...                                                 ...   \n7630  Head of Internal Control & Compliance (ICC) - ...   \n7631                                      Data Engineer   \n7632                           Network Support Engineer   \n7633                                Mechanical Engineer   \n7634                                Mechanical Engineer   \n\n                               educationaL_requirements  \\\n0     B.Sc in Computer Science & Engineering from a ...   \n1     M.Sc in Computer Science & Engineering or in a...   \n2               Master of Business Administration (MBA)   \n3                                       Bachelor/Honors   \n4         Bachelor of Science (BSc) in Computer Science   \n...                                                 ...   \n7630  Masters, Master of Business Administration (MB...   \n7631                          Bachelor of Science (BSc)   \n7632                           Diploma, Bachelor/Honors   \n7633  Bachelor of Science (BSc) in Mechanical Engine...   \n7634  Bachelor of Science (BSc) in Mechanical Engine...   \n\n     experiencere_requirement       age_requirement  \\\n0             At least 1 year                   NaN   \n1          At least 5 year(s)                   NaN   \n2            At least 3 years                   NaN   \n3                1 to 3 years    Age 22 to 30 years   \n4            At least 4 years                   NaN   \n...                       ...                   ...   \n7630        At least 15 years  Age at most 52 years   \n7631             5 to 8 years                   NaN   \n7632         At least 3 years    Age 25 to 35 years   \n7633             2 to 5 years    Age 25 to 40 years   \n7634             2 to 5 years    Age 25 to 40 years   \n\n                                     responsibilities.1  \\\n0     Technical Support\\nTroubleshooting\\nCollaborat...   \n1     Machine Learning Leadership\\nCross-Functional ...   \n2     Trade Marketing Executive\\nBrand Visibility, S...   \n3     Apparel Sourcing\\nQuality Garment Sourcing\\nRe...   \n4     iOS Lifecycle\\nRequirement Analysis\\nNative Fr...   \n...                                                 ...   \n7630  15+ Years Banking Experience\\nAudit/Inspection...   \n7631  Data Platform Design\\nData Pipeline Developmen...   \n7632  Mikrotik Router Configuration\\nOLT Device Setu...   \n7633  Machinery Maintenance\\nTroubleshooting\\nReport...   \n7634  Machinery Maintenance\\nTroubleshooting\\nReport...   \n\n                                        skills_required matched_score  \\\n0                                                            0.850000   \n1                                                            0.750000   \n2     Brand Promotion\\nCampaign Management\\nField Su...      0.416667   \n3     Fast typing skill\\nIELTSInternet browsing & on...      0.760000   \n4     iOS\\niOS App Developer\\niOS Application Develo...      0.650000   \n...                                                 ...           ...   \n7630      AUDIT AND INSPECTION\\nBanking\\nInternal Audit      0.643333   \n7631  Azure\\nBig Data\\nData Analytics\\nETL Tools\\nPo...      0.650000   \n7632  CCNA (Cisco Certified Network Associate)\\nGPON...      0.760000   \n7633       Maintenance  and Troubleshooting\\nMechanical      0.350000   \n7634       Maintenance  and Troubleshooting\\nMechanical      0.716667   \n\n     experience_required age_required  \\\n0                    1.0          NaN   \n1                    5.0          NaN   \n2                    3.0          NaN   \n3                    1.0         22.0   \n4                    4.0          NaN   \n...                  ...          ...   \n7630                15.0         52.0   \n7631                 5.0          NaN   \n7632                 3.0         25.0   \n7633                 2.0         25.0   \n7634                 2.0         25.0   \n\n                                          combined_text  \n0     Big data analytics working and database wareho...  \n1     Fresher looking to join as a data analyst and ...  \n2      Trade Marketing Executive\\nBrand Visibility, ...  \n3     To obtain a position in a fast-paced business ...  \n4     Professional accountant with an outstanding wo...  \n...                                                 ...  \n7630  Dedicated and well-rounded software engineer w...  \n7631  Want to work as a Machine Learning Production ...  \n7632  Software developer focused in the areas of Mac...  \n7633   Machinery Maintenance\\nTroubleshooting\\nRepor...  \n7634   Machinery Maintenance\\nTroubleshooting\\nRepor...  \n\n[7635 rows x 35 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>career_objective</th>\n      <th>skills</th>\n      <th>educational_institution_name</th>\n      <th>degree_names</th>\n      <th>passing_years</th>\n      <th>educational_results</th>\n      <th>result_types</th>\n      <th>major_field_of_studies</th>\n      <th>professional_company_names</th>\n      <th>company_urls</th>\n      <th>...</th>\n      <th>﻿job_position_name</th>\n      <th>educationaL_requirements</th>\n      <th>experiencere_requirement</th>\n      <th>age_requirement</th>\n      <th>responsibilities.1</th>\n      <th>skills_required</th>\n      <th>matched_score</th>\n      <th>experience_required</th>\n      <th>age_required</th>\n      <th>combined_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Big data analytics working and database wareho...</td>\n      <td>[Big Data, Hadoop, Hive, Python, Mapreduce, Sp...</td>\n      <td>['The Amity School of Engineering &amp; Technology...</td>\n      <td>['B.Tech']</td>\n      <td>['2019']</td>\n      <td>['N/A']</td>\n      <td>[None]</td>\n      <td>['Electronics']</td>\n      <td>['Coca-COla']</td>\n      <td>[None]</td>\n      <td>...</td>\n      <td>Senior Software Engineer</td>\n      <td>B.Sc in Computer Science &amp; Engineering from a ...</td>\n      <td>At least 1 year</td>\n      <td>NaN</td>\n      <td>Technical Support\\nTroubleshooting\\nCollaborat...</td>\n      <td></td>\n      <td>0.850000</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>Big data analytics working and database wareho...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fresher looking to join as a data analyst and ...</td>\n      <td>[Data Analysis, Data Analytics, Business Analy...</td>\n      <td>['Delhi University - Hansraj College', 'Delhi ...</td>\n      <td>['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']</td>\n      <td>['2015', '2018']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['Mathematics', 'Statistics']</td>\n      <td>['BIB Consultancy']</td>\n      <td>['N/A']</td>\n      <td>...</td>\n      <td>Machine Learning (ML) Engineer</td>\n      <td>M.Sc in Computer Science &amp; Engineering or in a...</td>\n      <td>At least 5 year(s)</td>\n      <td>NaN</td>\n      <td>Machine Learning Leadership\\nCross-Functional ...</td>\n      <td></td>\n      <td>0.750000</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>Fresher looking to join as a data analyst and ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>[Software Development, Machine Learning, Deep ...</td>\n      <td>['Birla Institute of Technology (BIT), Ranchi']</td>\n      <td>['B.Tech']</td>\n      <td>['2018']</td>\n      <td>['N/A']</td>\n      <td>['N/A']</td>\n      <td>['Electronics/Telecommunication']</td>\n      <td>['Axis Bank Limited']</td>\n      <td>['N/A']</td>\n      <td>...</td>\n      <td>Executive/ Senior Executive- Trade Marketing, ...</td>\n      <td>Master of Business Administration (MBA)</td>\n      <td>At least 3 years</td>\n      <td>NaN</td>\n      <td>Trade Marketing Executive\\nBrand Visibility, S...</td>\n      <td>Brand Promotion\\nCampaign Management\\nField Su...</td>\n      <td>0.416667</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>Trade Marketing Executive\\nBrand Visibility, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To obtain a position in a fast-paced business ...</td>\n      <td>[accounts payables, accounts receivables, Acco...</td>\n      <td>['Martinez Adult Education, Business Training ...</td>\n      <td>['Computer Applications Specialist Certificate...</td>\n      <td>['2008']</td>\n      <td>[None]</td>\n      <td>[None]</td>\n      <td>['Computer Applications']</td>\n      <td>['Company Name ï¼ City , State', 'Company Name...</td>\n      <td>[None, None, None, None, None, None]</td>\n      <td>...</td>\n      <td>Business Development Executive</td>\n      <td>Bachelor/Honors</td>\n      <td>1 to 3 years</td>\n      <td>Age 22 to 30 years</td>\n      <td>Apparel Sourcing\\nQuality Garment Sourcing\\nRe...</td>\n      <td>Fast typing skill\\nIELTSInternet browsing &amp; on...</td>\n      <td>0.760000</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>To obtain a position in a fast-paced business ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Professional accountant with an outstanding wo...</td>\n      <td>[Analytical reasoning, Compliance testing know...</td>\n      <td>['Kent State University']</td>\n      <td>['Bachelor of Business Administration']</td>\n      <td>[None]</td>\n      <td>['3.84']</td>\n      <td>[None]</td>\n      <td>['Accounting']</td>\n      <td>['Company Name', 'Company Name', 'Company Name...</td>\n      <td>[None, None, None, None, None]</td>\n      <td>...</td>\n      <td>Senior iOS Engineer</td>\n      <td>Bachelor of Science (BSc) in Computer Science</td>\n      <td>At least 4 years</td>\n      <td>NaN</td>\n      <td>iOS Lifecycle\\nRequirement Analysis\\nNative Fr...</td>\n      <td>iOS\\niOS App Developer\\niOS Application Develo...</td>\n      <td>0.650000</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>Professional accountant with an outstanding wo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7630</th>\n      <td>Dedicated and well-rounded software engineer w...</td>\n      <td>[HTML, CSS, JavaScript (Angular), Python, Git,...</td>\n      <td>['Princeton International School of Mathematic...</td>\n      <td>['Master of Science', 'Bachelor of Science']</td>\n      <td>['2015', '2012']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>[None, None]</td>\n      <td>['Computer Science', 'Computer Science']</td>\n      <td>['Princeton International School of Mathematic...</td>\n      <td>['N/A', 'N/A', 'N/A']</td>\n      <td>...</td>\n      <td>Head of Internal Control &amp; Compliance (ICC) - ...</td>\n      <td>Masters, Master of Business Administration (MB...</td>\n      <td>At least 15 years</td>\n      <td>Age at most 52 years</td>\n      <td>15+ Years Banking Experience\\nAudit/Inspection...</td>\n      <td>AUDIT AND INSPECTION\\nBanking\\nInternal Audit</td>\n      <td>0.643333</td>\n      <td>15.0</td>\n      <td>52.0</td>\n      <td>Dedicated and well-rounded software engineer w...</td>\n    </tr>\n    <tr>\n      <th>7631</th>\n      <td>Want to work as a Machine Learning Production ...</td>\n      <td>[Machine Learning Engineer, Data Analyst, Natu...</td>\n      <td>['AMIT, Bijnor', 'KVIT, Pilani']</td>\n      <td>['B.Tech', 'M.Tech']</td>\n      <td>['2017', 'N/A']</td>\n      <td>['N/A', 'Gold Medalist']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['Electronics/Telecommunication', 'Advanced An...</td>\n      <td>['Larsen &amp; Toubro']</td>\n      <td>[None]</td>\n      <td>...</td>\n      <td>Data Engineer</td>\n      <td>Bachelor of Science (BSc)</td>\n      <td>5 to 8 years</td>\n      <td>NaN</td>\n      <td>Data Platform Design\\nData Pipeline Developmen...</td>\n      <td>Azure\\nBig Data\\nData Analytics\\nETL Tools\\nPo...</td>\n      <td>0.650000</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>Want to work as a Machine Learning Production ...</td>\n    </tr>\n    <tr>\n      <th>7632</th>\n      <td>Software developer focused in the areas of Mac...</td>\n      <td>[Software Engineer, Data Analyst, Machine Lear...</td>\n      <td>['Dr. Jagjiban Rao Engineering College']</td>\n      <td>['B.Tech']</td>\n      <td>['2019']</td>\n      <td>[None]</td>\n      <td>[None]</td>\n      <td>['ECE']</td>\n      <td>['KLP Technology Solutions']</td>\n      <td>[None]</td>\n      <td>...</td>\n      <td>Network Support Engineer</td>\n      <td>Diploma, Bachelor/Honors</td>\n      <td>At least 3 years</td>\n      <td>Age 25 to 35 years</td>\n      <td>Mikrotik Router Configuration\\nOLT Device Setu...</td>\n      <td>CCNA (Cisco Certified Network Associate)\\nGPON...</td>\n      <td>0.760000</td>\n      <td>3.0</td>\n      <td>25.0</td>\n      <td>Software developer focused in the areas of Mac...</td>\n    </tr>\n    <tr>\n      <th>7633</th>\n      <td></td>\n      <td>[Accounting, Accounting Software, Accounts Pay...</td>\n      <td>['University of Kerala', 'Mahatma Gandhi Unive...</td>\n      <td>['M.Com (Master of Commerce)', 'B.Com (Bachelo...</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['N/A', 'N/A']</td>\n      <td>['Company Name', 'Company Name', 'Company Name...</td>\n      <td>[None, None, None, None]</td>\n      <td>...</td>\n      <td>Mechanical Engineer</td>\n      <td>Bachelor of Science (BSc) in Mechanical Engine...</td>\n      <td>2 to 5 years</td>\n      <td>Age 25 to 40 years</td>\n      <td>Machinery Maintenance\\nTroubleshooting\\nReport...</td>\n      <td>Maintenance  and Troubleshooting\\nMechanical</td>\n      <td>0.350000</td>\n      <td>2.0</td>\n      <td>25.0</td>\n      <td>Machinery Maintenance\\nTroubleshooting\\nRepor...</td>\n    </tr>\n    <tr>\n      <th>7634</th>\n      <td></td>\n      <td>[Electronic &amp; Mechanical Technology, Maintenan...</td>\n      <td>['Eastern New Mexico University', 'Embry-Riddl...</td>\n      <td>['MBA', 'Bachelor of Science', 'Associate of S...</td>\n      <td>['2015', '2008', '2004']</td>\n      <td>['N/A', 'N/A', 'N/A']</td>\n      <td>['N/A', 'N/A', 'N/A']</td>\n      <td>['N/A', 'Professional Aeronautics', 'Airframe ...</td>\n      <td>['Company Name', 'Company Name', 'Company Name']</td>\n      <td>[None, None, None]</td>\n      <td>...</td>\n      <td>Mechanical Engineer</td>\n      <td>Bachelor of Science (BSc) in Mechanical Engine...</td>\n      <td>2 to 5 years</td>\n      <td>Age 25 to 40 years</td>\n      <td>Machinery Maintenance\\nTroubleshooting\\nReport...</td>\n      <td>Maintenance  and Troubleshooting\\nMechanical</td>\n      <td>0.716667</td>\n      <td>2.0</td>\n      <td>25.0</td>\n      <td>Machinery Maintenance\\nTroubleshooting\\nRepor...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7635 rows × 35 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport ast\nimport re\nfrom datetime import datetime\nfrom dateutil import parser\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\n# =========================================================\n# 1. READ & BASIC CLEANING\n#    Update file paths for your Kaggle environment\n# =========================================================\ntrain_path = \"/kaggle/input/bitfest-datathon-2025/train.csv\"\ntest_path = \"/kaggle/input/bitfest-datathon-2025/test.csv\"\nsample_sub_path = \"/kaggle/input/bitfest-datathon-2025/sample_submission.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\nsample_submission = pd.read_csv(sample_sub_path)\n\nprint(\"Initial train shape:\", train_df.shape)\nprint(\"Initial test shape:\", test_df.shape)\n\n# Drop columns >80% missing\ncol_threshold = 0.8\ncols_to_drop = []\nnum_rows = len(train_df)\nfor col in train_df.columns:\n    if train_df[col].isnull().mean() > col_threshold:\n        cols_to_drop.append(col)\n\ntrain_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\ntest_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\nprint(\"Dropped columns:\", cols_to_drop)\n\n# Drop rows with <5 non-null in train\nrow_threshold = 5\nbefore_rows = len(train_df)\ntrain_df.dropna(thresh=row_threshold, axis=0, inplace=True)\nafter_rows = len(train_df)\nprint(f\"Dropped {before_rows - after_rows} rows with < {row_threshold} non-null columns.\")\n\nprint(\"Train shape after drops:\", train_df.shape)\nprint(\"Test shape after drops:\", test_df.shape)\n\n# =========================================================\n# 2. ADVANCED FEATURE ENGINEERING\n# =========================================================\n\n# ----------------------------\n# A) Parse skills, skills_required => skill overlap\n# ----------------------------\ndef parse_list(x):\n    if pd.isnull(x):\n        return []\n    try:\n        return ast.literal_eval(x)\n    except:\n        return []\n\nfor col in ['skills','skills_required']:\n    if col in train_df.columns:\n        train_df[col] = train_df[col].apply(parse_list)\n    if col in test_df.columns:\n        test_df[col] = test_df[col].apply(parse_list)\n\ndef skill_overlap(row):\n    candidate = set(row['skills']) if 'skills' in row else set()\n    required  = set(row['skills_required']) if 'skills_required' in row else set()\n    if not candidate or not required:\n        return 0.0\n    inter = candidate.intersection(required)\n    union = candidate.union(required)\n    return len(inter) / len(union) if union else 0.0\n\nif all(c in train_df.columns for c in ['skills','skills_required']):\n    train_df['skill_overlap'] = train_df.apply(skill_overlap, axis=1)\n    test_df['skill_overlap']  = test_df.apply(skill_overlap, axis=1)\nelse:\n    train_df['skill_overlap'] = 0.0\n    test_df['skill_overlap']  = 0.0\n\n# ----------------------------\n# B) Parse start_dates / end_dates => total months of experience\n#    e.g. \"Nov 2019\" => dateutil parser\n#    If end_date says \"Till Date\", consider today's date as a fallback\n# ----------------------------\ndef parse_date(date_str):\n    if pd.isnull(date_str):\n        return None\n    # handle \"Till Date\" or \"Present\" etc.\n    if any(word.lower() in str(date_str).lower() for word in ['till','present']):\n        return datetime.now()\n    try:\n        return parser.parse(str(date_str))\n    except:\n        return None\n\ndef calc_months_of_exp(start_str, end_str):\n    start = parse_date(start_str)\n    end   = parse_date(end_str)\n    if start is None or end is None:\n        return 0\n    # difference in months\n    diff = (end.year - start.year)*12 + (end.month - start.month)\n    # in case day-of-month is negative, but let's keep it simple\n    return max(diff, 0)\n\nif 'start_dates' in train_df.columns and 'end_dates' in train_df.columns:\n    train_df['total_experience_months'] = train_df.apply(\n        lambda row: calc_months_of_exp(row['start_dates'], row['end_dates']), axis=1\n    )\n    test_df['total_experience_months']  = test_df.apply(\n        lambda row: calc_months_of_exp(row['start_dates'], row['end_dates']), axis=1\n    )\nelse:\n    train_df['total_experience_months'] = 0\n    test_df['total_experience_months']  = 0\n\n# ----------------------------\n# C) Parse passing_years => numeric\n#    e.g. \"['2019']\" => 2019\n# ----------------------------\ndef parse_passing_years(val):\n    if pd.isnull(val):\n        return None\n    # Might be a list like \"['2019']\" or \"['2016', '2019']\"\n    try:\n        yrs = ast.literal_eval(val)\n        if isinstance(yrs, list) and len(yrs) > 0:\n            # return the most recent or average\n            yrs_numeric = [int(x) for x in yrs if x.isdigit()]\n            if len(yrs_numeric) == 0:\n                return None\n            return max(yrs_numeric)  # or sum(yrs_numeric)/len(yrs_numeric)\n    except:\n        pass\n    return None\n\nif 'passing_years' in train_df.columns:\n    train_df['passing_year'] = train_df['passing_years'].apply(parse_passing_years)\n    test_df['passing_year']  = test_df['passing_years'].apply(parse_passing_years)\nelse:\n    train_df['passing_year'] = None\n    test_df['passing_year']  = None\n\n# ----------------------------\n# D) Fill missing numeric with 0 or a fallback\n#    We'll do it in the pipeline, but let's ensure no weird strings remain\n# ----------------------------\n# (We will rely on StandardScaler + 'passthrough' for numeric, \n#  but we can fill NA in pipeline. For clarity, let's just fill them here.)\nnumeric_candidates = ['experience_required','age_required','skill_overlap',\n                      'total_experience_months','passing_year']\nfor col in numeric_candidates:\n    if col in train_df.columns:\n        train_df[col] = train_df[col].fillna(0)\n    if col in test_df.columns:\n        test_df[col] = test_df[col].fillna(0)\n\n# =========================================================\n# 3. IDENTIFY TEXT COLUMNS (with advanced TF-IDF)\n# =========================================================\ntext_cols = []\nfor col in ['career_objective','responsibilities','responsibilities.1','educationaL_requirements']:\n    if col in train_df.columns:\n        text_cols.append(col)\n# fill missing text\nfor col in text_cols:\n    train_df[col] = train_df[col].fillna(\"\")\n    test_df[col]  = test_df[col].fillna(\"\")\n\n# =========================================================\n# 4. DEFINE TARGET & SPLIT\n# =========================================================\ntarget_col = 'matched_score'\nif target_col not in train_df.columns:\n    raise ValueError(f\"{target_col} not found in train_df columns!\")\n\ntrain_df = train_df.dropna(subset=[target_col])\n\nX = train_df.copy()\ny = train_df[target_col].values\nX_test = test_df.copy()\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(\"Train set shape:\", X_train.shape, \"Val set shape:\", X_val.shape, \"Test set shape:\", X_test.shape)\n\n# =========================================================\n# 5. BUILD COLUMNTRANSFORMER\n#    - TF-IDF (1-2 grams) for text columns\n#    - StandardScaler for numeric\n# =========================================================\nnumeric_features = [\n    'experience_required',\n    'age_required',\n    'skill_overlap',\n    'total_experience_months',\n    'passing_year'\n]\n# Only keep the ones that exist in X_train\nnumeric_features = [col for col in numeric_features if col in X_train.columns]\n\nfrom sklearn.preprocessing import FunctionTransformer\n\ndef make_tfidf():\n    return TfidfVectorizer(\n        stop_words='english',\n        ngram_range=(1, 2),    # bigrams included\n        max_features=2000      # can tune this\n    )\n\ntext_transformers = []\nfor txt_col in text_cols:\n    text_transformers.append(\n        (f\"tfidf_{txt_col}\", make_tfidf(), txt_col)\n    )\n\nnum_pipeline = Pipeline([\n    ('scaler', MinMaxScaler())\n])\n\nfrom sklearn.compose import ColumnTransformer\n\ntransformers = text_transformers + [\n    (\"num\", num_pipeline, numeric_features)\n]\n\npreprocessor = ColumnTransformer(\n    transformers=transformers,\n    remainder='drop',\n    sparse_threshold=0\n)\n\n# =========================================================\n# 6. CHOOSE A DIFFERENT MODEL: HistGradientBoostingRegressor\n# =========================================================\nhgb_model = HistGradientBoostingRegressor(\n    loss='squared_error',\n    max_iter=300,        # ~ similar to n_estimators\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)\n\nmodel_pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('regressor', hgb_model)\n])\n\n# =========================================================\n# 7. TRAIN THE MODEL\n# =========================================================\nmodel_pipeline.fit(X_train, y_train)\n\n# =========================================================\n# 8. VALIDATE LOCALLY\n# =========================================================\ny_val_pred = model_pipeline.predict(X_val)\nmse_val = mean_squared_error(y_val, y_val_pred)\nrmse_val = np.sqrt(mse_val)\nr2_val = r2_score(y_val, y_val_pred)\n\nprint(\"Validation MSE:\", mse_val)\nprint(\"Validation RMSE:\", rmse_val)\nprint(\"Validation R^2:\", r2_val)\n\n# =========================================================\n# 9. PREDICT ON TEST SET\n# =========================================================\ntest_preds = model_pipeline.predict(X_test)\n# If domain knowledge: matched_score in [0,1], we can clip\ntest_preds = np.clip(test_preds, 0, 1)\n\n# =========================================================\n# 10. CREATE SUBMISSION\n# =========================================================\nsubmission = sample_submission.copy()\nsubmission['matched_score'] = test_preds\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission saved: submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T16:22:57.181961Z","iopub.execute_input":"2024-12-26T16:22:57.182343Z","iopub.status.idle":"2024-12-26T16:23:27.031840Z","shell.execute_reply.started":"2024-12-26T16:22:57.182292Z","shell.execute_reply":"2024-12-26T16:23:27.030397Z"}},"outputs":[{"name":"stdout","text":"Initial train shape: (7635, 35)\nInitial test shape: (1909, 35)\nDropped columns: ['address', 'languages', 'proficiency_levels']\nDropped 0 rows with < 5 non-null columns.\nTrain shape after drops: (7635, 32)\nTest shape after drops: (1909, 32)\nTrain set shape: (6108, 35) Val set shape: (1527, 35) Test set shape: (1909, 35)\nValidation MSE: 0.012194140503722667\nValidation RMSE: 0.11042708229289891\nValidation R^2: 0.5355593006807782\nSubmission saved: submission.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import TruncatedSVD\nimport gc\nfrom tqdm import tqdm\nimport ast\nfrom datetime import datetime\nfrom textblob import TextBlob\nimport re\nfrom collections import Counter\nfrom fuzzywuzzy import fuzz\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass EnhancedJobMatchingModel:\n    def __init__(self):\n        self.text_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n        self.n_folds = 5\n        self.seed = 42\n        self.label_encoders = {}\n        \n    def clean_text(self, text):\n        if pd.isna(text):\n            return ''\n        text = re.sub(r'[^\\w\\s]', ' ', str(text).lower())\n        text = re.sub(r'\\s+', ' ', text).strip()\n        return text\n\n    def extract_education_features(self, df):\n        \"\"\"Enhanced education feature extraction\"\"\"\n        def get_education_level(degree):\n            if pd.isna(degree):\n                return 0\n            degree = degree.lower()\n            if 'phd' in degree or 'doctorate' in degree:\n                return 4\n            elif 'master' in degree or 'mba' in degree:\n                return 3\n            elif 'bachelor' in degree or 'bsc' in degree:\n                return 2\n            elif 'diploma' in degree or 'certificate' in degree:\n                return 1\n            return 0\n\n        df['education_level'] = df['degree_names'].apply(get_education_level)\n        \n        # Convert educational results to numeric with better error handling\n        def extract_numeric_result(x):\n            if pd.isna(x):\n                return None\n            try:\n                # Find all numbers with optional decimal points\n                matches = re.findall(r'\\d+\\.?\\d*', str(x))\n                if matches:\n                    # Convert the first valid number found\n                    for match in matches:\n                        try:\n                            return float(match)\n                        except ValueError:\n                            continue\n                return None\n            except:\n                return None\n        \n        df['numeric_result'] = df['educational_results'].apply(extract_numeric_result)\n        \n        # Education-job requirement match score\n        df['education_match'] = df.apply(\n            lambda x: fuzz.ratio(\n                str(x['degree_names']).lower(), \n                str(x['educationaL_requirements']).lower()\n            ) / 100.0, \n            axis=1\n        )\n        \n        return df\n\n    def extract_experience_features(self, df):\n        \"\"\"Enhanced experience feature extraction\"\"\"\n        def extract_years(text):\n            if pd.isna(text):\n                return 0\n            years = re.findall(r'(\\d+)[\\s-]*year', text.lower())\n            return int(years[0]) if years else 0\n\n        df['required_years'] = df['experiencere_requirement'].apply(extract_years)\n        \n        # Calculate total experience\n        df['start_dates'] = pd.to_datetime(df['start_dates'], errors='coerce')\n        df['end_dates'] = pd.to_datetime(df['end_dates'], errors='coerce')\n        df['experience_years'] = (\n            (df['end_dates'] - df['start_dates']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n        ).fillna(0)\n        \n        # Experience match score\n        df['experience_match'] = (\n            df['experience_years'] / df['required_years'].replace(0, 1)\n        ).clip(0, 2)\n        \n        return df\n\n    def extract_skill_features(self, df):\n        \"\"\"Enhanced skill feature extraction\"\"\"\n        def parse_skills(x):\n            if pd.isna(x):\n                return set()\n            try:\n                skills = ast.literal_eval(x)\n                return set(skill.lower().strip() for skill in skills)\n            except:\n                return set()\n\n        df['candidate_skills'] = df['skills'].apply(parse_skills)\n        df['job_skills'] = df['skills_required'].apply(parse_skills)\n        \n        # Calculate various skill metrics\n        df['skill_match_ratio'] = df.apply(\n            lambda x: len(x['candidate_skills'].intersection(x['job_skills'])) / \n                     max(len(x['job_skills']), 1) if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        df['skill_coverage'] = df.apply(\n            lambda x: len(x['candidate_skills']) / max(len(x['job_skills']), 1) \n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        # Calculate skill relevance using TF-IDF-like approach\n        all_skills = set()\n        for skills in df['candidate_skills'].values:\n            all_skills.update(skills)\n            \n        skill_freq = Counter()\n        for skills in df['candidate_skills'].values:\n            skill_freq.update(skills)\n            \n        df['skill_importance_score'] = df.apply(\n            lambda x: sum(1/np.log2(skill_freq[skill] + 1) \n                         for skill in x['candidate_skills'].intersection(x['job_skills']))\n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        df.drop(['candidate_skills', 'job_skills'], axis=1, inplace=True)\n        return df\n\n    def extract_text_features(self, df):\n        \"\"\"Enhanced text feature extraction\"\"\"\n        # Sentiment analysis\n        df['objective_sentiment'] = df['career_objective'].apply(\n            lambda x: TextBlob(str(x)).sentiment.polarity\n        )\n        \n        # Text length features\n        df['objective_length'] = df['career_objective'].str.len()\n        df['resp_length'] = df['responsibilities'].str.len()\n        \n        # Keyword matching between responsibilities\n        df['resp_match'] = df.apply(\n            lambda x: fuzz.ratio(\n                str(x['responsibilities']), \n                str(x['responsibilities.1'])\n            ) / 100.0,\n            axis=1\n        )\n        \n        return df\n\n    def create_interaction_features(self, df):\n        \"\"\"Create interaction features\"\"\"\n        df['skill_edu_interaction'] = df['skill_match_ratio'] * df['education_match']\n        df['skill_exp_interaction'] = df['skill_match_ratio'] * df['experience_match']\n        df['edu_exp_interaction'] = df['education_match'] * df['experience_match']\n        \n        return df\n\n    def encode_text_features(self, df, text_cols):\n        \"\"\"Encode text features using sentence transformer\"\"\"\n        encoded_features = {}\n        batch_size = 32\n        \n        for col in text_cols:\n            if col not in df.columns:\n                continue\n                \n            print(f\"Encoding {col}...\")\n            texts = df[col].fillna('').astype(str).values\n            embeddings = []\n            \n            # Process in batches for memory efficiency\n            for i in tqdm(range(0, len(texts), batch_size)):\n                batch = texts[i:i + batch_size]\n                batch_embeddings = self.text_encoder.encode(\n                    batch,\n                    convert_to_numpy=True,\n                    show_progress_bar=False\n                )\n                embeddings.append(batch_embeddings)\n                \n            embeddings = np.vstack(embeddings)\n            \n            # Create feature names for the embeddings\n            for j in range(embeddings.shape[1]):\n                encoded_features[f'{col}_emb_{j}'] = embeddings[:, j]\n        \n        return pd.DataFrame(encoded_features, index=df.index)\n\n    def reduce_dimensions(self, train_df, test_df, text_cols, n_components=50):\n        \"\"\"Dimension reduction for text embeddings\"\"\"\n        print(\"Reducing dimensions of text embeddings...\")\n        for col in text_cols:\n            if col not in train_df.columns:\n                continue\n            \n            # Get embedding columns for this text column\n            emb_cols = [c for c in train_df.columns if f'{col}_emb_' in c]\n            if not emb_cols:\n                continue\n                \n            print(f\"Processing {col} embeddings...\")\n            svd = TruncatedSVD(n_components=min(n_components, len(emb_cols)), \n                             random_state=self.seed)\n            \n            # Fit and transform train data\n            train_embeddings = svd.fit_transform(train_df[emb_cols])\n            # Transform test data\n            test_embeddings = svd.transform(test_df[emb_cols])\n            \n            # Add reduced dimensions as new features\n            for i in range(train_embeddings.shape[1]):\n                train_df[f'{col}_svd_{i}'] = train_embeddings[:, i]\n                test_df[f'{col}_svd_{i}'] = test_embeddings[:, i]\n            \n            # Drop original embedding columns to save memory\n            train_df.drop(emb_cols, axis=1, inplace=True)\n            test_df.drop(emb_cols, axis=1, inplace=True)\n            \n            # Clean up memory\n            gc.collect()\n            \n        return train_df, test_df\n        \"\"\"Dimension reduction for text embeddings\"\"\"\n        for col in text_cols:\n            if col not in train_df.columns:\n                continue\n                \n            svd = TruncatedSVD(n_components=n_components, random_state=self.seed)\n            train_embeddings = svd.fit_transform(\n                train_df[[c for c in train_df.columns if f'{col}_emb_' in c]]\n            )\n            test_embeddings = svd.transform(\n                test_df[[c for c in test_df.columns if f'{col}_emb_' in c]]\n            )\n            \n            # Replace original embeddings with reduced dimensions\n            for i in range(n_components):\n                train_df[f'{col}_svd_{i}'] = train_embeddings[:, i]\n                test_df[f'{col}_svd_{i}'] = test_embeddings[:, i]\n                \n            # Drop original embeddings\n            train_df.drop(\n                [c for c in train_df.columns if f'{col}_emb_' in c], \n                axis=1, \n                inplace=True\n            )\n            test_df.drop(\n                [c for c in test_df.columns if f'{col}_emb_' in c], \n                axis=1, \n                inplace=True\n            )\n            \n        return train_df, test_df\n\n    def evaluate_metrics(self, y_true, y_pred):\n        \"\"\"Calculate various metrics for model evaluation\"\"\"\n        mse = mean_squared_error(y_true, y_pred)\n        rmse = np.sqrt(mse)\n        mae = np.mean(np.abs(y_true - y_pred))\n        r2 = 1 - np.sum((y_true - y_pred)**2) / np.sum((y_true - np.mean(y_true))**2)\n        \n        return {\n            'MSE': mse,\n            'RMSE': rmse,\n            'MAE': mae,\n            'R2': r2\n        }\n\n    def train_predict(self, train_df, test_df, features, target):\n        \"\"\"Enhanced training with optimized parameters and detailed validation\"\"\"\n        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.seed)\n        oof_predictions = np.zeros(len(train_df))\n        test_predictions = np.zeros(len(test_df))\n        \n        params = {\n            'objective': 'regression',\n            'metric': 'rmse',\n            'num_leaves': 64,\n            'learning_rate': 0.005,\n            'feature_fraction': 0.8,\n            'bagging_fraction': 0.8,\n            'bagging_freq': 1,\n            'verbose': -1,\n            'seed': self.seed,\n            'lambda_l1': 0.1,\n            'lambda_l2': 0.1,\n            'max_depth': 8\n        }\n        \n        # Train models\n        models = []\n        for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n            print(f'Training fold {fold + 1}')\n            \n            X_train = train_df[features].iloc[train_idx]\n            y_train = train_df[target].iloc[train_idx]\n            X_val = train_df[features].iloc[val_idx]\n            y_val = train_df[target].iloc[val_idx]\n            \n            train_data = lgb.Dataset(X_train, y_train)\n            val_data = lgb.Dataset(X_val, y_val)\n            \n            model = lgb.train(\n                params,\n                train_data,\n                valid_sets=[train_data, val_data],\n                num_boost_round=10000,\n                callbacks=[\n                    lgb.early_stopping(stopping_rounds=100),\n                    lgb.log_evaluation(period=100)\n                ]\n            )\n            \n            models.append(model)\n            oof_predictions[val_idx] = model.predict(X_val)\n            test_predictions += model.predict(test_df[features]) / self.n_folds\n            \n        # Calculate metrics for each fold\n        fold_metrics = []\n        for fold, (_, val_idx) in enumerate(kf.split(train_df)):\n            fold_y_true = train_df[target].iloc[val_idx]\n            fold_y_pred = oof_predictions[val_idx]\n            metrics = self.evaluate_metrics(fold_y_true, fold_y_pred)\n            fold_metrics.append(metrics)\n            \n            print(f\"\\nFold {fold + 1} Metrics:\")\n            for metric_name, value in metrics.items():\n                print(f\"{metric_name}: {value:.4f}\")\n        \n        # Calculate and print average metrics across folds\n        avg_metrics = {}\n        for metric in ['MSE', 'RMSE', 'MAE', 'R2']:\n            avg_metrics[metric] = np.mean([m[metric] for m in fold_metrics])\n            std_metric = np.std([m[metric] for m in fold_metrics])\n            print(f\"\\nAverage {metric}: {avg_metrics[metric]:.4f} ± {std_metric:.4f}\")\n        \n        return test_predictions, models, avg_metrics\n\n    def process_and_train(self, train_path, test_path):\n        # Load data\n        train_df = pd.read_csv(train_path)\n        test_df = pd.read_csv(test_path)\n        \n        print(\"Extracting features...\")\n        \n        # Extract all features\n        for df in [train_df, test_df]:\n            df = self.extract_education_features(df)\n            df = self.extract_experience_features(df)\n            df = self.extract_skill_features(df)\n            df = self.extract_text_features(df)\n            df = self.create_interaction_features(df)\n        \n        # Encode categorical variables\n        categorical_cols = ['educational_institution_name', 'major_field_of_studies']\n        for col in categorical_cols:\n            if col in train_df.columns:\n                le = LabelEncoder()\n                train_df[f'{col}_encoded'] = le.fit_transform(train_df[col].fillna('unknown'))\n                test_df[f'{col}_encoded'] = le.transform(test_df[col].fillna('unknown'))\n        \n        # Text encoding and dimension reduction\n        text_cols = ['career_objective', 'responsibilities', 'educationaL_requirements']\n        train_encoded = self.encode_text_features(train_df, text_cols)\n        test_encoded = self.encode_text_features(test_df, text_cols)\n        \n        # Combine features\n        train_features = pd.concat([train_df, train_encoded], axis=1)\n        test_features = pd.concat([test_df, test_encoded], axis=1)\n        \n        # Reduce dimensions of text embeddings\n        train_features, test_features = self.reduce_dimensions(\n            train_features, \n            test_features, \n            text_cols\n        )\n        \n        # Select features for training\n        feature_cols = [\n            col for col in train_features.columns \n            if col not in ['matched_score', 'ID'] and \n            train_features[col].dtype in ['int64', 'float64']\n        ]\n        \n        # Scale features\n        scaler = StandardScaler()\n        train_features[feature_cols] = scaler.fit_transform(train_features[feature_cols])\n        test_features[feature_cols] = scaler.transform(test_features[feature_cols])\n        \n        # Train and predict\n        predictions, models, cv_score = self.train_predict(\n            train_features, \n            test_features, \n            feature_cols, \n            'matched_score'\n        )\n        \n        # Clip predictions to valid range\n        predictions = np.clip(predictions, 0, 1)\n        \n        return predictions, models, cv_score\n\n# Usage\nmodel = EnhancedJobMatchingModel()\npredictions, models, metrics = model.process_and_train('/kaggle/input/bitfest-datathon-2025/train.csv', '/kaggle/input/bitfest-datathon-2025/test.csv')\n\n# Print final validation metrics\nprint(\"\\nFinal Validation Metrics:\")\nfor metric_name, value in metrics.items():\n    print(f\"{metric_name}: {value:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:18:48.436247Z","iopub.execute_input":"2024-12-26T17:18:48.436571Z","iopub.status.idle":"2024-12-26T17:19:59.615714Z","shell.execute_reply.started":"2024-12-26T17:18:48.436545Z","shell.execute_reply":"2024-12-26T17:19:59.614657Z"}},"outputs":[{"name":"stdout","text":"Extracting features...\nEncoding career_objective...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 239/239 [00:09<00:00, 26.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding responsibilities...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 239/239 [00:07<00:00, 30.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding educationaL_requirements...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 239/239 [00:02<00:00, 88.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding career_objective...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [00:02<00:00, 28.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding responsibilities...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [00:01<00:00, 31.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding educationaL_requirements...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [00:00<00:00, 87.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Reducing dimensions of text embeddings...\nProcessing career_objective embeddings...\nProcessing responsibilities embeddings...\nProcessing educationaL_requirements embeddings...\nTraining fold 1\nTraining until validation scores don't improve for 100 rounds\n[100]\ttraining's rmse: 0.145821\tvalid_1's rmse: 0.144155\n[200]\ttraining's rmse: 0.13167\tvalid_1's rmse: 0.133982\n[300]\ttraining's rmse: 0.122828\tvalid_1's rmse: 0.1282\n[400]\ttraining's rmse: 0.117175\tvalid_1's rmse: 0.12473\n[500]\ttraining's rmse: 0.112696\tvalid_1's rmse: 0.122255\n[600]\ttraining's rmse: 0.109026\tvalid_1's rmse: 0.120285\n[700]\ttraining's rmse: 0.106148\tvalid_1's rmse: 0.118825\n[800]\ttraining's rmse: 0.10376\tvalid_1's rmse: 0.117515\n[900]\ttraining's rmse: 0.101727\tvalid_1's rmse: 0.116335\n[1000]\ttraining's rmse: 0.0998745\tvalid_1's rmse: 0.115269\n[1100]\ttraining's rmse: 0.0982159\tvalid_1's rmse: 0.114401\n[1200]\ttraining's rmse: 0.0966308\tvalid_1's rmse: 0.113613\n[1300]\ttraining's rmse: 0.0951473\tvalid_1's rmse: 0.112862\n[1400]\ttraining's rmse: 0.0937423\tvalid_1's rmse: 0.112248\n[1500]\ttraining's rmse: 0.0925292\tvalid_1's rmse: 0.111773\n[1600]\ttraining's rmse: 0.0913537\tvalid_1's rmse: 0.111348\n[1700]\ttraining's rmse: 0.0902838\tvalid_1's rmse: 0.110988\n[1800]\ttraining's rmse: 0.089292\tvalid_1's rmse: 0.110713\n[1900]\ttraining's rmse: 0.0883345\tvalid_1's rmse: 0.110424\n[2000]\ttraining's rmse: 0.0873876\tvalid_1's rmse: 0.110173\n[2100]\ttraining's rmse: 0.0864589\tvalid_1's rmse: 0.109935\n[2200]\ttraining's rmse: 0.0855823\tvalid_1's rmse: 0.109767\n[2300]\ttraining's rmse: 0.0846885\tvalid_1's rmse: 0.109568\n[2400]\ttraining's rmse: 0.0838815\tvalid_1's rmse: 0.109401\n[2500]\ttraining's rmse: 0.0830681\tvalid_1's rmse: 0.109254\n[2600]\ttraining's rmse: 0.0823452\tvalid_1's rmse: 0.109158\n[2700]\ttraining's rmse: 0.0815981\tvalid_1's rmse: 0.109066\n[2800]\ttraining's rmse: 0.0808696\tvalid_1's rmse: 0.108999\n[2900]\ttraining's rmse: 0.0802031\tvalid_1's rmse: 0.108894\n[3000]\ttraining's rmse: 0.0795813\tvalid_1's rmse: 0.108848\n[3100]\ttraining's rmse: 0.0789144\tvalid_1's rmse: 0.108792\n[3200]\ttraining's rmse: 0.0783062\tvalid_1's rmse: 0.108738\n[3300]\ttraining's rmse: 0.0776846\tvalid_1's rmse: 0.108671\n[3400]\ttraining's rmse: 0.0770644\tvalid_1's rmse: 0.10863\n[3500]\ttraining's rmse: 0.0764441\tvalid_1's rmse: 0.108599\n[3600]\ttraining's rmse: 0.0758571\tvalid_1's rmse: 0.108537\n[3700]\ttraining's rmse: 0.0753238\tvalid_1's rmse: 0.108501\n[3800]\ttraining's rmse: 0.0747712\tvalid_1's rmse: 0.108485\n[3900]\ttraining's rmse: 0.0742407\tvalid_1's rmse: 0.108492\nEarly stopping, best iteration is:\n[3847]\ttraining's rmse: 0.0745041\tvalid_1's rmse: 0.108467\nTraining fold 2\nTraining until validation scores don't improve for 100 rounds\n[100]\ttraining's rmse: 0.144602\tvalid_1's rmse: 0.149139\n[200]\ttraining's rmse: 0.130585\tvalid_1's rmse: 0.137805\n[300]\ttraining's rmse: 0.121789\tvalid_1's rmse: 0.131299\n[400]\ttraining's rmse: 0.116079\tvalid_1's rmse: 0.127374\n[500]\ttraining's rmse: 0.111706\tvalid_1's rmse: 0.124638\n[600]\ttraining's rmse: 0.108229\tvalid_1's rmse: 0.122438\n[700]\ttraining's rmse: 0.105418\tvalid_1's rmse: 0.120765\n[800]\ttraining's rmse: 0.102813\tvalid_1's rmse: 0.119272\n[900]\ttraining's rmse: 0.100832\tvalid_1's rmse: 0.118197\n[1000]\ttraining's rmse: 0.0989945\tvalid_1's rmse: 0.117247\n[1100]\ttraining's rmse: 0.0973608\tvalid_1's rmse: 0.116344\n[1200]\ttraining's rmse: 0.0959509\tvalid_1's rmse: 0.115598\n[1300]\ttraining's rmse: 0.0944801\tvalid_1's rmse: 0.114895\n[1400]\ttraining's rmse: 0.0932131\tvalid_1's rmse: 0.114344\n[1500]\ttraining's rmse: 0.0919601\tvalid_1's rmse: 0.113852\n[1600]\ttraining's rmse: 0.0908439\tvalid_1's rmse: 0.113455\n[1700]\ttraining's rmse: 0.0897137\tvalid_1's rmse: 0.113042\n[1800]\ttraining's rmse: 0.0886516\tvalid_1's rmse: 0.112703\n[1900]\ttraining's rmse: 0.0876764\tvalid_1's rmse: 0.112412\n[2000]\ttraining's rmse: 0.0867455\tvalid_1's rmse: 0.112162\n[2100]\ttraining's rmse: 0.0858915\tvalid_1's rmse: 0.111971\n[2200]\ttraining's rmse: 0.0850689\tvalid_1's rmse: 0.111779\n[2300]\ttraining's rmse: 0.0842693\tvalid_1's rmse: 0.111641\n[2400]\ttraining's rmse: 0.0834621\tvalid_1's rmse: 0.111485\n[2500]\ttraining's rmse: 0.0827034\tvalid_1's rmse: 0.111353\n[2600]\ttraining's rmse: 0.0819756\tvalid_1's rmse: 0.111259\n[2700]\ttraining's rmse: 0.0812445\tvalid_1's rmse: 0.111146\n[2800]\ttraining's rmse: 0.080541\tvalid_1's rmse: 0.111034\n[2900]\ttraining's rmse: 0.079867\tvalid_1's rmse: 0.110959\n[3000]\ttraining's rmse: 0.0792033\tvalid_1's rmse: 0.110871\n[3100]\ttraining's rmse: 0.0785281\tvalid_1's rmse: 0.110792\n[3200]\ttraining's rmse: 0.0778939\tvalid_1's rmse: 0.110723\n[3300]\ttraining's rmse: 0.0772821\tvalid_1's rmse: 0.110658\n[3400]\ttraining's rmse: 0.0766966\tvalid_1's rmse: 0.110621\n[3500]\ttraining's rmse: 0.0761171\tvalid_1's rmse: 0.110607\n[3600]\ttraining's rmse: 0.0755265\tvalid_1's rmse: 0.110553\n[3700]\ttraining's rmse: 0.0749597\tvalid_1's rmse: 0.110532\n[3800]\ttraining's rmse: 0.0743925\tvalid_1's rmse: 0.110506\nEarly stopping, best iteration is:\n[3773]\ttraining's rmse: 0.0745457\tvalid_1's rmse: 0.110491\nTraining fold 3\nTraining until validation scores don't improve for 100 rounds\n[100]\ttraining's rmse: 0.145739\tvalid_1's rmse: 0.147478\n[200]\ttraining's rmse: 0.132351\tvalid_1's rmse: 0.135746\n[300]\ttraining's rmse: 0.123574\tvalid_1's rmse: 0.128541\n[400]\ttraining's rmse: 0.118077\tvalid_1's rmse: 0.124388\n[500]\ttraining's rmse: 0.113671\tvalid_1's rmse: 0.121239\n[600]\ttraining's rmse: 0.110221\tvalid_1's rmse: 0.118925\n[700]\ttraining's rmse: 0.107247\tvalid_1's rmse: 0.116932\n[800]\ttraining's rmse: 0.104762\tvalid_1's rmse: 0.115379\n[900]\ttraining's rmse: 0.102537\tvalid_1's rmse: 0.114022\n[1000]\ttraining's rmse: 0.100579\tvalid_1's rmse: 0.112832\n[1100]\ttraining's rmse: 0.0988512\tvalid_1's rmse: 0.111768\n[1200]\ttraining's rmse: 0.0973879\tvalid_1's rmse: 0.111003\n[1300]\ttraining's rmse: 0.0959486\tvalid_1's rmse: 0.110327\n[1400]\ttraining's rmse: 0.0945873\tvalid_1's rmse: 0.109639\n[1500]\ttraining's rmse: 0.0933244\tvalid_1's rmse: 0.109094\n[1600]\ttraining's rmse: 0.0921536\tvalid_1's rmse: 0.108608\n[1700]\ttraining's rmse: 0.0910295\tvalid_1's rmse: 0.108173\n[1800]\ttraining's rmse: 0.0899377\tvalid_1's rmse: 0.10785\n[1900]\ttraining's rmse: 0.0889486\tvalid_1's rmse: 0.107539\n[2000]\ttraining's rmse: 0.0880244\tvalid_1's rmse: 0.107243\n[2100]\ttraining's rmse: 0.0871243\tvalid_1's rmse: 0.107005\n[2200]\ttraining's rmse: 0.0862009\tvalid_1's rmse: 0.106813\n[2300]\ttraining's rmse: 0.0853214\tvalid_1's rmse: 0.106633\n[2400]\ttraining's rmse: 0.0845182\tvalid_1's rmse: 0.106472\n[2500]\ttraining's rmse: 0.0837748\tvalid_1's rmse: 0.10634\n[2600]\ttraining's rmse: 0.0830224\tvalid_1's rmse: 0.106201\n[2700]\ttraining's rmse: 0.0822762\tvalid_1's rmse: 0.106095\n[2800]\ttraining's rmse: 0.081517\tvalid_1's rmse: 0.106007\n[2900]\ttraining's rmse: 0.080825\tvalid_1's rmse: 0.105919\n[3000]\ttraining's rmse: 0.0802072\tvalid_1's rmse: 0.105865\n[3100]\ttraining's rmse: 0.0795686\tvalid_1's rmse: 0.105771\n[3200]\ttraining's rmse: 0.0789494\tvalid_1's rmse: 0.105679\n[3300]\ttraining's rmse: 0.0783697\tvalid_1's rmse: 0.105611\n[3400]\ttraining's rmse: 0.077757\tvalid_1's rmse: 0.105574\n[3500]\ttraining's rmse: 0.0771483\tvalid_1's rmse: 0.105518\n[3600]\ttraining's rmse: 0.0765743\tvalid_1's rmse: 0.105457\n[3700]\ttraining's rmse: 0.0759938\tvalid_1's rmse: 0.105399\n[3800]\ttraining's rmse: 0.0754404\tvalid_1's rmse: 0.105383\n[3900]\ttraining's rmse: 0.0749057\tvalid_1's rmse: 0.10537\nEarly stopping, best iteration is:\n[3896]\ttraining's rmse: 0.0749274\tvalid_1's rmse: 0.105368\nTraining fold 4\nTraining until validation scores don't improve for 100 rounds\n[100]\ttraining's rmse: 0.145039\tvalid_1's rmse: 0.150233\n[200]\ttraining's rmse: 0.13136\tvalid_1's rmse: 0.138531\n[300]\ttraining's rmse: 0.122709\tvalid_1's rmse: 0.131591\n[400]\ttraining's rmse: 0.116956\tvalid_1's rmse: 0.127213\n[500]\ttraining's rmse: 0.112494\tvalid_1's rmse: 0.124077\n[600]\ttraining's rmse: 0.108896\tvalid_1's rmse: 0.121706\n[700]\ttraining's rmse: 0.106098\tvalid_1's rmse: 0.12001\n[800]\ttraining's rmse: 0.103704\tvalid_1's rmse: 0.118544\n[900]\ttraining's rmse: 0.10174\tvalid_1's rmse: 0.117381\n[1000]\ttraining's rmse: 0.0999535\tvalid_1's rmse: 0.116333\n[1100]\ttraining's rmse: 0.098213\tvalid_1's rmse: 0.115324\n[1200]\ttraining's rmse: 0.0966378\tvalid_1's rmse: 0.114457\n[1300]\ttraining's rmse: 0.0951506\tvalid_1's rmse: 0.113653\n[1400]\ttraining's rmse: 0.0938766\tvalid_1's rmse: 0.11306\n[1500]\ttraining's rmse: 0.092714\tvalid_1's rmse: 0.112534\n[1600]\ttraining's rmse: 0.0915711\tvalid_1's rmse: 0.112013\n[1700]\ttraining's rmse: 0.0904325\tvalid_1's rmse: 0.111621\n[1800]\ttraining's rmse: 0.0893548\tvalid_1's rmse: 0.111263\n[1900]\ttraining's rmse: 0.0883944\tvalid_1's rmse: 0.110975\n[2000]\ttraining's rmse: 0.0874779\tvalid_1's rmse: 0.110707\n[2100]\ttraining's rmse: 0.0865823\tvalid_1's rmse: 0.110426\n[2200]\ttraining's rmse: 0.0857091\tvalid_1's rmse: 0.110233\n[2300]\ttraining's rmse: 0.0848839\tvalid_1's rmse: 0.110042\n[2400]\ttraining's rmse: 0.0840894\tvalid_1's rmse: 0.109846\n[2500]\ttraining's rmse: 0.0833036\tvalid_1's rmse: 0.109673\n[2600]\ttraining's rmse: 0.0825133\tvalid_1's rmse: 0.109557\n[2700]\ttraining's rmse: 0.0817947\tvalid_1's rmse: 0.109432\n[2800]\ttraining's rmse: 0.0810213\tvalid_1's rmse: 0.109293\n[2900]\ttraining's rmse: 0.0803598\tvalid_1's rmse: 0.109166\n[3000]\ttraining's rmse: 0.0797191\tvalid_1's rmse: 0.109077\n[3100]\ttraining's rmse: 0.0790497\tvalid_1's rmse: 0.108995\n[3200]\ttraining's rmse: 0.0784146\tvalid_1's rmse: 0.108917\n[3300]\ttraining's rmse: 0.0778299\tvalid_1's rmse: 0.108892\n[3400]\ttraining's rmse: 0.0772346\tvalid_1's rmse: 0.108838\n[3500]\ttraining's rmse: 0.0766513\tvalid_1's rmse: 0.108801\n[3600]\ttraining's rmse: 0.0760724\tvalid_1's rmse: 0.108776\n[3700]\ttraining's rmse: 0.0754959\tvalid_1's rmse: 0.108741\n[3800]\ttraining's rmse: 0.0749571\tvalid_1's rmse: 0.108719\n[3900]\ttraining's rmse: 0.0744338\tvalid_1's rmse: 0.108725\nEarly stopping, best iteration is:\n[3815]\ttraining's rmse: 0.0748804\tvalid_1's rmse: 0.108706\nTraining fold 5\nTraining until validation scores don't improve for 100 rounds\n[100]\ttraining's rmse: 0.145952\tvalid_1's rmse: 0.148469\n[200]\ttraining's rmse: 0.132681\tvalid_1's rmse: 0.136588\n[300]\ttraining's rmse: 0.123915\tvalid_1's rmse: 0.129449\n[400]\ttraining's rmse: 0.118134\tvalid_1's rmse: 0.125305\n[500]\ttraining's rmse: 0.113663\tvalid_1's rmse: 0.12232\n[600]\ttraining's rmse: 0.110006\tvalid_1's rmse: 0.120036\n[700]\ttraining's rmse: 0.106898\tvalid_1's rmse: 0.118136\n[800]\ttraining's rmse: 0.104312\tvalid_1's rmse: 0.116588\n[900]\ttraining's rmse: 0.102209\tvalid_1's rmse: 0.115305\n[1000]\ttraining's rmse: 0.100318\tvalid_1's rmse: 0.114207\n[1100]\ttraining's rmse: 0.0986866\tvalid_1's rmse: 0.113267\n[1200]\ttraining's rmse: 0.0971369\tvalid_1's rmse: 0.11239\n[1300]\ttraining's rmse: 0.0957948\tvalid_1's rmse: 0.111722\n[1400]\ttraining's rmse: 0.0944507\tvalid_1's rmse: 0.111065\n[1500]\ttraining's rmse: 0.093256\tvalid_1's rmse: 0.110551\n[1600]\ttraining's rmse: 0.0920671\tvalid_1's rmse: 0.110046\n[1700]\ttraining's rmse: 0.0909503\tvalid_1's rmse: 0.109587\n[1800]\ttraining's rmse: 0.0899013\tvalid_1's rmse: 0.109231\n[1900]\ttraining's rmse: 0.0889315\tvalid_1's rmse: 0.108882\n[2000]\ttraining's rmse: 0.0880146\tvalid_1's rmse: 0.10859\n[2100]\ttraining's rmse: 0.0870597\tvalid_1's rmse: 0.108294\n[2200]\ttraining's rmse: 0.0861962\tvalid_1's rmse: 0.108084\n[2300]\ttraining's rmse: 0.0853764\tvalid_1's rmse: 0.107915\n[2400]\ttraining's rmse: 0.0846157\tvalid_1's rmse: 0.107742\n[2500]\ttraining's rmse: 0.0838152\tvalid_1's rmse: 0.107575\n[2600]\ttraining's rmse: 0.0830971\tvalid_1's rmse: 0.107415\n[2700]\ttraining's rmse: 0.0823718\tvalid_1's rmse: 0.107294\n[2800]\ttraining's rmse: 0.0816468\tvalid_1's rmse: 0.107229\n[2900]\ttraining's rmse: 0.0809649\tvalid_1's rmse: 0.107149\n[3000]\ttraining's rmse: 0.0802965\tvalid_1's rmse: 0.107085\n[3100]\ttraining's rmse: 0.0796266\tvalid_1's rmse: 0.107025\n[3200]\ttraining's rmse: 0.0789661\tvalid_1's rmse: 0.10694\n[3300]\ttraining's rmse: 0.0783676\tvalid_1's rmse: 0.10687\n[3400]\ttraining's rmse: 0.077777\tvalid_1's rmse: 0.106837\n[3500]\ttraining's rmse: 0.077153\tvalid_1's rmse: 0.106782\n[3600]\ttraining's rmse: 0.0765508\tvalid_1's rmse: 0.106747\n[3700]\ttraining's rmse: 0.075984\tvalid_1's rmse: 0.106732\n[3800]\ttraining's rmse: 0.0754696\tvalid_1's rmse: 0.106714\n[3900]\ttraining's rmse: 0.0749584\tvalid_1's rmse: 0.106702\nEarly stopping, best iteration is:\n[3847]\ttraining's rmse: 0.0752209\tvalid_1's rmse: 0.106699\n\nFold 1 Metrics:\nMSE: 0.0118\nRMSE: 0.1085\nMAE: 0.0810\nR2: 0.5519\n\nFold 2 Metrics:\nMSE: 0.0122\nRMSE: 0.1105\nMAE: 0.0829\nR2: 0.5728\n\nFold 3 Metrics:\nMSE: 0.0111\nRMSE: 0.1054\nMAE: 0.0803\nR2: 0.6036\n\nFold 4 Metrics:\nMSE: 0.0118\nRMSE: 0.1087\nMAE: 0.0826\nR2: 0.5895\n\nFold 5 Metrics:\nMSE: 0.0114\nRMSE: 0.1067\nMAE: 0.0811\nR2: 0.5987\n\nAverage MSE: 0.0117 ± 0.0004\n\nAverage RMSE: 0.1079 ± 0.0018\n\nAverage MAE: 0.0816 ± 0.0010\n\nAverage R2: 0.5833 ± 0.0189\n\nFinal Validation Metrics:\nMSE: 0.0117\nRMSE: 0.1079\nMAE: 0.0816\nR2: 0.5833\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-5645dc2b8920>\u001b[0m in \u001b[0;36m<cell line: 438>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;31m# Create submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m submission = pd.DataFrame({\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;34m'ID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0;34m'matched_score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m })\n","\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"],"ename":"NameError","evalue":"name 'test_df' is not defined","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:22:22.315147Z","iopub.execute_input":"2024-12-26T17:22:22.315509Z","iopub.status.idle":"2024-12-26T17:22:22.361920Z","shell.execute_reply.started":"2024-12-26T17:22:22.315480Z","shell.execute_reply":"2024-12-26T17:22:22.361285Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install sentence-transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:17:28.016841Z","iopub.execute_input":"2024-12-26T17:17:28.017143Z","iopub.status.idle":"2024-12-26T17:17:31.384967Z","shell.execute_reply.started":"2024-12-26T17:17:28.017119Z","shell.execute_reply":"2024-12-26T17:17:31.384095Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:24:40.858149Z","iopub.execute_input":"2024-12-26T17:24:40.858524Z","iopub.status.idle":"2024-12-26T17:25:16.888748Z","shell.execute_reply.started":"2024-12-26T17:24:40.858497Z","shell.execute_reply":"2024-12-26T17:25:16.888083Z"}},"outputs":[{"name":"stdout","text":"Engineering features...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac99c5c85f9434cba971359d000795b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a191baa0bf4bd598fbb7641d6ba711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adffb5551f9641caa1475fdc6a06d00f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/60 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a1ec4a46d004b739face68ce18b273c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/60 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3751e743b05944b9a4e8a9e5e0e81647"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/60 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6911032e3e243a6aa67362a3536e59f"}},"metadata":{}},{"name":"stdout","text":"Training fold 1\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1482]\tvalid_0's l2: 0.0173076\nTraining fold 2\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1365]\tvalid_0's l2: 0.0175824\nTraining fold 3\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1448]\tvalid_0's l2: 0.0169199\nTraining fold 4\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1794]\tvalid_0's l2: 0.0173083\nTraining fold 5\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1381]\tvalid_0's l2: 0.0174404\n\nMSE: 0.017278\n\nFinal MSE: 0.017278\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import TruncatedSVD\nimport gc\nfrom tqdm import tqdm\nimport ast\nfrom datetime import datetime\nfrom textblob import TextBlob\nimport re\nfrom collections import Counter\nfrom fuzzywuzzy import fuzz\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nclass EnhancedJobMatchingModel:\n    def __init__(self):\n        self.text_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n        self.n_folds = 5\n        self.seed = 42\n        self.label_encoders = {}\n        \n    def clean_text(self, text):\n        if pd.isna(text):\n            return ''\n        text = re.sub(r'[^\\w\\s]', ' ', str(text).lower())\n        text = re.sub(r'\\s+', ' ', text).strip()\n        return text\n\n    def extract_education_features(self, df):\n        \"\"\"Enhanced education feature extraction\"\"\"\n        def get_education_level(degree):\n            if pd.isna(degree):\n                return 0\n            degree = degree.lower()\n            if 'phd' in degree or 'doctorate' in degree:\n                return 4\n            elif 'master' in degree or 'mba' in degree:\n                return 3\n            elif 'bachelor' in degree or 'bsc' in degree:\n                return 2\n            elif 'diploma' in degree or 'certificate' in degree:\n                return 1\n            return 0\n\n        df['education_level'] = df['degree_names'].apply(get_education_level)\n        \n        # Convert educational results to numeric\n        def extract_numeric_result(x):\n            if pd.isna(x):\n                return None\n            try:\n                matches = re.findall(r'\\d+\\.?\\d*', str(x))\n                if matches:\n                    for match in matches:\n                        try:\n                            return float(match)\n                        except ValueError:\n                            continue\n                return None\n            except:\n                return None\n        \n        df['numeric_result'] = df['educational_results'].apply(extract_numeric_result)\n        \n        # Education-job requirement match score\n        df['education_match'] = df.apply(\n            lambda x: fuzz.ratio(\n                str(x['degree_names']).lower(), \n                str(x['educationaL_requirements']).lower()\n            ) / 100.0, \n            axis=1\n        )\n        \n        return df\n\n    def extract_experience_features(self, df):\n        \"\"\"Enhanced experience feature extraction\"\"\"\n        def extract_years(text):\n            if pd.isna(text):\n                return 0\n            years = re.findall(r'(\\d+)[\\s-]*year', text.lower())\n            return int(years[0]) if years else 0\n\n        df['required_years'] = df['experiencere_requirement'].apply(extract_years)\n        \n        # Calculate total experience\n        df['start_dates'] = pd.to_datetime(df['start_dates'], errors='coerce')\n        df['end_dates'] = pd.to_datetime(df['end_dates'], errors='coerce')\n        df['experience_years'] = (\n            (df['end_dates'] - df['start_dates']).dt.total_seconds() \n            / (365.25 * 24 * 60 * 60)\n        ).fillna(0)\n        \n        # Experience match score\n        df['experience_match'] = (\n            df['experience_years'] / df['required_years'].replace(0, 1)\n        ).clip(0, 2)\n        \n        return df\n\n    def extract_skill_features(self, df):\n        \"\"\"Enhanced skill feature extraction\"\"\"\n        def parse_skills(x):\n            if pd.isna(x):\n                return set()\n            try:\n                skills = ast.literal_eval(x)\n                return set(skill.lower().strip() for skill in skills)\n            except:\n                return set()\n\n        df['candidate_skills'] = df['skills'].apply(parse_skills)\n        df['job_skills'] = df['skills_required'].apply(parse_skills)\n        \n        # Calculate various skill metrics\n        df['skill_match_ratio'] = df.apply(\n            lambda x: len(x['candidate_skills'].intersection(x['job_skills'])) \n                      / max(len(x['job_skills']), 1) \n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        df['skill_coverage'] = df.apply(\n            lambda x: len(x['candidate_skills']) / max(len(x['job_skills']), 1) \n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        # TF-IDF-like skill importance\n        all_skills = set()\n        for skills in df['candidate_skills'].values:\n            all_skills.update(skills)\n            \n        skill_freq = Counter()\n        for skills in df['candidate_skills'].values:\n            skill_freq.update(skills)\n            \n        df['skill_importance_score'] = df.apply(\n            lambda x: sum(1/np.log2(skill_freq[skill] + 1) \n                         for skill in x['candidate_skills'].intersection(x['job_skills']))\n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        df.drop(['candidate_skills', 'job_skills'], axis=1, inplace=True)\n        return df\n\n    def extract_text_features(self, df):\n        \"\"\"Enhanced text feature extraction\"\"\"\n        # Sentiment analysis\n        df['objective_sentiment'] = df['career_objective'].apply(\n            lambda x: TextBlob(str(x)).sentiment.polarity\n        )\n        \n        # Text length features\n        df['objective_length'] = df['career_objective'].str.len()\n        df['resp_length'] = df['responsibilities'].str.len()\n        \n        # Keyword matching between responsibilities\n        df['resp_match'] = df.apply(\n            lambda x: fuzz.ratio(\n                str(x['responsibilities']), \n                str(x['responsibilities.1'])\n            ) / 100.0,\n            axis=1\n        )\n        \n        return df\n\n    def create_interaction_features(self, df):\n        \"\"\"Create interaction features\"\"\"\n        df['skill_edu_interaction'] = df['skill_match_ratio'] * df['education_match']\n        df['skill_exp_interaction'] = df['skill_match_ratio'] * df['experience_match']\n        df['edu_exp_interaction'] = df['education_match'] * df['experience_match']\n        \n        return df\n\n    def encode_text_features(self, df, text_cols):\n        \"\"\"Encode text features using sentence transformer\"\"\"\n        encoded_features = {}\n        batch_size = 32\n        \n        for col in text_cols:\n            if col not in df.columns:\n                continue\n                \n            print(f\"Encoding {col}...\")\n            texts = df[col].fillna('').astype(str).values\n            embeddings = []\n            \n            # Process in batches for memory efficiency\n            for i in tqdm(range(0, len(texts), batch_size)):\n                batch = texts[i:i + batch_size]\n                batch_embeddings = self.text_encoder.encode(\n                    batch,\n                    convert_to_numpy=True,\n                    show_progress_bar=False\n                )\n                embeddings.append(batch_embeddings)\n                \n            embeddings = np.vstack(embeddings)\n            \n            # Create feature names for the embeddings\n            for j in range(embeddings.shape[1]):\n                encoded_features[f'{col}_emb_{j}'] = embeddings[:, j]\n        \n        return pd.DataFrame(encoded_features, index=df.index)\n\n    def reduce_dimensions(self, train_df, test_df, text_cols, n_components=50):\n        \"\"\"Dimension reduction for text embeddings\"\"\"\n        print(\"Reducing dimensions of text embeddings...\")\n        for col in text_cols:\n            emb_cols = [c for c in train_df.columns if f'{col}_emb_' in c]\n            if not emb_cols:\n                continue\n                \n            print(f\"Processing {col} embeddings with SVD n_components={n_components}...\")\n            svd = TruncatedSVD(\n                n_components=min(n_components, len(emb_cols)), \n                random_state=self.seed\n            )\n            \n            train_embeddings = svd.fit_transform(train_df[emb_cols])\n            test_embeddings  = svd.transform(test_df[emb_cols])\n            \n            for i in range(train_embeddings.shape[1]):\n                train_df[f'{col}_svd_{i}'] = train_embeddings[:, i]\n                test_df[f'{col}_svd_{i}']  = test_embeddings[:, i]\n            \n            train_df.drop(emb_cols, axis=1, inplace=True)\n            test_df.drop(emb_cols, axis=1, inplace=True)\n            gc.collect()\n            \n        return train_df, test_df\n\n    def evaluate_mse(self, y_true, y_pred):\n        \"\"\"Calculate only MSE for model evaluation\"\"\"\n        mse = mean_squared_error(y_true, y_pred)\n        return mse\n\n    def train_predict(self, train_df, test_df, features, target):\n        \"\"\"Enhanced training: focus on MSE\"\"\"\n        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.seed)\n        oof_predictions = np.zeros(len(train_df))\n        test_predictions = np.zeros(len(test_df))\n        \n        # Potentially more aggressive hyperparams for lower MSE\n        params = {\n            'objective': 'regression',\n            'metric': 'rmse',\n            'num_leaves': 64,\n            'learning_rate': 0.005,\n            'feature_fraction': 0.8,\n            'bagging_fraction': 0.8,\n            'bagging_freq': 1,\n            'verbose': -1,\n            'seed': self.seed,\n            'lambda_l1': 0.2,  # increased reg\n            'lambda_l2': 0.2,  # increased reg\n            'max_depth': 8\n        }\n        \n        fold_mses = []\n        for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n            print(f'\\nTraining fold {fold + 1} / {self.n_folds}')\n            \n            X_train = train_df[features].iloc[train_idx]\n            y_train = train_df[target].iloc[train_idx]\n            X_val = train_df[features].iloc[val_idx]\n            y_val = train_df[target].iloc[val_idx]\n            \n            train_data = lgb.Dataset(X_train, y_train)\n            val_data = lgb.Dataset(X_val, y_val)\n            \n            model = lgb.train(\n                params,\n                train_data,\n                valid_sets=[train_data, val_data],\n                num_boost_round=15000,  # more potential boosting rounds\n                callbacks=[\n                    lgb.early_stopping(stopping_rounds=150),\n                    lgb.log_evaluation(period=200)\n                ]\n            )\n            \n            val_pred = model.predict(X_val)\n            mse_score = self.evaluate_mse(y_val, val_pred)\n            fold_mses.append(mse_score)\n            \n            print(f\"Fold {fold+1} MSE: {mse_score:.6f}\")\n            \n            oof_predictions[val_idx] = val_pred\n            test_predictions += model.predict(test_df[features]) / self.n_folds\n            \n        # Average fold MSE\n        mean_mse = np.mean(fold_mses)\n        std_mse  = np.std(fold_mses)\n        \n        print(f\"\\nAverage MSE across folds: {mean_mse:.6f} ± {std_mse:.6f}\")\n        \n        return test_predictions, mean_mse\n\n    def process_and_train(self, train_path, test_path):\n        # Load data\n        train_df = pd.read_csv(train_path)\n        test_df  = pd.read_csv(test_path)\n        \n        print(\"Extracting features...\")\n        \n        # Feature extraction\n        for df in [train_df, test_df]:\n            df = self.extract_education_features(df)\n            df = self.extract_experience_features(df)\n            df = self.extract_skill_features(df)\n            df = self.extract_text_features(df)\n            df = self.create_interaction_features(df)\n        \n        # Encode categorical variables\n        categorical_cols = ['educational_institution_name', 'major_field_of_studies']\n        for col in categorical_cols:\n            if col in train_df.columns:\n                le = LabelEncoder()\n                train_df[f'{col}_encoded'] = le.fit_transform(train_df[col].fillna('unknown'))\n                test_df[f'{col}_encoded'] = le.transform(test_df[col].fillna('unknown'))\n        \n        # Sentence-BERT for text columns\n        text_cols = ['career_objective', 'responsibilities', 'educationaL_requirements']\n        train_encoded = self.encode_text_features(train_df, text_cols)\n        test_encoded  = self.encode_text_features(test_df, text_cols)\n        \n        # Combine embeddings into main data\n        train_features = pd.concat([train_df, train_encoded], axis=1)\n        test_features  = pd.concat([test_df, test_encoded], axis=1)\n        \n        # Reduce text embedding dimensions\n        train_features, test_features = self.reduce_dimensions(train_features, test_features, text_cols)\n        \n        # Select features\n        drop_cols = ['matched_score', 'ID']  # exclude from features\n        feature_cols = [\n            c for c in train_features.columns\n            if c not in drop_cols\n               and (train_features[c].dtype in [np.float64, np.int64, np.float32, np.int32])\n        ]\n        \n        # Scale numeric features\n        scaler = StandardScaler()\n        train_features[feature_cols] = scaler.fit_transform(train_features[feature_cols])\n        test_features[feature_cols]  = scaler.transform(test_features[feature_cols])\n        \n        # LightGBM training\n        predictions, mean_mse = self.train_predict(\n            train_features, \n            test_features, \n            feature_cols, \n            'matched_score'\n        )\n        \n        # Clip predictions to valid range\n        predictions = np.clip(predictions, 0, 1)\n        \n        return predictions, mean_mse\n\n\n# ===============================\n# Usage Example\n# ===============================\nif __name__ == \"__main__\":\n    model = EnhancedJobMatchingModel()\n    preds, avg_mse = model.process_and_train(\n        '/kaggle/input/bitfest-datathon-2025/train.csv',\n        '/kaggle/input/bitfest-datathon-2025/test.csv'\n    )\n    \n    print(\"\\nFinal Average MSE:\", avg_mse)\n    # preds can then be used to create submission file if needed\n    test_df = pd.read_csv(\"/kaggle/input/bitfest-datathon-2025/test.csv\")\n    # Create submission\n    submission = pd.DataFrame({\n        'ID': test_df['ID'],\n        'matched_score': preds\n    })\n    submission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:31:51.485993Z","iopub.execute_input":"2024-12-26T17:31:51.486360Z","iopub.status.idle":"2024-12-26T17:34:28.555820Z","shell.execute_reply.started":"2024-12-26T17:31:51.486334Z","shell.execute_reply":"2024-12-26T17:34:28.554992Z"}},"outputs":[{"name":"stdout","text":"Extracting features...\nEncoding career_objective...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 239/239 [00:09<00:00, 26.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding responsibilities...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 239/239 [00:07<00:00, 30.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding educationaL_requirements...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 239/239 [00:02<00:00, 89.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding career_objective...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [00:02<00:00, 28.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding responsibilities...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [00:01<00:00, 31.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Encoding educationaL_requirements...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [00:00<00:00, 89.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Reducing dimensions of text embeddings...\nProcessing career_objective embeddings with SVD n_components=50...\nProcessing responsibilities embeddings with SVD n_components=50...\nProcessing educationaL_requirements embeddings with SVD n_components=50...\n\nTraining fold 1 / 5\nTraining until validation scores don't improve for 150 rounds\n[200]\ttraining's rmse: 0.122121\tvalid_1's rmse: 0.129352\n[400]\ttraining's rmse: 0.103969\tvalid_1's rmse: 0.119068\n[600]\ttraining's rmse: 0.0943544\tvalid_1's rmse: 0.114057\n[800]\ttraining's rmse: 0.0881261\tvalid_1's rmse: 0.111414\n[1000]\ttraining's rmse: 0.0835227\tvalid_1's rmse: 0.109952\n[1200]\ttraining's rmse: 0.0795552\tvalid_1's rmse: 0.10894\n[1400]\ttraining's rmse: 0.0759314\tvalid_1's rmse: 0.108258\n[1600]\ttraining's rmse: 0.0725911\tvalid_1's rmse: 0.107695\n[1800]\ttraining's rmse: 0.0694635\tvalid_1's rmse: 0.107178\n[2000]\ttraining's rmse: 0.066679\tvalid_1's rmse: 0.106886\n[2200]\ttraining's rmse: 0.0641123\tvalid_1's rmse: 0.10667\n[2400]\ttraining's rmse: 0.0617227\tvalid_1's rmse: 0.106501\n[2600]\ttraining's rmse: 0.0594529\tvalid_1's rmse: 0.106344\n[2800]\ttraining's rmse: 0.0573274\tvalid_1's rmse: 0.106228\n[3000]\ttraining's rmse: 0.0553925\tvalid_1's rmse: 0.106149\n[3200]\ttraining's rmse: 0.0534929\tvalid_1's rmse: 0.106068\n[3400]\ttraining's rmse: 0.0517793\tvalid_1's rmse: 0.106\n[3600]\ttraining's rmse: 0.0500605\tvalid_1's rmse: 0.105927\n[3800]\ttraining's rmse: 0.048461\tvalid_1's rmse: 0.105873\nEarly stopping, best iteration is:\n[3765]\ttraining's rmse: 0.0487343\tvalid_1's rmse: 0.105858\nFold 1 MSE: 0.011206\n\nTraining fold 2 / 5\nTraining until validation scores don't improve for 150 rounds\n[200]\ttraining's rmse: 0.121193\tvalid_1's rmse: 0.13208\n[400]\ttraining's rmse: 0.103164\tvalid_1's rmse: 0.120633\n[600]\ttraining's rmse: 0.0937461\tvalid_1's rmse: 0.115767\n[800]\ttraining's rmse: 0.0875803\tvalid_1's rmse: 0.113145\n[1000]\ttraining's rmse: 0.082966\tvalid_1's rmse: 0.111537\n[1200]\ttraining's rmse: 0.078991\tvalid_1's rmse: 0.110509\n[1400]\ttraining's rmse: 0.0752555\tvalid_1's rmse: 0.10994\n[1600]\ttraining's rmse: 0.0718437\tvalid_1's rmse: 0.109365\n[1800]\ttraining's rmse: 0.0687711\tvalid_1's rmse: 0.109113\n[2000]\ttraining's rmse: 0.0658988\tvalid_1's rmse: 0.10886\n[2200]\ttraining's rmse: 0.0632743\tvalid_1's rmse: 0.108742\n[2400]\ttraining's rmse: 0.0608635\tvalid_1's rmse: 0.108648\n[2600]\ttraining's rmse: 0.0585721\tvalid_1's rmse: 0.108612\n[2800]\ttraining's rmse: 0.0563848\tvalid_1's rmse: 0.10855\n[3000]\ttraining's rmse: 0.0543724\tvalid_1's rmse: 0.108583\nEarly stopping, best iteration is:\n[2904]\ttraining's rmse: 0.055329\tvalid_1's rmse: 0.108546\nFold 2 MSE: 0.011782\n\nTraining fold 3 / 5\nTraining until validation scores don't improve for 150 rounds\n[200]\ttraining's rmse: 0.121928\tvalid_1's rmse: 0.128597\n[400]\ttraining's rmse: 0.103753\tvalid_1's rmse: 0.116146\n[600]\ttraining's rmse: 0.0947544\tvalid_1's rmse: 0.110954\n[800]\ttraining's rmse: 0.088596\tvalid_1's rmse: 0.108243\n[1000]\ttraining's rmse: 0.0837084\tvalid_1's rmse: 0.106701\n[1200]\ttraining's rmse: 0.079784\tvalid_1's rmse: 0.105715\n[1400]\ttraining's rmse: 0.0758596\tvalid_1's rmse: 0.104958\n[1600]\ttraining's rmse: 0.0724323\tvalid_1's rmse: 0.104493\n[1800]\ttraining's rmse: 0.069269\tvalid_1's rmse: 0.104271\n[2000]\ttraining's rmse: 0.0663688\tvalid_1's rmse: 0.104103\n[2200]\ttraining's rmse: 0.063736\tvalid_1's rmse: 0.104041\n[2400]\ttraining's rmse: 0.0613414\tvalid_1's rmse: 0.103956\n[2600]\ttraining's rmse: 0.0590132\tvalid_1's rmse: 0.103937\nEarly stopping, best iteration is:\n[2550]\ttraining's rmse: 0.0595874\tvalid_1's rmse: 0.103929\nFold 3 MSE: 0.010801\n\nTraining fold 4 / 5\nTraining until validation scores don't improve for 150 rounds\n[200]\ttraining's rmse: 0.121336\tvalid_1's rmse: 0.131566\n[400]\ttraining's rmse: 0.103465\tvalid_1's rmse: 0.119065\n[600]\ttraining's rmse: 0.0941684\tvalid_1's rmse: 0.113435\n[800]\ttraining's rmse: 0.0880674\tvalid_1's rmse: 0.110365\n[1000]\ttraining's rmse: 0.0831647\tvalid_1's rmse: 0.108471\n[1200]\ttraining's rmse: 0.0791223\tvalid_1's rmse: 0.107313\n[1400]\ttraining's rmse: 0.0754819\tvalid_1's rmse: 0.106529\n[1600]\ttraining's rmse: 0.0722381\tvalid_1's rmse: 0.105956\n[1800]\ttraining's rmse: 0.0691652\tvalid_1's rmse: 0.105555\n[2000]\ttraining's rmse: 0.0663613\tvalid_1's rmse: 0.105325\n[2200]\ttraining's rmse: 0.0637722\tvalid_1's rmse: 0.105153\n[2400]\ttraining's rmse: 0.0613725\tvalid_1's rmse: 0.105021\n[2600]\ttraining's rmse: 0.0591588\tvalid_1's rmse: 0.105002\n[2800]\ttraining's rmse: 0.0570925\tvalid_1's rmse: 0.104944\nEarly stopping, best iteration is:\n[2764]\ttraining's rmse: 0.0574877\tvalid_1's rmse: 0.104929\nFold 4 MSE: 0.011010\n\nTraining fold 5 / 5\nTraining until validation scores don't improve for 150 rounds\n[200]\ttraining's rmse: 0.122643\tvalid_1's rmse: 0.129126\n[400]\ttraining's rmse: 0.10501\tvalid_1's rmse: 0.116846\n[600]\ttraining's rmse: 0.0955194\tvalid_1's rmse: 0.111087\n[800]\ttraining's rmse: 0.0892274\tvalid_1's rmse: 0.10805\n[1000]\ttraining's rmse: 0.08441\tvalid_1's rmse: 0.106356\n[1200]\ttraining's rmse: 0.0800552\tvalid_1's rmse: 0.105175\n[1400]\ttraining's rmse: 0.0763407\tvalid_1's rmse: 0.104459\n[1600]\ttraining's rmse: 0.0729905\tvalid_1's rmse: 0.104045\n[1800]\ttraining's rmse: 0.0698928\tvalid_1's rmse: 0.103815\n[2000]\ttraining's rmse: 0.0669727\tvalid_1's rmse: 0.103635\n[2200]\ttraining's rmse: 0.0642405\tvalid_1's rmse: 0.103518\n[2400]\ttraining's rmse: 0.0617595\tvalid_1's rmse: 0.103476\nEarly stopping, best iteration is:\n[2323]\ttraining's rmse: 0.0627427\tvalid_1's rmse: 0.103458\nFold 5 MSE: 0.010704\n\nAverage MSE across folds: 0.011101 ± 0.000382\n\nFinal Average MSE: 0.011100609526866808\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# =========================================================\n# 1. INSTALL REQUIRED LIBRARIES\n# =========================================================\n# Uncomment and run the following lines if the libraries are not already installed.\n# !pip install lightgbm\n# !pip install fuzzywuzzy\n# !pip install textblob\n# !pip install tensorflow\n# !pip install python-Levenshtein  # Recommended for fuzzywuzzy speedup\n\n# =========================================================\n# 2. IMPORT LIBRARIES\n# =========================================================\nimport pandas as pd\nimport numpy as np\nimport gc\nimport re\nimport ast\nfrom collections import Counter\nfrom datetime import datetime\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport lightgbm as lgb\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom textblob import TextBlob\nfrom fuzzywuzzy import fuzz\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# =========================================================\n# 3. DEFINE THE MODEL CLASS\n# =========================================================\nclass EnhancedJobMatchingModel:\n    def __init__(self):\n        # Initialize TF-IDF Vectorizers for text features\n        self.tfidf_vectorizers = {}\n        \n        # Number of folds for cross-validation\n        self.n_folds = 5\n        \n        # Random seed for reproducibility\n        self.seed = 42\n        \n        # LightGBM parameters\n        self.lgb_params = {\n            'objective': 'regression',\n            'metric': 'rmse',\n            'num_leaves': 64,\n            'learning_rate': 0.005,\n            'feature_fraction': 0.8,\n            'bagging_fraction': 0.8,\n            'bagging_freq': 1,\n            'verbose': -1,\n            'seed': self.seed,\n            'lambda_l1': 0.2,\n            'lambda_l2': 0.2,\n            'max_depth': 8\n        }\n        \n        # Neural Network parameters\n        self.nn_params = {\n            'epochs': 20,\n            'batch_size': 32,\n            'learning_rate': 0.001\n        }\n    \n    #############################\n    #        FEATURE ENGINEERING      #\n    #############################\n    def extract_education_features(self, df):\n        \"\"\"Enhanced education feature extraction\"\"\"\n        def get_education_level(degree):\n            if pd.isna(degree):\n                return 0\n            degree = degree.lower()\n            if 'phd' in degree or 'doctorate' in degree:\n                return 4\n            elif 'master' in degree or 'mba' in degree:\n                return 3\n            elif 'bachelor' in degree or 'bsc' in degree:\n                return 2\n            elif 'diploma' in degree or 'certificate' in degree:\n                return 1\n            return 0\n\n        df['education_level'] = df['degree_names'].apply(get_education_level)\n        \n        # Convert educational results to numeric with better error handling\n        def extract_numeric_result(x):\n            if pd.isna(x):\n                return 0.0\n            try:\n                matches = re.findall(r'\\d+\\.?\\d*', str(x))\n                if matches:\n                    # Take the first valid number\n                    for match in matches:\n                        try:\n                            return float(match)\n                        except ValueError:\n                            continue\n                return 0.0\n            except:\n                return 0.0\n\n        df['numeric_result'] = df['educational_results'].apply(extract_numeric_result)\n        \n        # Education-job requirement match score\n        df['education_match'] = df.apply(\n            lambda x: fuzz.ratio(\n                str(x['degree_names']).lower(), \n                str(x['educationaL_requirements']).lower()\n            ) / 100.0, \n            axis=1\n        )\n        \n        return df\n\n    def extract_experience_features(self, df):\n        \"\"\"Enhanced experience feature extraction\"\"\"\n        def extract_years(text):\n            if pd.isna(text):\n                return 0\n            years = re.findall(r'(\\d+)[\\s-]*year', text.lower())\n            return int(years[0]) if years else 0\n\n        df['required_years'] = df['experiencere_requirement'].apply(extract_years)\n        \n        # Convert to datetime\n        df['start_dates'] = pd.to_datetime(df['start_dates'], errors='coerce')\n        df['end_dates'] = pd.to_datetime(df['end_dates'], errors='coerce')\n        df['experience_years'] = (\n            (df['end_dates'] - df['start_dates']).dt.total_seconds() \n            / (365.25 * 24 * 60 * 60)\n        ).fillna(0)\n        \n        # Experience match score\n        df['experience_match'] = (\n            df['experience_years'] / df['required_years'].replace(0, 1)\n        ).clip(0, 2)\n        \n        return df\n\n    def extract_skill_features(self, df):\n        \"\"\"Enhanced skill feature extraction\"\"\"\n        def parse_skills(x):\n            if pd.isna(x):\n                return set()\n            try:\n                arr = ast.literal_eval(x)\n                return set(skill.lower().strip() for skill in arr)\n            except:\n                return set()\n\n        df['candidate_skills'] = df['skills'].apply(parse_skills)\n        df['job_skills'] = df['skills_required'].apply(parse_skills)\n        \n        # Calculate various skill metrics\n        df['skill_match_ratio'] = df.apply(\n            lambda x: len(x['candidate_skills'].intersection(x['job_skills'])) \n                      / max(len(x['job_skills']), 1)\n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        df['skill_coverage'] = df.apply(\n            lambda x: len(x['candidate_skills']) / max(len(x['job_skills']), 1)\n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        # TF-IDF-like skill importance\n        all_skills = set()\n        for s in df['candidate_skills']:\n            all_skills.update(s)\n            \n        skill_freq = Counter()\n        for s in df['candidate_skills']:\n            skill_freq.update(s)\n            \n        df['skill_importance_score'] = df.apply(\n            lambda x: sum(1 / np.log2(skill_freq[skill] + 1)\n                          for skill in x['candidate_skills'].intersection(x['job_skills']))\n            if x['job_skills'] else 0,\n            axis=1\n        )\n        \n        # Drop intermediate columns to save memory\n        df.drop(['candidate_skills','job_skills'], axis=1, inplace=True)\n        \n        return df\n\n    def extract_text_features(self, df):\n        \"\"\"Enhanced text feature extraction\"\"\"\n        # Sentiment analysis\n        df['objective_sentiment'] = df['career_objective'].apply(\n            lambda x: TextBlob(str(x)).sentiment.polarity\n        )\n        \n        # Text length features\n        df['objective_length'] = df['career_objective'].str.len()\n        df['resp_length'] = df['responsibilities'].str.len()\n        \n        # Keyword matching between responsibilities\n        df['resp_match'] = df.apply(\n            lambda x: fuzz.ratio(\n                str(x['responsibilities']), \n                str(x['responsibilities.1'])\n            ) / 100.0,\n            axis=1\n        )\n        \n        return df\n\n    def create_interaction_features(self, df):\n        \"\"\"Create interaction features\"\"\"\n        df['skill_edu_interaction'] = df['skill_match_ratio'] * df['education_match']\n        df['skill_exp_interaction'] = df['skill_match_ratio'] * df['experience_match']\n        df['edu_exp_interaction']   = df['education_match'] * df['experience_match']\n        return df\n\n    ##############################\n    # TEXT EMBEDDINGS WITH TF-IDF\n    ##############################\n    def encode_text_features(self, df, text_cols):\n        \"\"\"Encode text features using TF-IDF Vectorization and return a DataFrame of embeddings.\"\"\"\n        encoded_features = []  # Initialize as a list\n        \n        for col in text_cols:\n            if col not in df.columns:\n                continue\n            print(f\"Encoding {col} with TF-IDF Vectorization...\")\n            # Initialize TF-IDF Vectorizer\n            tfidf = TfidfVectorizer(max_features=500, ngram_range=(1,2))  # Adjust max_features as needed\n            # Fit on training data\n            tfidf.fit(df[col].fillna('').astype(str))\n            # Transform both train and test data\n            train_tfidf = tfidf.transform(df[col].fillna('').astype(str))\n            # Convert to DataFrame\n            tfidf_df = pd.DataFrame(train_tfidf.toarray(), \n                                    columns=[f\"{col}_tfidf_{i}\" for i in range(train_tfidf.shape[1])], \n                                    index=df.index)\n            encoded_features.append(tfidf_df)  # Append to the list\n            # Store the vectorizer for potential future use (e.g., transforming new data)\n            self.tfidf_vectorizers[col] = tfidf\n        \n        if encoded_features:\n            encoded_features_df = pd.concat(encoded_features, axis=1)\n        else:\n            encoded_features_df = pd.DataFrame(index=df.index)\n        \n        return encoded_features_df\n\n    def reduce_dimensions(self, train_df, test_df, text_cols, n_components=50):\n        \"\"\"Reduce dimension of TF-IDF embeddings with Truncated SVD.\"\"\"\n        print(\"\\nReducing dimensions of TF-IDF embeddings via Truncated SVD...\")\n        for col in text_cols:\n            tfidf_cols = [c for c in train_df.columns if f'{col}_tfidf_' in c]\n            if not tfidf_cols:\n                continue\n            \n            print(f\"Processing {col} TF-IDF embeddings (Truncated SVD n={n_components})...\")\n            svd = TruncatedSVD(\n                n_components=min(n_components, len(tfidf_cols)),\n                random_state=self.seed\n            )\n            \n            # Fit on training data\n            train_svd = svd.fit_transform(train_df[tfidf_cols])\n            # Transform test data\n            test_svd  = svd.transform(test_df[tfidf_cols])\n            \n            # Add reduced dimensions as new features\n            for i in range(train_svd.shape[1]):\n                train_df[f'{col}_svd_{i}'] = train_svd[:, i]\n                test_df[f'{col}_svd_{i}']  = test_svd[:, i]\n            \n            # Drop original TF-IDF embedding columns to save memory\n            train_df.drop(tfidf_cols, axis=1, inplace=True)\n            test_df.drop(tfidf_cols, axis=1, inplace=True)\n            gc.collect()\n            \n        return train_df, test_df\n\n    ##############################\n    # MODEL TRAINING AND PREDICTION\n    ##############################\n    def evaluate_mse(self, y_true, y_pred):\n        \"\"\"Calculate Mean Squared Error\"\"\"\n        return mean_squared_error(y_true, y_pred)\n    \n    def build_nn(self, input_dim):\n        \"\"\"Build a simple Neural Network using TensorFlow Keras.\"\"\"\n        model = models.Sequential()\n        model.add(layers.Dense(256, activation='relu', input_shape=(input_dim,)))\n        model.add(layers.Dropout(0.2))\n        model.add(layers.Dense(128, activation='relu'))\n        model.add(layers.Dropout(0.2))\n        model.add(layers.Dense(64, activation='relu'))\n        model.add(layers.Dense(1, activation='linear'))  # Regression output\n        \n        optimizer = tf.keras.optimizers.Adam(learning_rate=self.nn_params['learning_rate'])\n        model.compile(loss='mse', optimizer=optimizer)\n        return model\n\n    def train_predict_lgb(self, train_df, test_df, features, target):\n        \"\"\"Train LightGBM with K-Fold Cross-Validation.\"\"\"\n        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.seed)\n        oof_preds = np.zeros(len(train_df))\n        test_preds = np.zeros(len(test_df))\n        fold_mses = []\n        \n        for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n            print(f\"\\n[LightGBM] Fold {fold+1}/{self.n_folds}\")\n            X_train = train_df[features].iloc[train_idx]\n            y_train = train_df[target].iloc[train_idx]\n            X_val   = train_df[features].iloc[val_idx]\n            y_val   = train_df[target].iloc[val_idx]\n            \n            lgb_train = lgb.Dataset(X_train, y_train)\n            lgb_val   = lgb.Dataset(X_val, y_val, reference=lgb_train)\n            \n            # Define callbacks\n            callbacks = [\n                lgb.early_stopping(stopping_rounds=150),\n                lgb.log_evaluation(period=300)\n            ]\n            \n            model = lgb.train(\n                self.lgb_params,\n                lgb_train,\n                valid_sets=[lgb_train, lgb_val],\n                num_boost_round=15000,\n                callbacks=callbacks\n            )\n            \n            # Predict on validation set\n            val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n            mse_val  = self.evaluate_mse(y_val, val_pred)\n            fold_mses.append(mse_val)\n            print(f\"Fold {fold+1} MSE: {mse_val:.6f}\")\n            \n            # Store out-of-fold predictions\n            oof_preds[val_idx] = val_pred\n            \n            # Predict on test set\n            test_pred = model.predict(test_df[features], num_iteration=model.best_iteration)\n            test_preds += test_pred / self.n_folds  # Average over folds\n        \n        # Average MSE across folds\n        avg_mse = np.mean(fold_mses)\n        std_mse = np.std(fold_mses)\n        print(f\"\\n[LightGBM] CV MSE: {avg_mse:.6f} ± {std_mse:.6f}\")\n        \n        return oof_preds, test_preds, avg_mse\n\n    def train_predict_nn(self, train_df, test_df, features, target):\n        \"\"\"Train Neural Network with K-Fold Cross-Validation.\"\"\"\n        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.seed)\n        oof_preds = np.zeros(len(train_df))\n        test_preds = np.zeros(len(test_df))\n        fold_mses = []\n        X_test_np = test_df[features].values.astype('float32')\n        \n        for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n            print(f\"\\n[NeuralNet] Fold {fold+1}/{self.n_folds}\")\n            X_train = train_df[features].iloc[train_idx].values.astype('float32')\n            y_train = train_df[target].iloc[train_idx].values.astype('float32')\n            X_val   = train_df[features].iloc[val_idx].values.astype('float32')\n            y_val   = train_df[target].iloc[val_idx].values.astype('float32')\n            \n            # Build and compile the model\n            model = self.build_nn(input_dim=X_train.shape[1])\n            \n            # Early stopping\n            es = EarlyStopping(\n                monitor='val_loss',\n                patience=5,\n                restore_best_weights=True,\n                verbose=1\n            )\n            \n            # Train the model\n            model.fit(\n                X_train, y_train,\n                validation_data=(X_val, y_val),\n                epochs=self.nn_params['epochs'],\n                batch_size=self.nn_params['batch_size'],\n                callbacks=[es],\n                verbose=1\n            )\n            \n            # Predict on validation set\n            val_pred = model.predict(X_val).reshape(-1)\n            \n            # Check for NaNs in predictions\n            if np.isnan(val_pred).any():\n                print(f\"Warning: Fold {fold+1} Neural Network predictions contain NaNs. Replacing NaNs with 0.\")\n                val_pred = np.nan_to_num(val_pred, nan=0.0)\n            \n            mse_val  = self.evaluate_mse(y_val, val_pred)\n            fold_mses.append(mse_val)\n            print(f\"Fold {fold+1} NN MSE: {mse_val:.6f}\")\n            \n            # Store out-of-fold predictions\n            oof_preds[val_idx] = val_pred\n            \n            # Predict on test set\n            test_pred = model.predict(X_test_np).reshape(-1)\n            \n            # Check for NaNs in predictions\n            if np.isnan(test_pred).any():\n                print(f\"Warning: Fold {fold+1} Neural Network test predictions contain NaNs. Replacing NaNs with 0.\")\n                test_pred = np.nan_to_num(test_pred, nan=0.0)\n            \n            test_preds += test_pred / self.n_folds  # Average over folds\n        \n        # Average MSE across folds\n        avg_mse = np.mean(fold_mses)\n        std_mse = np.std(fold_mses)\n        print(f\"\\n[NeuralNet] CV MSE: {avg_mse:.6f} ± {std_mse:.6f}\")\n        \n        return oof_preds, test_preds, avg_mse\n\n    ##############################\n    # MAIN ENTRY POINT\n    ##############################\n    def process_and_train(self, train_path, test_path):\n        \"\"\"Main method to process data, train models, and predict.\"\"\"\n        # 1. Load data\n        print(\"Loading data...\")\n        train_df = pd.read_csv(train_path)\n        test_df  = pd.read_csv(test_path)\n        \n        # 2. Feature extraction\n        print(\"\\nExtracting features...\")\n        for df in [train_df, test_df]:\n            df = self.extract_education_features(df)\n            df = self.extract_experience_features(df)\n            df = self.extract_skill_features(df)\n            df = self.extract_text_features(df)\n            df = self.create_interaction_features(df)\n        \n        # 3. Encode categorical variables\n        print(\"\\nEncoding categorical features...\")\n        categorical_cols = ['educational_institution_name', 'major_field_of_studies']\n        for col in categorical_cols:\n            if col in train_df.columns:\n                le = LabelEncoder()\n                # Fill NaNs with 'unknown' before encoding\n                train_df[f'{col}_encoded'] = le.fit_transform(train_df[col].fillna('unknown'))\n                test_df[f'{col}_encoded']  = le.transform(test_df[col].fillna('unknown'))\n        \n        # 4. Encode text features using TF-IDF Vectorization\n        print(\"\\nEncoding text features with TF-IDF Vectorization...\")\n        text_cols = ['career_objective', 'responsibilities', 'educationaL_requirements']\n        train_emb = self.encode_text_features(train_df, text_cols)\n        test_emb  = self.encode_text_features(test_df, text_cols)\n        \n        # 5. Combine embeddings with main dataframe\n        print(\"\\nCombining text embeddings with main features...\")\n        train_feat = pd.concat([train_df, train_emb], axis=1)\n        test_feat  = pd.concat([test_df, test_emb], axis=1)\n        \n        # 6. Reduce dimensionality of text embeddings\n        train_feat, test_feat = self.reduce_dimensions(\n            train_feat, \n            test_feat, \n            text_cols,\n            n_components=50  # Adjust as needed\n        )\n        \n        # 7. Define feature columns\n        print(\"\\nDefining feature columns...\")\n        drop_cols = ['matched_score', 'ID']  # Adjust if your ID column has a different name\n        feature_cols = [\n            c for c in train_feat.columns \n            if c not in drop_cols\n               and (train_feat[c].dtype in [np.float64, np.float32, np.int64, np.int32])\n        ]\n        print(f\"Total features: {len(feature_cols)}\")\n        \n        # 8. Check for NaNs in features before scaling\n        print(\"\\nChecking for NaN values in training features before scaling...\")\n        train_nan = train_feat[feature_cols].isnull().sum().sum()\n        test_nan = test_feat[feature_cols].isnull().sum().sum()\n        print(f\"Training features contain {train_nan} NaN values.\")\n        print(f\"Testing features contain {test_nan} NaN values.\")\n        \n        if train_nan > 0 or test_nan > 0:\n            print(\"Filling NaN values with 0 in features.\")\n            train_feat[feature_cols] = train_feat[feature_cols].fillna(0)\n            test_feat[feature_cols]  = test_feat[feature_cols].fillna(0)\n        \n        # 9. Scale numeric features\n        print(\"\\nScaling numeric features...\")\n        scaler = StandardScaler()\n        train_feat[feature_cols] = scaler.fit_transform(train_feat[feature_cols])\n        test_feat[feature_cols]  = scaler.transform(test_feat[feature_cols])\n        \n        # 10. Check for NaNs after scaling\n        print(\"\\nChecking for NaN values in features after scaling...\")\n        train_nan_scaled = train_feat[feature_cols].isnull().sum().sum()\n        test_nan_scaled = test_feat[feature_cols].isnull().sum().sum()\n        print(f\"Training features after scaling contain {train_nan_scaled} NaN values.\")\n        print(f\"Testing features after scaling contain {test_nan_scaled} NaN values.\")\n        \n        if train_nan_scaled > 0 or test_nan_scaled > 0:\n            print(\"Filling NaN values with 0 in scaled features.\")\n            train_feat[feature_cols] = train_feat[feature_cols].fillna(0)\n            test_feat[feature_cols]  = test_feat[feature_cols].fillna(0)\n        \n        # 11. Train LightGBM\n        print(\"\\n========== LightGBM Training ==========\")\n        lgb_oof, lgb_test, lgb_mse = self.train_predict_lgb(\n            train_feat, test_feat, feature_cols, 'matched_score'\n        )\n        \n        # 12. Train Neural Network\n        print(\"\\n========== Neural Network Training ==========\")\n        nn_oof, nn_test, nn_mse = self.train_predict_nn(\n            train_feat, test_feat, feature_cols, 'matched_score'\n        )\n        \n        # 13. Ensemble Predictions\n        print(\"\\n========== Ensembling Predictions ==========\")\n        ensemble_oof = (lgb_oof + nn_oof) / 2.0\n        ensemble_test= (lgb_test + nn_test) / 2.0\n        \n        # 14. Evaluate Ensemble MSE on Training Data's OOF Predictions\n        print(\"\\nEvaluating Ensemble MSE on OOF Predictions...\")\n        y_true = train_feat['matched_score'].values\n        ensemble_mse = self.evaluate_mse(y_true, ensemble_oof)\n        print(f\"Ensemble MSE: {ensemble_mse:.6f}\")\n        \n        # 15. Prepare Final Submission\n        print(\"\\nPreparing Final Submission...\")\n        # Verify if 'ID' exists in test set\n        if 'ID' not in test_feat.columns:\n            raise ValueError(\"Test dataset does not contain 'ID' column. Please adjust the identifier column name.\")\n        \n        submission = pd.DataFrame({\n            'ID': test_feat['ID'],  # Adjust if your ID column has a different name\n            'matched_score': ensemble_test\n        })\n        submission['matched_score'] = np.clip(submission['matched_score'], 0, 1)\n        \n        # Save submission\n        submission_file = \"submission_ensemble.csv\"\n        submission.to_csv(submission_file, index=False)\n        print(f\"Submission saved as '{submission_file}'.\")\n        \n        return {\n            'lgb_mse': lgb_mse,\n            'nn_mse': nn_mse,\n            'ensemble_mse': ensemble_mse,\n            'lgb_predictions': lgb_test,\n            'nn_predictions': nn_test,\n            'ensemble_predictions': ensemble_test,\n            'submission_file': submission_file\n        }\n\n# =========================================================\n# 4. USAGE EXAMPLE\n# =========================================================\nif __name__ == \"__main__\":\n    # Initialize the model\n    model = EnhancedJobMatchingModel()\n    \n    # Define file paths\n    # Adjust these paths based on your environment. For example, in Kaggle:\n    # train_path = \"/kaggle/input/bitfest-datathon-2025/train.csv\"\n    # test_path  = \"/kaggle/input/bitfest-datathon-2025/test.csv\"\n    # For local environments, provide absolute or relative paths.\n    \n    # Example paths (replace with your actual paths)\n    train_path = '/kaggle/input/bitfest-datathon-2025/train.csv'\n    test_path  = '/kaggle/input/bitfest-datathon-2025/test.csv'\n    \n    # Process data, train models, and generate predictions\n    results = model.process_and_train(train_path, test_path)\n    \n    # Display final MSE metrics\n    print(\"\\n--- Summary of MSE ---\")\n    print(f\"LightGBM CV MSE: {results['lgb_mse']:.6f}\")\n    print(f\"Neural Network CV MSE: {results['nn_mse']:.6f}\")\n    print(f\"Ensemble CV MSE: {results['ensemble_mse']:.6f}\")\n    \n    # Optionally, display the first few rows of the submission file\n    print(\"\\n--- Submission Preview ---\")\n    submission_preview = pd.read_csv(results['submission_file']).head()\n    print(submission_preview)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:59:21.283962Z","iopub.execute_input":"2024-12-26T17:59:21.284340Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n\nExtracting features...\n\nEncoding categorical features...\n\nEncoding text features with TF-IDF Vectorization...\nEncoding career_objective with TF-IDF Vectorization...\nEncoding responsibilities with TF-IDF Vectorization...\nEncoding educationaL_requirements with TF-IDF Vectorization...\nEncoding career_objective with TF-IDF Vectorization...\nEncoding responsibilities with TF-IDF Vectorization...\nEncoding educationaL_requirements with TF-IDF Vectorization...\n\nCombining text embeddings with main features...\n\nReducing dimensions of TF-IDF embeddings via Truncated SVD...\nProcessing career_objective TF-IDF embeddings (Truncated SVD n=50)...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}