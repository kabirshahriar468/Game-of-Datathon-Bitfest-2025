{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90798,"databundleVersionId":10606811,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('./'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:18:29.436228Z","iopub.execute_input":"2024-12-27T09:18:29.436626Z","iopub.status.idle":"2024-12-27T09:18:29.442824Z","shell.execute_reply.started":"2024-12-27T09:18:29.436564Z","shell.execute_reply":"2024-12-27T09:18:29.442009Z"}},"outputs":[{"name":"stdout","text":"./submission.csv\n./submission_final.csv\n./log.csv\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"# =========================================================\nimport pandas as pd\nimport numpy as np\nimport ast\nimport re\nfrom datetime import datetime\nfrom dateutil import parser\nfrom collections import Counter\n\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\n\nfrom textblob import TextBlob\nfrom fuzzywuzzy import fuzz\nfrom sklearn.preprocessing import RobustScaler\n\n\nimport gc\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:18:52.374004Z","iopub.execute_input":"2024-12-27T09:18:52.374305Z","iopub.status.idle":"2024-12-27T09:18:52.379619Z","shell.execute_reply.started":"2024-12-27T09:18:52.374280Z","shell.execute_reply":"2024-12-27T09:18:52.378655Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"train_path = '/kaggle/input/bitfest-datathon-2025/train.csv'\ntest_path  = '/kaggle/input/bitfest-datathon-2025/test.csv'\nsample_sub_path = '/kaggle/input/bitfest-datathon-2025/sample_submission.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:18:56.213369Z","iopub.execute_input":"2024-12-27T09:18:56.213685Z","iopub.status.idle":"2024-12-27T09:18:56.217369Z","shell.execute_reply.started":"2024-12-27T09:18:56.213661Z","shell.execute_reply":"2024-12-27T09:18:56.216445Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"seed=42\ndef parse_list( x):\n    \"\"\"Parse string representation of lists\"\"\"\n    if pd.isnull(x):\n        return []\n    try:\n        return ast.literal_eval(x)\n    except:\n        return []\n\ndef extract_skill_overlap( row):\n    \"\"\"Calculate skill overlap ratio\"\"\"\n    candidate = set(row['skills']) if 'skills' in row else set()\n    required  = set(row['skills_required']) if 'skills_required' in row else set()\n    if not candidate or not required:\n        return 0.0\n    inter = candidate.intersection(required)\n    union = candidate.union(required)\n    return len(inter) / len(union) if union else 0.0\n\ndef extract_total_experience_months( row):\n    \"\"\"Calculate total months of experience\"\"\"\n    start_str = row['start_dates']\n    end_str = row['end_dates']\n    start = parse_date(start_str)\n    end = parse_date(end_str)\n    if start is None or end is None:\n        return 0\n    diff = (end.year - start.year)*12 + (end.month - start.month)\n    return max(diff, 0)\n\ndef parse_date( date_str):\n    \"\"\"Parse date string\"\"\"\n    if pd.isnull(date_str):\n        return None\n    if any(word.lower() in str(date_str).lower() for word in ['till','present']):\n        return datetime.now()\n    try:\n        return parser.parse(str(date_str))\n    except:\n        return None\n\ndef extract_passing_year( val):\n    \"\"\"Extract passing year as integer\"\"\"\n    if pd.isnull(val):\n        return 0\n    try:\n        yrs = ast.literal_eval(val)\n        if isinstance(yrs, list) and len(yrs) > 0:\n            yrs_numeric = [int(x) for x in yrs if str(x).isdigit()]\n            if len(yrs_numeric) == 0:\n                return 0\n            return max(yrs_numeric)\n    except:\n        pass\n    return 0\n\n\ndef extract_education_features( df):\n    \"\"\"Enhanced education feature extraction\"\"\"\n    def get_education_level(degree):\n        if pd.isna(degree):\n            return 0\n        degree = degree.lower()\n        if 'phd' in degree or 'doctorate' in degree:\n            return 4\n        elif 'master' in degree or 'mba' in degree:\n            return 3\n        elif 'bachelor' in degree or 'bsc' in degree:\n            return 2\n        elif 'diploma' in degree or 'certificate' in degree:\n            return 1\n        return 0\n\n    df['education_level'] = df['degree_names'].apply(get_education_level)\n\n    def extract_numeric_result(x):\n        if pd.isna(x):\n            return 0.0\n        try:\n            matches = re.findall(r'\\d+\\.?\\d*', str(x))\n            if matches:\n                return float(matches[0])\n            return 0.0\n        except:\n            return 0.0\n\n    df['numeric_result'] = df['educational_results'].apply(extract_numeric_result)\n\n    # Education-job requirement match score using fuzzy matching\n    df['education_match'] = df.apply(\n        lambda x: fuzz.ratio(\n            str(x['degree_names']).lower(), \n            str(x['educationaL_requirements']).lower()\n        ) / 100.0, \n        axis=1\n    )\n\n    return df\n\ndef extract_experience_features( df):\n    \"\"\"Enhanced experience feature extraction\"\"\"\n    df['required_years'] = df['experiencere_requirement'].apply(extract_years)\n\n    # Calculate total experience in months\n    df['total_experience_months'] = df.apply(\n        extract_total_experience_months, axis=1\n    )\n\n    # Experience match score\n    df['experience_match'] = (\n        df['total_experience_months'] / df['required_years'].replace(0, 1)\n    ).clip(0, 2)\n\n    return df\n\ndef extract_years( text):\n    \"\"\"Extract years from text\"\"\"\n    if pd.isna(text):\n        return 0\n    years = re.findall(r'(\\d+)[\\s-]*year', text.lower())\n    return int(years[0]) if years else 0\n\ndef extract_skill_features( df):\n    \"\"\"Enhanced skill feature extraction\"\"\"\n    df['skills'] = df['skills'].apply(parse_list)\n    df['skills_required'] = df['skills_required'].apply(parse_list)\n\n    df['skill_overlap'] = df.apply(extract_skill_overlap, axis=1)\n\n    # Skill coverage\n    df['skill_coverage'] = df.apply(\n        lambda x: len(x['skills']) / max(len(x['skills_required']), 1) \n        if len(x['skills_required']) > 0 else 0, axis=1\n    )\n\n    # Skill importance score\n    skill_freq = Counter()\n    for skills in df['skills']:\n        skill_freq.update(skills)\n    \n    df['skill_importance_score'] = df.apply(\n        lambda x: sum(1/np.log2(skill_freq[skill] + 1) \n                        for skill in set(x['skills']).intersection(set(x['skills_required'])))\n        if len(x['skills_required']) > 0 else 0,\n        axis=1\n    )\n\n    df.drop(['skills', 'skills_required'], axis=1, inplace=True)\n\n    return df\n\ndef extract_text_features( df):\n    \"\"\"Enhanced text feature extraction\"\"\"\n    # Sentiment analysis\n    df['objective_sentiment'] = df['career_objective'].apply(\n        lambda x: TextBlob(str(x)).sentiment.polarity\n    )\n\n    # Text length features\n    df['objective_length'] = df['career_objective'].str.len()\n    df['resp_length'] = df['responsibilities'].str.len()\n\n    # Keyword matching between responsibilities\n    df['resp_match'] = df.apply(\n        lambda x: fuzz.ratio(\n            str(x['responsibilities']), \n            str(x['responsibilities.1'])\n        ) / 100.0,\n        axis=1\n    )\n\n    return df\n\n\ndef create_interaction_features( df):\n    \"\"\"Create interaction features\"\"\"\n    df['skill_edu_interaction'] = df['skill_overlap'] * df['education_match']\n    df['skill_exp_interaction'] = df['skill_overlap'] * df['experience_match']\n    df['edu_exp_interaction'] = df['education_match'] * df['experience_match']\n\n    return df\n\n# def encode_categorical_features( train_df, test_df, categorical_cols):\n#     \"\"\"Encode categorical features using Label Encoding\"\"\"\n#     for col in categorical_cols:\n#         if col in train_df.columns:\n#             le = LabelEncoder()\n#             train_df[f'{col}_encoded'] = le.fit_transform(train_df[col].fillna('unknown'))\n#             test_df[f'{col}_encoded'] = le.transform(test_df[col].fillna('unknown'))\n#     return train_df, test_df\n\n# from sklearn.preprocessing import LabelEncoder\n\ndef encode_categorical_features(train_df, test_df, categorical_cols):\n    \"\"\"\n    Encode categorical features using Label Encoding.\n    If a category is present in the test set but not in the train set, it will be labeled as -1.\n    \"\"\"\n    for col in categorical_cols:\n        if col in train_df.columns:\n            le = LabelEncoder()\n\n            # Combine unique categories from train and test to avoid unseen errors\n            all_categories = pd.concat([train_df[col], test_df[col]], axis=0).fillna('unknown').unique()\n            le.fit(all_categories)\n\n            # Transform train and test datasets\n            train_df[f'{col}_encoded'] = le.transform(train_df[col].fillna('unknown'))\n            test_df[f'{col}_encoded'] = le.transform(test_df[col].fillna('unknown'))\n\n    return train_df, test_df\n\n\ndef extract_text_features_tf_idf_svd_scaled(train_df, test_df, text_cols, max_features=500, n_components=50):\n    \"\"\"Encode text features using TF-IDF Vectorization, SVD, and scale the SVD features.\"\"\"\n    scaler = StandardScaler()  # Initialize the scaler\n    svd_cols = []  # List to store names of SVD columns created\n\n    for col in text_cols:\n        print(f\"Processing TF-IDF for column: {col}\")\n        tfidf = TfidfVectorizer(\n            stop_words='english',\n            max_features=max_features,\n            ngram_range=(1, 2)\n        )\n\n        # Fit TF-IDF on train and transform train/test\n        tfidf.fit(train_df[col].fillna('').astype(str))\n        train_tfidf = tfidf.transform(train_df[col].fillna('').astype(str))\n        test_tfidf = tfidf.transform(test_df[col].fillna('').astype(str))\n\n        # Truncated SVD\n        svd = TruncatedSVD(n_components=n_components, random_state=42)\n        svd.fit(train_tfidf)\n        train_svd = svd.transform(train_tfidf)\n        test_svd = svd.transform(test_tfidf)\n\n        # Scale the SVD components\n        train_svd_scaled = scaler.fit_transform(train_svd)  # Fit and transform on training data\n        test_svd_scaled = scaler.transform(test_svd)        # Transform on test data\n\n        # Add scaled SVD components as new features\n        for i in range(n_components):\n            svd_col_name = f'{col}_svd_scaled_{i}'\n            train_df[svd_col_name] = train_svd_scaled[:, i]\n            test_df[svd_col_name] = test_svd_scaled[:, i]\n            svd_cols.append(svd_col_name)  # Append to the list of SVD columns\n\n    # Drop original text columns\n    train_df.drop(text_cols, axis=1, inplace=True)\n    test_df.drop(text_cols, axis=1, inplace=True)\n    gc.collect()\n\n    return train_df, test_df, svd_cols\n\n\n\n\n\n\ndef prepare_features( train_df, test_df):\n    \"\"\"Prepare features for modeling\"\"\"\n    # Fill missing numeric values with 0\n    numeric_cols = ['skill_overlap', 'skill_coverage', 'skill_importance_score',\n                    'objective_sentiment', 'objective_length', 'resp_length',\n                    'resp_match', 'skill_edu_interaction', 'skill_exp_interaction',\n                    'edu_exp_interaction', 'total_experience_months', 'passing_year']\n    for col in numeric_cols:\n        if col in train_df.columns:\n            train_df[col] = train_df[col].fillna(0)\n        if col in test_df.columns:\n            test_df[col] = test_df[col].fillna(0)\n\n    return train_df, test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:18:57.051735Z","iopub.execute_input":"2024-12-27T09:18:57.052051Z","iopub.status.idle":"2024-12-27T09:18:57.074474Z","shell.execute_reply.started":"2024-12-27T09:18:57.052025Z","shell.execute_reply":"2024-12-27T09:18:57.073656Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"\ndef emphasize_numerical_features(train_df, test_df, numerical_cols, svd_cols, weight_factor=2.0):\n    \"\"\"\n    Emphasize numerical features by scaling them and optionally weighting them more heavily than SVD features.\n    \"\"\"\n    # Initialize scalers\n    numerical_cols = [col for col in numerical_cols if col in train_df.columns and col in test_df.columns]\n    numerical_scaler = StandardScaler()\n    svd_scaler = StandardScaler()\n\n    # Scale and emphasize numerical features\n    train_df[numerical_cols] = numerical_scaler.fit_transform(train_df[numerical_cols])\n    test_df[numerical_cols] = numerical_scaler.transform(test_df[numerical_cols])\n    \n    train_df[numerical_cols] *= weight_factor\n    test_df[numerical_cols] *= weight_factor\n\n    # Scale SVD features\n    train_df[svd_cols] = svd_scaler.fit_transform(train_df[svd_cols])\n    test_df[svd_cols] = svd_scaler.transform(test_df[svd_cols])\n\n    # Combine emphasized numerical and scaled SVD features into separate DataFrames for clarity\n    train_combined = train_df[numerical_cols + svd_cols + ['matched_score']].copy()\n    test_combined = test_df[numerical_cols + svd_cols].copy()\n\n    return train_combined, test_combined\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:01.693130Z","iopub.execute_input":"2024-12-27T09:19:01.693466Z","iopub.status.idle":"2024-12-27T09:19:01.699290Z","shell.execute_reply.started":"2024-12-27T09:19:01.693438Z","shell.execute_reply":"2024-12-27T09:19:01.698164Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\ndef cross_validate_model(train_df, features, target, params_hgb, params_gb, test_df, n_folds=5, random_state=42):\n    \"\"\"\n    Perform K-Fold Cross-Validation with HistGradientBoostingRegressor and GradientBoostingRegressor.\n    \n    Args:\n    - train_df (pd.DataFrame): Training data.\n    - features (list): List of feature column names.\n    - target (str): Target column name.\n    - params_hgb (dict): Parameters for HistGradientBoostingRegressor.\n    - params_gb (dict): Parameters for GradientBoostingRegressor.\n    - test_df (pd.DataFrame): Testing data (features only).\n    - n_folds (int): Number of folds for cross-validation.\n    - random_state (int): Random state for reproducibility.\n\n    Returns:\n    - final_test_preds (np.array): Averaged predictions for the test set.\n    - avg_mse (float): Average MSE across folds for both models.\n    \"\"\"\n    # Initialize KFold\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\n    # Initialize variables for predictions and metrics\n    oof_preds_hgb = np.zeros(len(train_df))\n    oof_preds_gb = np.zeros(len(train_df))\n    test_preds_hgb = np.zeros(len(test_df))\n    test_preds_gb = np.zeros(len(test_df))\n    fold_mses_hgb = []\n    fold_mses_gb = []\n\n    # Perform K-Fold Cross-Validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n        print(f'\\nTraining fold {fold + 1} / {n_folds}')\n        \n        # Split data into training and validation folds\n        X_train_fold = train_df.iloc[train_idx][features]\n        y_train_fold = train_df.iloc[train_idx][target]\n        X_val_fold = train_df.iloc[val_idx][features]\n        y_val_fold = train_df.iloc[val_idx][target]\n        \n        # Train HistGradientBoostingRegressor\n        hgb = HistGradientBoostingRegressor(**params_hgb)\n        hgb.fit(X_train_fold, y_train_fold)\n        y_pred_hgb = hgb.predict(X_val_fold)\n        mse_hgb = mean_squared_error(y_val_fold, y_pred_hgb)\n        fold_mses_hgb.append(mse_hgb)\n        print(f\"Fold {fold + 1} HistGradientBoostingRegressor MSE: {mse_hgb:.6f}\")\n        oof_preds_hgb[val_idx] = y_pred_hgb\n        \n        # Predict on test set\n        y_test_pred_hgb = hgb.predict(test_df[features])\n        test_preds_hgb += y_test_pred_hgb / n_folds\n        \n        # Train GradientBoostingRegressor\n        gb = GradientBoostingRegressor(**params_gb)\n        gb.fit(X_train_fold, y_train_fold)\n        y_pred_gb = gb.predict(X_val_fold)\n        mse_gb = mean_squared_error(y_val_fold, y_pred_gb)\n        fold_mses_gb.append(mse_gb)\n        print(f\"Fold {fold + 1} GradientBoostingRegressor MSE: {mse_gb:.6f}\")\n        oof_preds_gb[val_idx] = y_pred_gb\n        \n        # Predict on test set\n        y_test_pred_gb = gb.predict(test_df[features])\n        test_preds_gb += y_test_pred_gb / n_folds\n    \n    # Calculate average MSE\n    avg_mse_hgb = np.mean(fold_mses_hgb)\n    avg_mse_gb = np.mean(fold_mses_gb)\n    print(f\"\\nAverage HistGradientBoostingRegressor MSE: {avg_mse_hgb:.6f}\")\n    print(f\"Average GradientBoostingRegressor MSE: {avg_mse_gb:.6f}\")\n    \n    # Average predictions from both models\n    final_test_preds = (test_preds_hgb + test_preds_gb) / 2\n    \n    return final_test_preds, (avg_mse_hgb + avg_mse_gb) / 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:05.498544Z","iopub.execute_input":"2024-12-27T09:19:05.498858Z","iopub.status.idle":"2024-12-27T09:19:05.506929Z","shell.execute_reply.started":"2024-12-27T09:19:05.498834Z","shell.execute_reply":"2024-12-27T09:19:05.506027Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\nsample_submission = pd.read_csv(sample_sub_path)\n\nprint(\"Initial train shape:\", train_df.shape)\nprint(\"Initial test shape:\", test_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:09.127299Z","iopub.execute_input":"2024-12-27T09:19:09.127636Z","iopub.status.idle":"2024-12-27T09:19:09.293405Z","shell.execute_reply.started":"2024-12-27T09:19:09.127607Z","shell.execute_reply":"2024-12-27T09:19:09.292478Z"}},"outputs":[{"name":"stdout","text":"Initial train shape: (7635, 35)\nInitial test shape: (1909, 35)\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"# Drop columns >80% missing\ncol_threshold = 0.8\ncols_to_drop = [col for col in train_df.columns if train_df[col].isnull().mean() > col_threshold]\ntrain_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\ntest_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\nprint(\"Dropped columns:\", cols_to_drop)\n\n# Drop rows with <5 non-null in train\nrow_threshold = 5\nbefore_rows = len(train_df)\ntrain_df.dropna(thresh=row_threshold, axis=0, inplace=True)\nafter_rows = len(train_df)\nprint(f\"Dropped {before_rows - after_rows} rows with < {row_threshold} non-null columns.\")\n\nprint(\"Train shape after drops:\", train_df.shape)\nprint(\"Test shape after drops:\", test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:11.113703Z","iopub.execute_input":"2024-12-27T09:19:11.114002Z","iopub.status.idle":"2024-12-27T09:19:11.152843Z","shell.execute_reply.started":"2024-12-27T09:19:11.113979Z","shell.execute_reply":"2024-12-27T09:19:11.151847Z"}},"outputs":[{"name":"stdout","text":"Dropped columns: ['address', 'languages', 'proficiency_levels']\nDropped 0 rows with < 5 non-null columns.\nTrain shape after drops: (7635, 32)\nTest shape after drops: (1909, 32)\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"print(\"\\nExtracting features...\")\nfor df in [train_df, test_df]:\n    df = extract_education_features(df)\n    df = extract_experience_features(df)\n    df = extract_skill_features(df)\n    df = extract_text_features(df)\n    df = create_interaction_features(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:12.035362Z","iopub.execute_input":"2024-12-27T09:19:12.035676Z","iopub.status.idle":"2024-12-27T09:19:16.258143Z","shell.execute_reply.started":"2024-12-27T09:19:12.035651Z","shell.execute_reply":"2024-12-27T09:19:16.257478Z"}},"outputs":[{"name":"stdout","text":"\nExtracting features...\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:19.105882Z","iopub.execute_input":"2024-12-27T09:19:19.106204Z","iopub.status.idle":"2024-12-27T09:19:19.110137Z","shell.execute_reply.started":"2024-12-27T09:19:19.106179Z","shell.execute_reply":"2024-12-27T09:19:19.109055Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"#train_df.head()\ntrain_df.info()\n#train_df['educational_institution_name']\nnumerical = train_df.select_dtypes(include=['int64', 'float64','int32', 'float32'])\nnumerical_cols = numerical.columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:23.232470Z","iopub.execute_input":"2024-12-27T09:19:23.232774Z","iopub.status.idle":"2024-12-27T09:19:23.256295Z","shell.execute_reply.started":"2024-12-27T09:19:23.232751Z","shell.execute_reply":"2024-12-27T09:19:23.255314Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7635 entries, 0 to 7634\nData columns (total 46 columns):\n #   Column                               Non-Null Count  Dtype  \n---  ------                               --------------  -----  \n 0   career_objective                     3794 non-null   object \n 1   educational_institution_name         7574 non-null   object \n 2   degree_names                         7574 non-null   object \n 3   passing_years                        7574 non-null   object \n 4   educational_results                  7574 non-null   object \n 5   result_types                         7574 non-null   object \n 6   major_field_of_studies               7574 non-null   object \n 7   professional_company_names           7568 non-null   object \n 8   company_urls                         7568 non-null   object \n 9   start_dates                          7568 non-null   object \n 10  end_dates                            7568 non-null   object \n 11  related_skils_in_job                 7568 non-null   object \n 12  positions                            7568 non-null   object \n 13  locations                            7568 non-null   object \n 14  responsibilities                     7635 non-null   object \n 15  extra_curricular_activity_types      2732 non-null   object \n 16  extra_curricular_organization_names  2732 non-null   object \n 17  extra_curricular_organization_links  2732 non-null   object \n 18  role_positions                       2732 non-null   object \n 19  certification_providers              1587 non-null   object \n 20  certification_skills                 1587 non-null   object \n 21  online_links                         1587 non-null   object \n 22  issue_dates                          1587 non-null   object \n 23  expiry_dates                         1587 non-null   object \n 24  ﻿job_position_name                   7635 non-null   object \n 25  educationaL_requirements             7635 non-null   object \n 26  experiencere_requirement             6549 non-null   object \n 27  age_requirement                      4371 non-null   object \n 28  responsibilities.1                   7635 non-null   object \n 29  matched_score                        7635 non-null   float64\n 30  education_level                      7635 non-null   int64  \n 31  numeric_result                       7635 non-null   float64\n 32  education_match                      7635 non-null   float64\n 33  required_years                       7635 non-null   int64  \n 34  total_experience_months              7635 non-null   int64  \n 35  experience_match                     7635 non-null   float64\n 36  skill_overlap                        7635 non-null   float64\n 37  skill_coverage                       7635 non-null   int64  \n 38  skill_importance_score               7635 non-null   int64  \n 39  objective_sentiment                  7635 non-null   float64\n 40  objective_length                     3794 non-null   float64\n 41  resp_length                          7635 non-null   int64  \n 42  resp_match                           7635 non-null   float64\n 43  skill_edu_interaction                7635 non-null   float64\n 44  skill_exp_interaction                7635 non-null   float64\n 45  edu_exp_interaction                  7635 non-null   float64\ndtypes: float64(11), int64(6), object(29)\nmemory usage: 2.7+ MB\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# Define categorical columns\ncategorical_cols = [\n    'educational_institution_name',\n    'major_field_of_studies',\n    'degree_names',\n    'result_types',\n    'professional_company_names',\n    'role_positions',\n    'certification_providers',\n    'extra_curricular_organization_names'\n]\n\n# Encode categorical features\ntrain_df, test_df = encode_categorical_features(train_df, test_df, categorical_cols)\n\n# Define text columns\ntext_cols = [\n    'career_objective',\n    'responsibilities',\n    'responsibilities.1',\n    'educationaL_requirements',\n    'related_skils_in_job',\n    'certification_skills',\n    'extra_curricular_activity_types',\n    '﻿job_position_name'\n]\n\n# Encode text features using TF-IDF and SVD\ntrain_df, test_df, svd_cols = extract_text_features_tf_idf_svd_scaled(\n    train_df, test_df, text_cols, max_features=500, n_components=25\n)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:28.191146Z","iopub.execute_input":"2024-12-27T09:19:28.191462Z","iopub.status.idle":"2024-12-27T09:19:32.787129Z","shell.execute_reply.started":"2024-12-27T09:19:28.191435Z","shell.execute_reply":"2024-12-27T09:19:32.786298Z"}},"outputs":[{"name":"stdout","text":"Processing TF-IDF for column: career_objective\nProcessing TF-IDF for column: responsibilities\nProcessing TF-IDF for column: responsibilities.1\nProcessing TF-IDF for column: educationaL_requirements\nProcessing TF-IDF for column: related_skils_in_job\nProcessing TF-IDF for column: certification_skills\nProcessing TF-IDF for column: extra_curricular_activity_types\nProcessing TF-IDF for column: ﻿job_position_name\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"numerical_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:37.128392Z","iopub.execute_input":"2024-12-27T09:19:37.128774Z","iopub.status.idle":"2024-12-27T09:19:37.134078Z","shell.execute_reply.started":"2024-12-27T09:19:37.128742Z","shell.execute_reply":"2024-12-27T09:19:37.133036Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"['matched_score',\n 'education_level',\n 'numeric_result',\n 'education_match',\n 'required_years',\n 'total_experience_months',\n 'experience_match',\n 'skill_overlap',\n 'skill_coverage',\n 'skill_importance_score',\n 'objective_sentiment',\n 'objective_length',\n 'resp_length',\n 'resp_match',\n 'skill_edu_interaction',\n 'skill_exp_interaction',\n 'edu_exp_interaction']"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"train_df, test_df = emphasize_numerical_features(train_df, test_df, numerical_cols, svd_cols, weight_factor=2.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:39.959303Z","iopub.execute_input":"2024-12-27T09:19:39.959654Z","iopub.status.idle":"2024-12-27T09:19:40.079593Z","shell.execute_reply.started":"2024-12-27T09:19:39.959624Z","shell.execute_reply":"2024-12-27T09:19:40.078933Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"\ndrop_cols = ['matched_score', 'ID']\ntarget_col='matched_score'\nfeature_cols = [\n    c for c in train_df.columns\n    if c not in drop_cols\n        and (train_df[c].dtype in [np.float64, np.int64, np.float32, np.int32])\n]\n# Fill missing numeric values\ntrain_df, test_df = prepare_features(train_df, test_df)\noutlier_threshold = 3.0  # Define threshold for identifying outliers (z-score method)\n        \ndef handle_outliers(df, columns):\n    for col in columns:\n        if df[col].dtype in [np.float64, np.int64, np.float32, np.int32]:\n            # Calculate z-scores\n            z_scores = (df[col] - df[col].mean()) / df[col].std()\n            \n            # Winsorize extreme values (cap outliers)\n            upper_limit = df[col].mean() + outlier_threshold * df[col].std()\n            lower_limit = df[col].mean() - outlier_threshold * df[col].std()\n            \n            df[col] = np.clip(df[col], lower_limit, upper_limit)\n    return df\n    \n# Apply outlier handling on both train and test sets\ntrain_df = handle_outliers(train_df, feature_cols)\ntest_df = handle_outliers(test_df, feature_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:19:57.039791Z","iopub.execute_input":"2024-12-27T09:19:57.040100Z","iopub.status.idle":"2024-12-27T09:19:57.743329Z","shell.execute_reply.started":"2024-12-27T09:19:57.040078Z","shell.execute_reply":"2024-12-27T09:19:57.742392Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# def select_important_features(train_df, test_df, target, top_k=20):\n#     \"\"\"\n#     Select top `k` features based on importance using a random forest.\n#     \"\"\"\n#     # Split into features and target\n#     X_train = train_df.drop(columns=[target])\n#     y_train = train_df[target]\n    \n#     # Train a random forest to get feature importance\n#     model = RandomForestClassifier(random_state=42)\n#     model.fit(X_train, y_train)\n    \n#     # Get feature importance\n#     feature_importance = pd.Series(model.feature_importances_, index=X_train.columns)\n#     important_features = feature_importance.nlargest(top_k).index\n    \n#     # Filter top features\n#     train_df = train_df[important_features]\n#     test_df = test_df[important_features]\n    \n#     return train_df, test_df\n\n\n# Use Random Forest to estimate feature importance\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(train_df[feature_cols], train_df[target_col])\n\n# Feature importance\nfeature_importances = pd.Series(model.feature_importances_, index=feature_cols)\nprint(\"Feature Importances:\")\nprint(feature_importances)\n\n# Select features based on importance threshold\nimportant_features = feature_importances[feature_importances > 0.001].index.tolist()\nprint(f\"Selected features: {len(important_features)} out of {len(feature_cols)}\")\n\n# Drop less important features\ntrain_df = train_df[important_features + [target_col]]\ntest_df = test_df[important_features]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:20:03.800092Z","iopub.execute_input":"2024-12-27T09:20:03.800402Z","iopub.status.idle":"2024-12-27T09:20:38.275310Z","shell.execute_reply.started":"2024-12-27T09:20:03.800373Z","shell.execute_reply":"2024-12-27T09:20:38.274242Z"}},"outputs":[{"name":"stdout","text":"Feature Importances:\neducation_level                                  0.020773\nnumeric_result                                   0.009513\neducation_match                                  0.077909\nrequired_years                                   0.004556\ntotal_experience_months                          0.000000\nexperience_match                                 0.000000\nskill_overlap                                    0.000000\nskill_coverage                                   0.000000\nskill_importance_score                           0.000000\nobjective_sentiment                              0.003024\nobjective_length                                 0.008161\nresp_length                                      0.102434\nresp_match                                       0.000000\nskill_edu_interaction                            0.000000\nskill_exp_interaction                            0.000000\nedu_exp_interaction                              0.000000\ncareer_objective_svd_scaled_0                    0.034674\ncareer_objective_svd_scaled_1                    0.019782\ncareer_objective_svd_scaled_2                    0.006335\ncareer_objective_svd_scaled_3                    0.008346\ncareer_objective_svd_scaled_4                    0.003842\ncareer_objective_svd_scaled_5                    0.006626\ncareer_objective_svd_scaled_6                    0.003472\ncareer_objective_svd_scaled_7                    0.003348\ncareer_objective_svd_scaled_8                    0.003963\ncareer_objective_svd_scaled_9                    0.002898\ncareer_objective_svd_scaled_10                   0.003528\ncareer_objective_svd_scaled_11                   0.002470\ncareer_objective_svd_scaled_12                   0.006300\ncareer_objective_svd_scaled_13                   0.002967\ncareer_objective_svd_scaled_14                   0.003346\ncareer_objective_svd_scaled_15                   0.007772\ncareer_objective_svd_scaled_16                   0.004928\ncareer_objective_svd_scaled_17                   0.004150\ncareer_objective_svd_scaled_18                   0.009179\ncareer_objective_svd_scaled_19                   0.003677\ncareer_objective_svd_scaled_20                   0.005948\ncareer_objective_svd_scaled_21                   0.004812\ncareer_objective_svd_scaled_22                   0.003500\ncareer_objective_svd_scaled_23                   0.004939\ncareer_objective_svd_scaled_24                   0.003048\nresponsibilities_svd_scaled_0                    0.001301\nresponsibilities_svd_scaled_1                    0.001217\nresponsibilities_svd_scaled_2                    0.004189\nresponsibilities_svd_scaled_3                    0.001319\nresponsibilities_svd_scaled_4                    0.001756\nresponsibilities_svd_scaled_5                    0.001587\nresponsibilities_svd_scaled_6                    0.001956\nresponsibilities_svd_scaled_7                    0.002849\nresponsibilities_svd_scaled_8                    0.001438\nresponsibilities_svd_scaled_9                    0.001314\nresponsibilities_svd_scaled_10                   0.001894\nresponsibilities_svd_scaled_11                   0.001866\nresponsibilities_svd_scaled_12                   0.000902\nresponsibilities_svd_scaled_13                   0.001380\nresponsibilities_svd_scaled_14                   0.001440\nresponsibilities_svd_scaled_15                   0.004386\nresponsibilities_svd_scaled_16                   0.000946\nresponsibilities_svd_scaled_17                   0.028644\nresponsibilities_svd_scaled_18                   0.001309\nresponsibilities_svd_scaled_19                   0.001119\nresponsibilities_svd_scaled_20                   0.003813\nresponsibilities_svd_scaled_21                   0.001875\nresponsibilities_svd_scaled_22                   0.001357\nresponsibilities_svd_scaled_23                   0.001177\nresponsibilities_svd_scaled_24                   0.002684\nresponsibilities.1_svd_scaled_0                  0.001771\nresponsibilities.1_svd_scaled_1                  0.001291\nresponsibilities.1_svd_scaled_2                  0.003793\nresponsibilities.1_svd_scaled_3                  0.002276\nresponsibilities.1_svd_scaled_4                  0.002657\nresponsibilities.1_svd_scaled_5                  0.001514\nresponsibilities.1_svd_scaled_6                  0.002447\nresponsibilities.1_svd_scaled_7                  0.004376\nresponsibilities.1_svd_scaled_8                  0.001400\nresponsibilities.1_svd_scaled_9                  0.001072\nresponsibilities.1_svd_scaled_10                 0.001292\nresponsibilities.1_svd_scaled_11                 0.001876\nresponsibilities.1_svd_scaled_12                 0.001200\nresponsibilities.1_svd_scaled_13                 0.001269\nresponsibilities.1_svd_scaled_14                 0.001482\nresponsibilities.1_svd_scaled_15                 0.003036\nresponsibilities.1_svd_scaled_16                 0.000959\nresponsibilities.1_svd_scaled_17                 0.023523\nresponsibilities.1_svd_scaled_18                 0.001117\nresponsibilities.1_svd_scaled_19                 0.001409\nresponsibilities.1_svd_scaled_20                 0.003781\nresponsibilities.1_svd_scaled_21                 0.001462\nresponsibilities.1_svd_scaled_22                 0.001250\nresponsibilities.1_svd_scaled_23                 0.001347\nresponsibilities.1_svd_scaled_24                 0.003165\neducationaL_requirements_svd_scaled_0            0.002019\neducationaL_requirements_svd_scaled_1            0.001086\neducationaL_requirements_svd_scaled_2            0.001897\neducationaL_requirements_svd_scaled_3            0.001232\neducationaL_requirements_svd_scaled_4            0.000783\neducationaL_requirements_svd_scaled_5            0.002240\neducationaL_requirements_svd_scaled_6            0.068614\neducationaL_requirements_svd_scaled_7            0.001171\neducationaL_requirements_svd_scaled_8            0.000927\neducationaL_requirements_svd_scaled_9            0.001405\neducationaL_requirements_svd_scaled_10           0.000943\neducationaL_requirements_svd_scaled_11           0.001205\neducationaL_requirements_svd_scaled_12           0.001020\neducationaL_requirements_svd_scaled_13           0.000907\neducationaL_requirements_svd_scaled_14           0.001076\neducationaL_requirements_svd_scaled_15           0.000768\neducationaL_requirements_svd_scaled_16           0.001028\neducationaL_requirements_svd_scaled_17           0.001925\neducationaL_requirements_svd_scaled_18           0.000875\neducationaL_requirements_svd_scaled_19           0.000905\neducationaL_requirements_svd_scaled_20           0.002188\neducationaL_requirements_svd_scaled_21           0.001221\neducationaL_requirements_svd_scaled_22           0.001172\neducationaL_requirements_svd_scaled_23           0.000892\neducationaL_requirements_svd_scaled_24           0.002278\nrelated_skils_in_job_svd_scaled_0                0.022545\nrelated_skils_in_job_svd_scaled_1                0.010191\nrelated_skils_in_job_svd_scaled_2                0.009029\nrelated_skils_in_job_svd_scaled_3                0.009277\nrelated_skils_in_job_svd_scaled_4                0.037311\nrelated_skils_in_job_svd_scaled_5                0.011043\nrelated_skils_in_job_svd_scaled_6                0.013362\nrelated_skils_in_job_svd_scaled_7                0.008755\nrelated_skils_in_job_svd_scaled_8                0.010770\nrelated_skils_in_job_svd_scaled_9                0.010535\nrelated_skils_in_job_svd_scaled_10               0.006435\nrelated_skils_in_job_svd_scaled_11               0.008750\nrelated_skils_in_job_svd_scaled_12               0.007752\nrelated_skils_in_job_svd_scaled_13               0.010170\nrelated_skils_in_job_svd_scaled_14               0.008317\nrelated_skils_in_job_svd_scaled_15               0.007603\nrelated_skils_in_job_svd_scaled_16               0.008808\nrelated_skils_in_job_svd_scaled_17               0.007992\nrelated_skils_in_job_svd_scaled_18               0.006722\nrelated_skils_in_job_svd_scaled_19               0.007193\nrelated_skils_in_job_svd_scaled_20               0.007903\nrelated_skils_in_job_svd_scaled_21               0.007039\nrelated_skils_in_job_svd_scaled_22               0.009881\nrelated_skils_in_job_svd_scaled_23               0.008510\nrelated_skils_in_job_svd_scaled_24               0.009245\ncertification_skills_svd_scaled_0                0.000273\ncertification_skills_svd_scaled_1                0.000262\ncertification_skills_svd_scaled_2                0.000311\ncertification_skills_svd_scaled_3                0.000119\ncertification_skills_svd_scaled_4                0.000061\ncertification_skills_svd_scaled_5                0.000236\ncertification_skills_svd_scaled_6                0.000026\ncertification_skills_svd_scaled_7                0.000047\ncertification_skills_svd_scaled_8                0.000022\ncertification_skills_svd_scaled_9                0.000091\ncertification_skills_svd_scaled_10               0.000083\ncertification_skills_svd_scaled_11               0.000060\ncertification_skills_svd_scaled_12               0.000377\ncertification_skills_svd_scaled_13               0.000021\ncertification_skills_svd_scaled_14               0.000033\ncertification_skills_svd_scaled_15               0.000147\ncertification_skills_svd_scaled_16               0.000231\ncertification_skills_svd_scaled_17               0.000007\ncertification_skills_svd_scaled_18               0.000068\ncertification_skills_svd_scaled_19               0.000137\ncertification_skills_svd_scaled_20               0.000505\ncertification_skills_svd_scaled_21               0.000579\ncertification_skills_svd_scaled_22               0.000305\ncertification_skills_svd_scaled_23               0.000007\ncertification_skills_svd_scaled_24               0.000284\nextra_curricular_activity_types_svd_scaled_0     0.001236\nextra_curricular_activity_types_svd_scaled_1     0.001930\nextra_curricular_activity_types_svd_scaled_2     0.001972\nextra_curricular_activity_types_svd_scaled_3     0.001757\nextra_curricular_activity_types_svd_scaled_4     0.001746\nextra_curricular_activity_types_svd_scaled_5     0.001729\nextra_curricular_activity_types_svd_scaled_6     0.002240\nextra_curricular_activity_types_svd_scaled_7     0.002340\nextra_curricular_activity_types_svd_scaled_8     0.001819\nextra_curricular_activity_types_svd_scaled_9     0.001812\nextra_curricular_activity_types_svd_scaled_10    0.001819\nextra_curricular_activity_types_svd_scaled_11    0.002428\nextra_curricular_activity_types_svd_scaled_12    0.001702\nextra_curricular_activity_types_svd_scaled_13    0.001603\nextra_curricular_activity_types_svd_scaled_14    0.001727\nextra_curricular_activity_types_svd_scaled_15    0.002674\nextra_curricular_activity_types_svd_scaled_16    0.001983\nextra_curricular_activity_types_svd_scaled_17    0.001939\nextra_curricular_activity_types_svd_scaled_18    0.001584\nextra_curricular_activity_types_svd_scaled_19    0.001740\nextra_curricular_activity_types_svd_scaled_20    0.001795\nextra_curricular_activity_types_svd_scaled_21    0.001963\nextra_curricular_activity_types_svd_scaled_22    0.001868\nextra_curricular_activity_types_svd_scaled_23    0.002435\nextra_curricular_activity_types_svd_scaled_24    0.002117\n﻿job_position_name_svd_scaled_0                  0.001575\n﻿job_position_name_svd_scaled_1                  0.001021\n﻿job_position_name_svd_scaled_2                  0.001410\n﻿job_position_name_svd_scaled_3                  0.005504\n﻿job_position_name_svd_scaled_4                  0.001317\n﻿job_position_name_svd_scaled_5                  0.002298\n﻿job_position_name_svd_scaled_6                  0.009902\n﻿job_position_name_svd_scaled_7                  0.000142\n﻿job_position_name_svd_scaled_8                  0.001895\n﻿job_position_name_svd_scaled_9                  0.000132\n﻿job_position_name_svd_scaled_10                 0.000834\n﻿job_position_name_svd_scaled_11                 0.002031\n﻿job_position_name_svd_scaled_12                 0.002373\n﻿job_position_name_svd_scaled_13                 0.001421\n﻿job_position_name_svd_scaled_14                 0.001366\n﻿job_position_name_svd_scaled_15                 0.000065\n﻿job_position_name_svd_scaled_16                 0.001527\n﻿job_position_name_svd_scaled_17                 0.000827\n﻿job_position_name_svd_scaled_18                 0.001432\n﻿job_position_name_svd_scaled_19                 0.001260\n﻿job_position_name_svd_scaled_20                 0.002710\n﻿job_position_name_svd_scaled_21                 0.001976\n﻿job_position_name_svd_scaled_22                 0.001066\n﻿job_position_name_svd_scaled_23                 0.000785\n﻿job_position_name_svd_scaled_24                 0.003264\ndtype: float64\nSelected features: 165 out of 216\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"print(\"md\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:20:58.623136Z","iopub.execute_input":"2024-12-27T09:20:58.623443Z","iopub.status.idle":"2024-12-27T09:20:58.627902Z","shell.execute_reply.started":"2024-12-27T09:20:58.623421Z","shell.execute_reply":"2024-12-27T09:20:58.626808Z"}},"outputs":[{"name":"stdout","text":"md\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"\n\n# Define target and features\ntarget_col = 'matched_score'\nif target_col not in train_df.columns:\n    raise ValueError(f\"{target_col} not found in train_df columns!\")\n\n# Drop rows with missing target\ntrain_df = train_df.dropna(subset=[target_col])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:21:02.319713Z","iopub.execute_input":"2024-12-27T09:21:02.320007Z","iopub.status.idle":"2024-12-27T09:21:02.339500Z","shell.execute_reply.started":"2024-12-27T09:21:02.319977Z","shell.execute_reply":"2024-12-27T09:21:02.338451Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"X = train_df.copy()\ny = train_df[target_col].values\nX_test = test_df.copy()\n\n# Define feature columns\ndrop_cols = ['matched_score', 'ID']\nfeature_cols = [\n    c for c in train_df.columns\n    if c not in drop_cols\n        and (train_df[c].dtype in [np.float64, np.int64, np.float32, np.int32])\n]\nprint(f\"Total features: {len(feature_cols)}\")\n\n# Scale features\n\n# Scale features\nscaler = RobustScaler()\nX[feature_cols] = scaler.fit_transform(X[feature_cols])\nX_test[feature_cols] = scaler.transform(X_test[feature_cols])\n\n# scaler = StandardScaler()\n# X[feature_cols] = scaler.fit_transform(X[feature_cols])\n# X_test[feature_cols] = scaler.transform(X_test[feature_cols])\n\n# Re-assign after scaling\ntrain_df = X\ntest_df = X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:21:07.651772Z","iopub.execute_input":"2024-12-27T09:21:07.652053Z","iopub.status.idle":"2024-12-27T09:21:07.775860Z","shell.execute_reply.started":"2024-12-27T09:21:07.652032Z","shell.execute_reply":"2024-12-27T09:21:07.775083Z"}},"outputs":[{"name":"stdout","text":"Total features: 165\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:21:12.159673Z","iopub.execute_input":"2024-12-27T09:21:12.159966Z","iopub.status.idle":"2024-12-27T09:21:12.173142Z","shell.execute_reply.started":"2024-12-27T09:21:12.159946Z","shell.execute_reply":"2024-12-27T09:21:12.172040Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7635 entries, 0 to 7634\nColumns: 166 entries, education_level to matched_score\ndtypes: float64(166)\nmemory usage: 9.7 MB\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"numerical = train_df.select_dtypes(include=['int64', 'float64'])\nnumerical_cols = numerical.columns\nCorrelation = numerical.corr()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:22:36.022346Z","iopub.execute_input":"2024-12-27T09:22:36.022690Z","iopub.status.idle":"2024-12-27T09:22:44.936650Z","shell.execute_reply.started":"2024-12-27T09:22:36.022666Z","shell.execute_reply":"2024-12-27T09:22:44.935930Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"def create_neural_network(input_dim):\n    \"\"\"\n    Create a denser Neural Network model for datasets with sufficient samples.\n    Args:\n    - input_dim (int): Number of input features.\n\n    Returns:\n    - model: Compiled Keras model.\n    \"\"\"\n    model = Sequential()\n\n    # First hidden layer\n    model.add(Dense(256, input_dim=input_dim))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.3))  # Higher dropout for denser layers\n\n    # Second hidden layer\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Third hidden layer\n    model.add(Dense(64))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Output layer\n    model.add(Dense(1, activation='linear'))  # Linear activation for regression\n\n    # Compile the model\n    model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='mse',\n        metrics=['mse']\n    )\n    \n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:30:04.524681Z","iopub.execute_input":"2024-12-27T09:30:04.525012Z","iopub.status.idle":"2024-12-27T09:30:04.530843Z","shell.execute_reply.started":"2024-12-27T09:30:04.524982Z","shell.execute_reply":"2024-12-27T09:30:04.529787Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def cross_validate_neural_network(train_df, features, target, test_df, n_folds=5, random_state=42):\n    \"\"\"\n    Perform K-Fold Cross-Validation with a Neural Network.\n    \n    Args:\n    - train_df (pd.DataFrame): Training data.\n    - features (list): List of feature column names.\n    - target (str): Target column name.\n    - test_df (pd.DataFrame): Testing data (features only).\n    - n_folds (int): Number of folds for cross-validation.\n    - random_state (int): Random state for reproducibility.\n\n    Returns:\n    - final_test_preds (np.array): Averaged predictions for the test set.\n    - avg_mse (float): Average MSE across folds.\n    \"\"\"\n    # Initialize KFold\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\n    # Initialize variables for predictions and metrics\n    oof_preds_nn = np.zeros(len(train_df))\n    test_preds_nn = np.zeros(len(test_df))\n    fold_mses_nn = []\n\n    # Perform K-Fold Cross-Validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n        print(f'\\nTraining fold {fold + 1} / {n_folds}')\n        \n        # Split data into training and validation folds\n        X_train_fold = train_df.iloc[train_idx][features].values\n        y_train_fold = train_df.iloc[train_idx][target].values\n        X_val_fold = train_df.iloc[val_idx][features].values\n        y_val_fold = train_df.iloc[val_idx][target].values\n\n        # Create Neural Network model\n        model = create_neural_network(input_dim=len(features))\n\n        # Early stopping\n        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n        # Train the model\n        model.fit(\n            X_train_fold, y_train_fold,\n            validation_data=(X_val_fold, y_val_fold),\n            epochs=200,\n            batch_size=32,\n            callbacks=[early_stopping],\n            verbose=1\n        )\n\n        # Predict on validation set\n        y_pred_nn = model.predict(X_val_fold).flatten()\n        mse_nn = mean_squared_error(y_val_fold, y_pred_nn)\n        fold_mses_nn.append(mse_nn)\n        print(f\"Fold {fold + 1} Neural Network MSE: {mse_nn:.6f}\")\n        oof_preds_nn[val_idx] = y_pred_nn\n\n        # Predict on test set\n        test_preds_nn += model.predict(test_df[features].values).flatten() / n_folds\n\n    # Calculate average MSE\n    avg_mse_nn = np.mean(fold_mses_nn)\n    print(f\"\\nAverage Neural Network MSE: {avg_mse_nn:.6f}\")\n    \n    return test_preds_nn, avg_mse_nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:30:07.378790Z","iopub.execute_input":"2024-12-27T09:30:07.379098Z","iopub.status.idle":"2024-12-27T09:30:07.386439Z","shell.execute_reply.started":"2024-12-27T09:30:07.379076Z","shell.execute_reply":"2024-12-27T09:30:07.385514Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"\n\n\n\n# Perform Cross-Validation\nprint(\"\\n========== Starting Cross-Validation with Neural Network ==========\")\ntest_preds_nn, mean_mse_nn = cross_validate_neural_network(\n    train_df, \n    feature_cols, \n    target_col, \n    test_df\n)\n\n# Clip predictions to valid range\ntest_preds = np.clip(test_preds, 0, 1)\n# Prepare submission\nprint(\"\\nPreparing Submission...\")\n\n# Check if 'ID' column exists, rename or create if necessary\nif 'ID' not in test_df.columns:\n    if 'id' in test_df.columns:\n        test_df.rename(columns={'id': 'ID'}, inplace=True)\n    elif 'identifier' in test_df.columns:\n        test_df.rename(columns={'identifier': 'ID'}, inplace=True)\n    else:\n        print(\"No 'ID' column found in test_df. Generating a sequential ID column...\")\n        test_df['ID'] = range(1, len(test_df) + 1)\n\n# Ensure sample_submission has matching 'ID' structure\nif 'ID' not in sample_submission.columns:\n    raise ValueError(\"Sample submission file does not contain 'ID' column. Please check the file structure.\")\n\noutput_path='/kaggle/working/submission_final_nn.csv'\nsubmission = sample_submission.copy()\nsubmission['matched_score'] = test_preds\nsubmission.to_csv(output_path, index=False)\nprint(f\"Submission saved: {output_path}\")\nprint(f\"Final Average MSE: {mean_mse:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:30:15.904140Z","iopub.execute_input":"2024-12-27T09:30:15.904473Z","iopub.status.idle":"2024-12-27T09:34:45.032588Z","shell.execute_reply.started":"2024-12-27T09:30:15.904447Z","shell.execute_reply":"2024-12-27T09:34:45.031456Z"}},"outputs":[{"name":"stdout","text":"\n========== Starting Cross-Validation with Neural Network ==========\n\nTraining fold 1 / 5\nEpoch 1/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.7109 - mse: 0.7109 - val_loss: 0.0562 - val_mse: 0.0562\nEpoch 2/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1738 - mse: 0.1738 - val_loss: 0.0323 - val_mse: 0.0323\nEpoch 3/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1105 - mse: 0.1105 - val_loss: 0.0278 - val_mse: 0.0278\nEpoch 4/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0273 - val_mse: 0.0273\nEpoch 5/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0287 - val_mse: 0.0287\nEpoch 6/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0264 - val_mse: 0.0264\nEpoch 7/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0277 - val_mse: 0.0277\nEpoch 8/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0261 - val_mse: 0.0261\nEpoch 9/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0250 - val_mse: 0.0250\nEpoch 10/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0235 - val_mse: 0.0235\nEpoch 11/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0236 - val_mse: 0.0236\nEpoch 12/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0225 - val_mse: 0.0225\nEpoch 13/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0199 - val_mse: 0.0199\nEpoch 14/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0214 - val_mse: 0.0214\nEpoch 15/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0192 - val_mse: 0.0192\nEpoch 16/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0200 - val_mse: 0.0200\nEpoch 17/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0180 - val_mse: 0.0180\nEpoch 18/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0203 - val_mse: 0.0203\nEpoch 19/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0179 - val_mse: 0.0179\nEpoch 20/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0176 - val_mse: 0.0176\nEpoch 21/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0191 - val_mse: 0.0191\nEpoch 22/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0173 - val_mse: 0.0173\nEpoch 23/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0171 - val_mse: 0.0171\nEpoch 24/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0170 - val_mse: 0.0170\nEpoch 25/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0162 - val_mse: 0.0162\nEpoch 26/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0158 - val_mse: 0.0158\nEpoch 27/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0170 - val_mse: 0.0170\nEpoch 28/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0160 - val_mse: 0.0160\nEpoch 29/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0164 - val_mse: 0.0164\nEpoch 30/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0161 - val_mse: 0.0161\nEpoch 31/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0167 - val_mse: 0.0167\nEpoch 32/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0157 - val_mse: 0.0157\nEpoch 33/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0155 - val_mse: 0.0155\nEpoch 34/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0155 - val_mse: 0.0155\nEpoch 35/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0154 - val_mse: 0.0154\nEpoch 36/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0158 - val_mse: 0.0158\nEpoch 37/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0164 - val_mse: 0.0164\nEpoch 38/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 39/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 40/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 41/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0143 - val_mse: 0.0143\nEpoch 42/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0158 - val_mse: 0.0158\nEpoch 43/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0148 - val_mse: 0.0148\nEpoch 44/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 45/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0149 - val_mse: 0.0149\nEpoch 46/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 47/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0145 - val_mse: 0.0145\nEpoch 48/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 49/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 50/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 51/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 52/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0158 - val_mse: 0.0158\nEpoch 53/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0145 - val_mse: 0.0145\nEpoch 54/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\nEpoch 55/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 56/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 57/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0135 - val_mse: 0.0135\nEpoch 58/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 59/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0141 - val_mse: 0.0141\nEpoch 60/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 61/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 62/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 63/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 64/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 65/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 66/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 67/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 68/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 69/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 70/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 71/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0154\nEpoch 72/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 73/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 74/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 75/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 76/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 77/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 78/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 79/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 80/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 81/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 82/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 83/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 84/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 85/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 86/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 87/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 88/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 89/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 90/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 91/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 92/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 93/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 94/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 95/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 96/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 97/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 98/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 99/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 100/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 101/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 102/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 103/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 104/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 105/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 106/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 107/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 108/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 109/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0115 - val_mse: 0.0115\nEpoch 110/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 111/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 112/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 113/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 114/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 115/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 116/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 117/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 118/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 119/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 120/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 121/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 122/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0115 - val_mse: 0.0115\nEpoch 123/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 124/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0115 - val_mse: 0.0115\nEpoch 125/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 126/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 127/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 128/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0114 - val_mse: 0.0114\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\nFold 1 Neural Network MSE: 0.011288\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\nTraining fold 2 / 5\nEpoch 1/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.5674 - mse: 0.5674 - val_loss: 0.0399 - val_mse: 0.0399\nEpoch 2/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1605 - mse: 0.1605 - val_loss: 0.0357 - val_mse: 0.0357\nEpoch 3/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 0.0313 - val_mse: 0.0313\nEpoch 4/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0717 - mse: 0.0717 - val_loss: 0.0314 - val_mse: 0.0314\nEpoch 5/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0278 - val_mse: 0.0278\nEpoch 6/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0285 - val_mse: 0.0285\nEpoch 7/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0273 - val_mse: 0.0273\nEpoch 8/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0268 - val_mse: 0.0268\nEpoch 9/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0267 - val_mse: 0.0267\nEpoch 10/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0249 - val_mse: 0.0249\nEpoch 11/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0232 - val_mse: 0.0232\nEpoch 12/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0227 - val_mse: 0.0227\nEpoch 13/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0211 - val_mse: 0.0211\nEpoch 14/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0202 - val_mse: 0.0202\nEpoch 15/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0189 - val_mse: 0.0189\nEpoch 16/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0188 - val_mse: 0.0188\nEpoch 17/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0182 - val_mse: 0.0182\nEpoch 18/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0191 - val_mse: 0.0191\nEpoch 19/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0178 - val_mse: 0.0178\nEpoch 20/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0175 - val_mse: 0.0175\nEpoch 21/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0176 - val_mse: 0.0176\nEpoch 22/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0177 - val_mse: 0.0177\nEpoch 23/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0173 - val_mse: 0.0173\nEpoch 24/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0183 - val_mse: 0.0183\nEpoch 25/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0171 - val_mse: 0.0171\nEpoch 26/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0166 - val_mse: 0.0166\nEpoch 27/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0163 - val_mse: 0.0163\nEpoch 28/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0160 - val_mse: 0.0160\nEpoch 29/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0159 - val_mse: 0.0159\nEpoch 30/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0168 - val_mse: 0.0168\nEpoch 31/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0159 - val_mse: 0.0159\nEpoch 32/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0159 - val_mse: 0.0159\nEpoch 33/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0168 - val_mse: 0.0168\nEpoch 34/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0156 - val_mse: 0.0156\nEpoch 35/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0155 - val_mse: 0.0155\nEpoch 36/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0150 - val_mse: 0.0150\nEpoch 37/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0152 - val_mse: 0.0152\nEpoch 38/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 39/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0148 - val_mse: 0.0148\nEpoch 40/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 41/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0150 - val_mse: 0.0150\nEpoch 42/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 43/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0145 - val_mse: 0.0145\nEpoch 44/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0152 - val_mse: 0.0152\nEpoch 45/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 46/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 47/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 48/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0141 - val_mse: 0.0141\nEpoch 49/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0141 - val_mse: 0.0141\nEpoch 50/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 51/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0142 - val_mse: 0.0142\nEpoch 52/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0138 - val_mse: 0.0138\nEpoch 53/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\nEpoch 54/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0138 - val_mse: 0.0138\nEpoch 55/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0137 - val_mse: 0.0137\nEpoch 56/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 57/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 58/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 59/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 60/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 61/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 62/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 63/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 64/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 65/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 66/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 67/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0135 - val_mse: 0.0135\nEpoch 68/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 69/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0128 - val_mse: 0.0128\nEpoch 70/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 71/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 72/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 73/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 74/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 75/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0128 - val_mse: 0.0128\nEpoch 76/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0142 - val_mse: 0.0142\nEpoch 77/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0137 - val_mse: 0.0137\nEpoch 78/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 79/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 80/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 81/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 82/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 83/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 84/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 85/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 86/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 87/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 88/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 89/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 90/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 91/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0123 - val_mse: 0.0123\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\nFold 2 Neural Network MSE: 0.011935\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\nTraining fold 3 / 5\nEpoch 1/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.3744 - mse: 0.3744 - val_loss: 0.0477 - val_mse: 0.0477\nEpoch 2/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.0428 - val_mse: 0.0428\nEpoch 3/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 0.0286 - val_mse: 0.0286\nEpoch 4/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0276 - val_mse: 0.0276\nEpoch 5/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0284 - val_mse: 0.0284\nEpoch 6/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0288 - val_mse: 0.0288\nEpoch 7/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0266 - val_mse: 0.0266\nEpoch 8/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0267 - val_mse: 0.0267\nEpoch 9/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0243 - val_mse: 0.0243\nEpoch 10/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0221 - val_mse: 0.0221\nEpoch 11/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0197 - val_mse: 0.0197\nEpoch 12/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0212 - val_mse: 0.0212\nEpoch 13/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0183 - val_mse: 0.0183\nEpoch 14/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0187 - val_mse: 0.0187\nEpoch 15/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0177 - val_mse: 0.0177\nEpoch 16/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0171 - val_mse: 0.0171\nEpoch 17/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0164 - val_mse: 0.0164\nEpoch 18/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0178 - val_mse: 0.0178\nEpoch 19/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0161 - val_mse: 0.0161\nEpoch 20/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0166 - val_mse: 0.0166\nEpoch 21/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0154 - val_mse: 0.0154\nEpoch 22/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0172 - val_mse: 0.0172\nEpoch 23/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0155 - val_mse: 0.0155\nEpoch 24/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 25/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 26/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0150 - val_mse: 0.0150\nEpoch 27/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0153 - val_mse: 0.0153\nEpoch 28/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0150 - val_mse: 0.0150\nEpoch 29/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0163 - val_mse: 0.0163\nEpoch 30/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 31/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0159 - val_mse: 0.0159\nEpoch 32/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 33/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 34/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 35/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 36/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0137 - val_mse: 0.0137\nEpoch 37/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0142 - val_mse: 0.0142\nEpoch 38/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0165 - val_mse: 0.0165\nEpoch 39/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 40/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 41/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0145 - val_mse: 0.0145\nEpoch 42/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0142 - val_mse: 0.0142\nEpoch 43/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0135 - val_mse: 0.0135\nEpoch 44/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0135 - val_mse: 0.0135\nEpoch 45/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 46/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 47/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 48/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0141 - val_mse: 0.0141\nEpoch 49/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 50/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 51/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 52/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 53/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 54/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 55/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0137 - val_mse: 0.0137\nEpoch 56/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 57/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 58/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 59/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 60/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 61/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 62/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 63/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 64/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 65/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 66/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 67/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 68/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 69/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 70/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 71/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 72/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 73/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 74/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 75/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 76/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 77/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 78/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 79/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 80/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 81/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 82/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 83/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 84/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 85/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 86/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 87/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 88/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 89/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 90/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 91/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0131 - val_mse: 0.0131\nEpoch 92/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0111 - val_mse: 0.0111\nEpoch 93/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 94/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 95/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 96/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 97/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 98/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 99/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 100/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 101/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 102/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0110 - val_mse: 0.0110\nEpoch 103/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 104/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 105/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 106/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 107/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0111 - val_mse: 0.0111\nEpoch 108/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 109/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0115 - val_mse: 0.0115\nEpoch 110/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 111/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 112/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 113/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 114/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0107 - val_mse: 0.0107\nEpoch 115/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0107 - val_mse: 0.0107\nEpoch 116/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 117/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0111 - val_mse: 0.0111\nEpoch 118/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 119/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 120/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 121/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 122/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 123/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 124/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 125/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 126/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0110 - val_mse: 0.0110\nEpoch 127/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0111 - val_mse: 0.0111\nEpoch 128/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 129/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0105 - val_mse: 0.0105\nEpoch 130/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 131/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 132/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0107 - val_mse: 0.0107\nEpoch 133/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 134/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0105 - val_mse: 0.0105\nEpoch 135/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 136/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 137/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 138/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0112 - val_mse: 0.0112\nEpoch 139/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0105 - val_mse: 0.0105\nEpoch 140/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0107 - val_mse: 0.0107\nEpoch 141/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0105 - val_mse: 0.0105\nEpoch 142/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 143/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 144/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 145/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0107 - val_mse: 0.0107\nEpoch 146/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 147/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 148/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 149/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 150/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0101 - val_mse: 0.0101\nEpoch 151/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0103 - val_mse: 0.0103\nEpoch 152/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0111 - val_mse: 0.0111\nEpoch 153/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 154/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0112 - val_mse: 0.0112\nEpoch 155/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 156/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 157/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0107 - val_mse: 0.0107\nEpoch 158/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0108 - val_mse: 0.0108\nEpoch 159/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0106 - val_mse: 0.0106\nEpoch 160/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0103 - val_mse: 0.0103\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\nFold 3 Neural Network MSE: 0.010087\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\nTraining fold 4 / 5\nEpoch 1/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.5129 - mse: 0.5129 - val_loss: 0.0621 - val_mse: 0.0621\nEpoch 2/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1648 - mse: 0.1648 - val_loss: 0.0381 - val_mse: 0.0381\nEpoch 3/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.0278 - val_mse: 0.0278\nEpoch 4/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0357 - val_mse: 0.0357\nEpoch 5/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0280 - val_mse: 0.0280\nEpoch 6/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0283 - val_mse: 0.0283\nEpoch 7/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0282 - val_mse: 0.0282\nEpoch 8/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0266 - val_mse: 0.0266\nEpoch 9/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0256 - val_mse: 0.0256\nEpoch 10/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0242 - val_mse: 0.0242\nEpoch 11/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0220 - val_mse: 0.0220\nEpoch 12/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0213 - val_mse: 0.0213\nEpoch 13/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0204 - val_mse: 0.0204\nEpoch 14/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0195 - val_mse: 0.0195\nEpoch 15/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0188 - val_mse: 0.0188\nEpoch 16/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0180 - val_mse: 0.0180\nEpoch 17/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0186 - val_mse: 0.0186\nEpoch 18/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0171 - val_mse: 0.0171\nEpoch 19/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0174 - val_mse: 0.0174\nEpoch 20/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0169 - val_mse: 0.0169\nEpoch 21/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0174 - val_mse: 0.0174\nEpoch 22/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0169 - val_mse: 0.0169\nEpoch 23/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0166 - val_mse: 0.0166\nEpoch 24/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0165 - val_mse: 0.0165\nEpoch 25/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0163 - val_mse: 0.0163\nEpoch 26/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0179 - val_mse: 0.0179\nEpoch 27/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0163 - val_mse: 0.0163\nEpoch 28/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0163 - val_mse: 0.0163\nEpoch 29/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0155 - val_mse: 0.0155\nEpoch 30/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0154 - val_mse: 0.0154\nEpoch 31/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0154 - val_mse: 0.0154\nEpoch 32/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0169 - val_mse: 0.0169\nEpoch 33/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 34/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0162 - val_mse: 0.0162\nEpoch 35/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0150 - val_mse: 0.0150\nEpoch 36/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0150 - val_mse: 0.0150\nEpoch 37/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0165 - val_mse: 0.0165\nEpoch 38/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0143 - val_mse: 0.0143\nEpoch 39/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 40/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0147 - val_mse: 0.0147\nEpoch 41/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 42/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0138 - val_mse: 0.0138\nEpoch 43/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0141 - val_mse: 0.0141\nEpoch 44/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0141 - val_mse: 0.0141\nEpoch 45/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0150 - val_mse: 0.0150\nEpoch 46/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 47/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 48/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0137 - val_mse: 0.0137\nEpoch 49/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 50/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 51/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 52/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 53/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 54/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 55/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 56/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 57/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0134 - val_mse: 0.0134\nEpoch 58/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 59/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\nEpoch 60/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0142 - val_mse: 0.0142\nEpoch 61/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 62/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 63/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 64/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 65/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 66/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 67/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 68/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0120 - val_mse: 0.0120\nEpoch 69/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 70/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 71/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 72/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 73/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 74/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 75/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0135 - val_mse: 0.0135\nEpoch 76/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 77/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 78/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0121 - val_mse: 0.0121\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\nFold 4 Neural Network MSE: 0.011989\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\nTraining fold 5 / 5\nEpoch 1/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.5815 - mse: 0.5815 - val_loss: 0.0646 - val_mse: 0.0646\nEpoch 2/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1878 - mse: 0.1878 - val_loss: 0.0356 - val_mse: 0.0356\nEpoch 3/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1148 - mse: 0.1148 - val_loss: 0.0343 - val_mse: 0.0343\nEpoch 4/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0308 - val_mse: 0.0308\nEpoch 5/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0306 - val_mse: 0.0306\nEpoch 6/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0292 - val_mse: 0.0292\nEpoch 7/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0277 - val_mse: 0.0277\nEpoch 8/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0272 - val_mse: 0.0272\nEpoch 9/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0274 - val_mse: 0.0274\nEpoch 10/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0267 - val_mse: 0.0267\nEpoch 11/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0255 - val_mse: 0.0255\nEpoch 12/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0239 - val_mse: 0.0239\nEpoch 13/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0215 - val_mse: 0.0215\nEpoch 14/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0209 - val_mse: 0.0209\nEpoch 15/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0202 - val_mse: 0.0202\nEpoch 16/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0195 - val_mse: 0.0195\nEpoch 17/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0181 - val_mse: 0.0181\nEpoch 18/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0177 - val_mse: 0.0177\nEpoch 19/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0178 - val_mse: 0.0178\nEpoch 20/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0172 - val_mse: 0.0172\nEpoch 21/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0169 - val_mse: 0.0169\nEpoch 22/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0158 - val_mse: 0.0158\nEpoch 23/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0162 - val_mse: 0.0162\nEpoch 24/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0163 - val_mse: 0.0163\nEpoch 25/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0156 - val_mse: 0.0156\nEpoch 26/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0159 - val_mse: 0.0159\nEpoch 27/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0154 - val_mse: 0.0154\nEpoch 28/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0163 - val_mse: 0.0163\nEpoch 29/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0151 - val_mse: 0.0151\nEpoch 30/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0148 - val_mse: 0.0148\nEpoch 31/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0158 - val_mse: 0.0158\nEpoch 32/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0146 - val_mse: 0.0146\nEpoch 33/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0145 - val_mse: 0.0145\nEpoch 34/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0141 - val_mse: 0.0141\nEpoch 35/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0144 - val_mse: 0.0144\nEpoch 36/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0145 - val_mse: 0.0145\nEpoch 37/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0155 - val_mse: 0.0155\nEpoch 38/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0142 - val_mse: 0.0142\nEpoch 39/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 40/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0138 - val_mse: 0.0138\nEpoch 41/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 42/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 43/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0140 - val_mse: 0.0140\nEpoch 44/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0142 - val_mse: 0.0142\nEpoch 45/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0139 - val_mse: 0.0139\nEpoch 46/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0136 - val_mse: 0.0136\nEpoch 47/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0138 - val_mse: 0.0138\nEpoch 48/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0161 - val_mse: 0.0161\nEpoch 49/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 50/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 51/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 52/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0125 - val_mse: 0.0125\nEpoch 53/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0135 - val_mse: 0.0135\nEpoch 54/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0130 - val_mse: 0.0130\nEpoch 55/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0133 - val_mse: 0.0133\nEpoch 56/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0128 - val_mse: 0.0128\nEpoch 57/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\nEpoch 58/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0119 - val_mse: 0.0119\nEpoch 59/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 60/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 61/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 62/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 63/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 64/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0116 - val_mse: 0.0116\nEpoch 65/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 66/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 67/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\nEpoch 68/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 69/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0126 - val_mse: 0.0126\nEpoch 70/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 71/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 72/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0127 - val_mse: 0.0127\nEpoch 73/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0124 - val_mse: 0.0124\nEpoch 74/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0112 - val_mse: 0.0112\nEpoch 75/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 76/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0123 - val_mse: 0.0123\nEpoch 77/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0122 - val_mse: 0.0122\nEpoch 78/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0132 - val_mse: 0.0132\nEpoch 79/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0114 - val_mse: 0.0114\nEpoch 80/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 81/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0114 - val_mse: 0.0114\nEpoch 82/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0114 - val_mse: 0.0114\nEpoch 83/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 84/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0109 - val_mse: 0.0109\nEpoch 85/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0121 - val_mse: 0.0121\nEpoch 86/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 87/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0115 - val_mse: 0.0115\nEpoch 88/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0113 - val_mse: 0.0113\nEpoch 89/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0114 - val_mse: 0.0114\nEpoch 90/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0118 - val_mse: 0.0118\nEpoch 91/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0117 - val_mse: 0.0117\nEpoch 92/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0111 - val_mse: 0.0111\nEpoch 93/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0111 - val_mse: 0.0111\nEpoch 94/200\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0110 - val_mse: 0.0110\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\nFold 5 Neural Network MSE: 0.010883\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\nAverage Neural Network MSE: 0.011236\n\nPreparing Submission...\nSubmission saved: /kaggle/working/submission_final_nn.csv\nFinal Average MSE: 0.010103\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Correlation.iloc[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nparams_hgb = {\n    'loss': 'squared_error',\n    'max_iter': 300,\n    'learning_rate': 0.05,\n    'max_depth': 6,\n    'random_state': seed,\n    'n_iter_no_change': 50,       # Early stopping\n    'tol': 1e-4,                   # Tolerance for early stopping\n    'validation_fraction': 0.1,    # Fraction of data to use for early stopping\n    'verbose': 0                   # Silent\n}\nparams_gb = {\n    'n_estimators': 300,\n    'learning_rate': 0.05,\n    'max_depth': 6,\n    'random_state': seed,\n    'n_iter_no_change': 50,      # Early stopping\n    'tol': 1e-4,                 # Tolerance for early stopping\n    'validation_fraction': 0.1,  # Fraction of data to use for early stopping\n    'verbose': 0                 # Silent\n}\n\n# Perform Cross-Validation\nprint(\"\\n========== Starting Cross-Validation ==========\")\ntest_preds, mean_mse = cross_validate_model(\n    train_df, \n    feature_cols, \n    target_col, \n    params_hgb, \n    params_gb,\n    test_df\n)\n\n# Clip predictions to valid range\ntest_preds = np.clip(test_preds, 0, 1)\n# Prepare submission\nprint(\"\\nPreparing Submission...\")\n\n# Check if 'ID' column exists, rename or create if necessary\nif 'ID' not in test_df.columns:\n    if 'id' in test_df.columns:\n        test_df.rename(columns={'id': 'ID'}, inplace=True)\n    elif 'identifier' in test_df.columns:\n        test_df.rename(columns={'identifier': 'ID'}, inplace=True)\n    else:\n        print(\"No 'ID' column found in test_df. Generating a sequential ID column...\")\n        test_df['ID'] = range(1, len(test_df) + 1)\n\n# Ensure sample_submission has matching 'ID' structure\nif 'ID' not in sample_submission.columns:\n    raise ValueError(\"Sample submission file does not contain 'ID' column. Please check the file structure.\")\n\noutput_path='/kaggle/working/submission_final.csv'\nsubmission = sample_submission.copy()\nsubmission['matched_score'] = test_preds\nsubmission.to_csv(output_path, index=False)\nprint(f\"Submission saved: {output_path}\")\nprint(f\"Final Average MSE: {mean_mse:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:06:25.601685Z","iopub.execute_input":"2024-12-27T09:06:25.602045Z","iopub.status.idle":"2024-12-27T09:09:48.292892Z","shell.execute_reply.started":"2024-12-27T09:06:25.602018Z","shell.execute_reply":"2024-12-27T09:09:48.292064Z"}},"outputs":[{"name":"stdout","text":"\n========== Starting Cross-Validation ==========\n\nTraining fold 1 / 5\nFold 1 HistGradientBoostingRegressor MSE: 0.010304\nFold 1 GradientBoostingRegressor MSE: 0.010574\n\nTraining fold 2 / 5\nFold 2 HistGradientBoostingRegressor MSE: 0.010149\nFold 2 GradientBoostingRegressor MSE: 0.010361\n\nTraining fold 3 / 5\nFold 3 HistGradientBoostingRegressor MSE: 0.009689\nFold 3 GradientBoostingRegressor MSE: 0.009915\n\nTraining fold 4 / 5\nFold 4 HistGradientBoostingRegressor MSE: 0.010183\nFold 4 GradientBoostingRegressor MSE: 0.010611\n\nTraining fold 5 / 5\nFold 5 HistGradientBoostingRegressor MSE: 0.009415\nFold 5 GradientBoostingRegressor MSE: 0.009832\n\nAverage HistGradientBoostingRegressor MSE: 0.009948\nAverage GradientBoostingRegressor MSE: 0.010258\n\nPreparing Submission...\nSubmission saved: /kaggle/working/submission_final.csv\nFinal Average MSE: 0.010103\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"output_path='/kaggle/working/submission_final.csv'\nsubmission.to_csv(output_path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:01:37.548928Z","iopub.execute_input":"2024-12-27T09:01:37.549298Z","iopub.status.idle":"2024-12-27T09:01:37.558434Z","shell.execute_reply.started":"2024-12-27T09:01:37.549270Z","shell.execute_reply":"2024-12-27T09:01:37.557487Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import csv\n\n# Open file for writing\nfile = open('submission.csv', 'w', encoding='utf-8')\nlog_file = open('log.csv', 'w', encoding='utf-8')\n\n# Create CSV writers\nsubmission_writer = csv.writer(file)\nlog_writer = csv.writer(log_file)\n\n# Write headers\nsubmission_writer.writerow(['ID', 'matched_score'])  # Assuming your DataFrame has these columns\nlog_writer.writerow(['ID', 'Agent ID', 'matched_score'])  # Example log file headers\n\n# Write submission content\nfor index, row in submission.iterrows():\n    submission_writer.writerow([row['ID'], row['matched_score']])  # Adjust columns as per your DataFrame\n    log_writer.writerow([row['ID'], 'Agent_X', row['matched_score']])  # Example log content\n\n# Close files\nfile.close()\nlog_file.close()\n\nprint(\"Submission and log files written successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T09:05:30.468694Z","iopub.execute_input":"2024-12-27T09:05:30.469086Z","iopub.status.idle":"2024-12-27T09:05:30.554652Z","shell.execute_reply.started":"2024-12-27T09:05:30.469058Z","shell.execute_reply":"2024-12-27T09:05:30.553787Z"}},"outputs":[{"name":"stdout","text":"Submission and log files written successfully.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"plt.figure(figsize=(20,7))\n\nsns.heatmap(Correlation,\n            annot=True,\n            cmap='coolwarm',\n            fmt='.2f',\n            linewidths=0.5)\n\nplt.title('Correlation Matrix')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\n\ndef create_denser_neural_network(input_dim):\n    \"\"\"\n    Create a denser Neural Network model for datasets with sufficient samples.\n    Args:\n    - input_dim (int): Number of input features.\n\n    Returns:\n    - model: Compiled Keras model.\n    \"\"\"\n    model = Sequential()\n\n    # First hidden layer\n    model.add(Dense(256, input_dim=input_dim))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.3))  # Higher dropout for denser layers\n\n    # Second hidden layer\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Third hidden layer\n    model.add(Dense(64))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    # Output layer\n    model.add(Dense(1, activation='linear'))  # Linear activation for regression\n\n    # Compile the model\n    model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='mse',\n        metrics=['mse']\n    )\n    \n    return model\n\n\n\ndef cross_validate_neural_network(train_df, features, target, test_df, n_folds=5, random_state=42):\n    \"\"\"\n    Perform K-Fold Cross-Validation with a Neural Network.\n    \n    Args:\n    - train_df (pd.DataFrame): Training data.\n    - features (list): List of feature column names.\n    - target (str): Target column name.\n    - test_df (pd.DataFrame): Testing data (features only).\n    - n_folds (int): Number of folds for cross-validation.\n    - random_state (int): Random state for reproducibility.\n\n    Returns:\n    - final_test_preds (np.array): Averaged predictions for the test set.\n    - avg_mse (float): Average MSE across folds.\n    \"\"\"\n    # Initialize KFold\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\n    # Initialize variables for predictions and metrics\n    oof_preds_nn = np.zeros(len(train_df))\n    test_preds_nn = np.zeros(len(test_df))\n    fold_mses_nn = []\n\n    # Perform K-Fold Cross-Validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n        print(f'\\nTraining fold {fold + 1} / {n_folds}')\n        \n        # Split data into training and validation folds\n        X_train_fold = train_df.iloc[train_idx][features].values\n        y_train_fold = train_df.iloc[train_idx][target].values\n        X_val_fold = train_df.iloc[val_idx][features].values\n        y_val_fold = train_df.iloc[val_idx][target].values\n\n        # Create Neural Network model\n        model = create_neural_network(input_dim=len(features))\n\n        # Early stopping\n        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n        # Train the model\n        model.fit(\n            X_train_fold, y_train_fold,\n            validation_data=(X_val_fold, y_val_fold),\n            epochs=100,\n            batch_size=32,\n            callbacks=[early_stopping],\n            verbose=1\n        )\n\n        # Predict on validation set\n        y_pred_nn = model.predict(X_val_fold).flatten()\n        mse_nn = mean_squared_error(y_val_fold, y_pred_nn)\n        fold_mses_nn.append(mse_nn)\n        print(f\"Fold {fold + 1} Neural Network MSE: {mse_nn:.6f}\")\n        oof_preds_nn[val_idx] = y_pred_nn\n\n        # Predict on test set\n        test_preds_nn += model.predict(test_df[features].values).flatten() / n_folds\n\n    # Calculate average MSE\n    avg_mse_nn = np.mean(fold_mses_nn)\n    print(f\"\\nAverage Neural Network MSE: {avg_mse_nn:.6f}\")\n    \n    return test_preds_nn, avg_mse_nn\n\n\n# Perform Cross-Validation\nprint(\"\\n========== Starting Cross-Validation with Neural Network ==========\")\ntest_preds_nn, mean_mse_nn = cross_validate_neural_network(\n    train_df, \n    feature_cols, \n    target_col, \n    test_df\n)\n\n# Clip predictions to valid range\ntest_preds_nn = np.clip(test_preds_nn, 0, 1)\n\n# Prepare submission\nprint(\"\\nPreparing Submission...\")\nif 'ID' not in test_df.columns:\n    raise ValueError(\"Test dataset does not contain 'ID' column. Please adjust the identifier column name.\")\n\nsubmission = sample_submission.copy()\nsubmission['matched_score'] = test_preds_nn\nsubmission.to_csv(output_path, index=False)\nprint(f\"Submission saved: {output_path}\")\nprint(f\"Final Average MSE: {mean_mse_nn:.6f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}